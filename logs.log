2023-06-12 21:32:12,710:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 21:32:12,711:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 21:32:12,711:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 21:32:12,711:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 21:32:15,215:INFO:Soft dependency imported: prophet: 1.1.4
2023-06-12 22:59:13,630:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 22:59:13,630:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 22:59:13,630:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 22:59:13,630:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 22:59:16,966:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 22:59:16,966:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 22:59:16,966:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 22:59:16,966:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 22:59:18,057:INFO:Soft dependency imported: prophet: 1.1.4
2023-06-13 19:30:56,436:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-13 19:30:56,436:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-13 19:30:56,436:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-13 19:30:56,436:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-13 19:30:58,941:INFO:Soft dependency imported: prophet: 1.1.4
2023-06-13 19:41:44,508:INFO:PyCaret ClassificationExperiment
2023-06-13 19:41:44,509:INFO:Logging name: clf-default-name
2023-06-13 19:41:44,509:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-13 19:41:44,509:INFO:version 3.0.2
2023-06-13 19:41:44,509:INFO:Initializing setup()
2023-06-13 19:41:44,509:INFO:self.USI: 6d2b
2023-06-13 19:41:44,509:INFO:self._variable_keys: {'fix_imbalance', 'exp_name_log', 'fold_shuffle_param', '_ml_usecase', 'fold_generator', 'exp_id', 'pipeline', 'data', 'target_param', '_available_plots', 'memory', 'y_test', 'n_jobs_param', 'y', 'y_train', 'log_plots_param', 'gpu_param', 'seed', 'html_param', 'gpu_n_jobs_param', 'fold_groups_param', 'X_test', 'is_multiclass', 'idx', 'USI', 'X', 'X_train', 'logging_param'}
2023-06-13 19:41:44,509:INFO:Checking environment
2023-06-13 19:41:44,509:INFO:python_version: 3.8.12
2023-06-13 19:41:44,509:INFO:python_build: ('default', 'Oct 12 2021 03:01:40')
2023-06-13 19:41:44,509:INFO:machine: AMD64
2023-06-13 19:41:44,509:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-13 19:41:44,509:INFO:Memory: svmem(total=16861405184, available=5012451328, percent=70.3, used=11848953856, free=5012451328)
2023-06-13 19:41:44,509:INFO:Physical Core: 4
2023-06-13 19:41:44,509:INFO:Logical Core: 8
2023-06-13 19:41:44,509:INFO:Checking libraries
2023-06-13 19:41:44,509:INFO:System:
2023-06-13 19:41:44,509:INFO:    python: 3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]
2023-06-13 19:41:44,509:INFO:executable: c:\Users\choib\anaconda3\envs\iise-python\python.exe
2023-06-13 19:41:44,509:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-13 19:41:44,509:INFO:PyCaret required dependencies:
2023-06-13 19:41:44,511:INFO:                 pip: 21.0.1
2023-06-13 19:41:44,511:INFO:          setuptools: 58.0.4
2023-06-13 19:41:44,511:INFO:             pycaret: 3.0.2
2023-06-13 19:41:44,511:INFO:             IPython: 8.12.0
2023-06-13 19:41:44,511:INFO:          ipywidgets: 8.0.6
2023-06-13 19:41:44,511:INFO:                tqdm: 4.65.0
2023-06-13 19:41:44,511:INFO:               numpy: 1.21.4
2023-06-13 19:41:44,511:INFO:              pandas: 1.5.3
2023-06-13 19:41:44,511:INFO:              jinja2: 3.1.2
2023-06-13 19:41:44,511:INFO:               scipy: 1.10.1
2023-06-13 19:41:44,511:INFO:              joblib: 1.2.0
2023-06-13 19:41:44,511:INFO:             sklearn: 1.2.2
2023-06-13 19:41:44,511:INFO:                pyod: 1.0.9
2023-06-13 19:41:44,511:INFO:            imblearn: 0.10.1
2023-06-13 19:41:44,511:INFO:   category_encoders: 2.6.1
2023-06-13 19:41:44,511:INFO:            lightgbm: 3.3.5
2023-06-13 19:41:44,511:INFO:               numba: 0.57.0
2023-06-13 19:41:44,511:INFO:            requests: 2.31.0
2023-06-13 19:41:44,512:INFO:          matplotlib: 3.4.3
2023-06-13 19:41:44,512:INFO:          scikitplot: 0.3.7
2023-06-13 19:41:44,512:INFO:         yellowbrick: 1.5
2023-06-13 19:41:44,512:INFO:              plotly: 5.15.0
2023-06-13 19:41:44,512:INFO:             kaleido: 0.2.1
2023-06-13 19:41:44,512:INFO:         statsmodels: 0.14.0
2023-06-13 19:41:44,512:INFO:              sktime: 0.17.0
2023-06-13 19:41:44,512:INFO:               tbats: 1.1.3
2023-06-13 19:41:44,512:INFO:            pmdarima: 2.0.3
2023-06-13 19:41:44,512:INFO:              psutil: 5.9.0
2023-06-13 19:41:44,512:INFO:PyCaret optional dependencies:
2023-06-13 19:41:44,535:INFO:                shap: Not installed
2023-06-13 19:41:44,535:INFO:           interpret: Not installed
2023-06-13 19:41:44,535:INFO:                umap: Not installed
2023-06-13 19:41:44,535:INFO:    pandas_profiling: Not installed
2023-06-13 19:41:44,535:INFO:  explainerdashboard: Not installed
2023-06-13 19:41:44,535:INFO:             autoviz: Not installed
2023-06-13 19:41:44,535:INFO:           fairlearn: Not installed
2023-06-13 19:41:44,535:INFO:             xgboost: Not installed
2023-06-13 19:41:44,535:INFO:            catboost: Not installed
2023-06-13 19:41:44,535:INFO:              kmodes: Not installed
2023-06-13 19:41:44,535:INFO:             mlxtend: Not installed
2023-06-13 19:41:44,535:INFO:       statsforecast: Not installed
2023-06-13 19:41:44,535:INFO:        tune_sklearn: Not installed
2023-06-13 19:41:44,536:INFO:                 ray: Not installed
2023-06-13 19:41:44,536:INFO:            hyperopt: Not installed
2023-06-13 19:41:44,536:INFO:              optuna: Not installed
2023-06-13 19:41:44,536:INFO:               skopt: Not installed
2023-06-13 19:41:44,536:INFO:              mlflow: Not installed
2023-06-13 19:41:44,536:INFO:              gradio: Not installed
2023-06-13 19:41:44,536:INFO:             fastapi: Not installed
2023-06-13 19:41:44,536:INFO:             uvicorn: Not installed
2023-06-13 19:41:44,536:INFO:              m2cgen: Not installed
2023-06-13 19:41:44,536:INFO:           evidently: Not installed
2023-06-13 19:41:44,536:INFO:               fugue: Not installed
2023-06-13 19:41:44,536:INFO:           streamlit: Not installed
2023-06-13 19:41:44,536:INFO:             prophet: 1.1.4
2023-06-13 19:41:44,536:INFO:None
2023-06-13 19:41:44,536:INFO:Set up data.
2023-06-13 19:41:51,427:INFO:PyCaret ClassificationExperiment
2023-06-13 19:41:51,427:INFO:Logging name: clf-default-name
2023-06-13 19:41:51,427:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-13 19:41:51,428:INFO:version 3.0.2
2023-06-13 19:41:51,428:INFO:Initializing setup()
2023-06-13 19:41:51,428:INFO:self.USI: 89fe
2023-06-13 19:41:51,428:INFO:self._variable_keys: {'fix_imbalance', 'exp_name_log', 'fold_shuffle_param', '_ml_usecase', 'fold_generator', 'exp_id', 'pipeline', 'data', 'target_param', '_available_plots', 'memory', 'y_test', 'n_jobs_param', 'y', 'y_train', 'log_plots_param', 'gpu_param', 'seed', 'html_param', 'gpu_n_jobs_param', 'fold_groups_param', 'X_test', 'is_multiclass', 'idx', 'USI', 'X', 'X_train', 'logging_param'}
2023-06-13 19:41:51,428:INFO:Checking environment
2023-06-13 19:41:51,428:INFO:python_version: 3.8.12
2023-06-13 19:41:51,428:INFO:python_build: ('default', 'Oct 12 2021 03:01:40')
2023-06-13 19:41:51,429:INFO:machine: AMD64
2023-06-13 19:41:51,429:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-13 19:41:51,429:INFO:Memory: svmem(total=16861405184, available=4948987904, percent=70.6, used=11912417280, free=4948987904)
2023-06-13 19:41:51,429:INFO:Physical Core: 4
2023-06-13 19:41:51,429:INFO:Logical Core: 8
2023-06-13 19:41:51,429:INFO:Checking libraries
2023-06-13 19:41:51,429:INFO:System:
2023-06-13 19:41:51,429:INFO:    python: 3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]
2023-06-13 19:41:51,429:INFO:executable: c:\Users\choib\anaconda3\envs\iise-python\python.exe
2023-06-13 19:41:51,430:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-13 19:41:51,430:INFO:PyCaret required dependencies:
2023-06-13 19:41:51,430:INFO:                 pip: 21.0.1
2023-06-13 19:41:51,430:INFO:          setuptools: 58.0.4
2023-06-13 19:41:51,430:INFO:             pycaret: 3.0.2
2023-06-13 19:41:51,430:INFO:             IPython: 8.12.0
2023-06-13 19:41:51,430:INFO:          ipywidgets: 8.0.6
2023-06-13 19:41:51,430:INFO:                tqdm: 4.65.0
2023-06-13 19:41:51,431:INFO:               numpy: 1.21.4
2023-06-13 19:41:51,431:INFO:              pandas: 1.5.3
2023-06-13 19:41:51,431:INFO:              jinja2: 3.1.2
2023-06-13 19:41:51,431:INFO:               scipy: 1.10.1
2023-06-13 19:41:51,431:INFO:              joblib: 1.2.0
2023-06-13 19:41:51,431:INFO:             sklearn: 1.2.2
2023-06-13 19:41:51,431:INFO:                pyod: 1.0.9
2023-06-13 19:41:51,431:INFO:            imblearn: 0.10.1
2023-06-13 19:41:51,431:INFO:   category_encoders: 2.6.1
2023-06-13 19:41:51,431:INFO:            lightgbm: 3.3.5
2023-06-13 19:41:51,431:INFO:               numba: 0.57.0
2023-06-13 19:41:51,431:INFO:            requests: 2.31.0
2023-06-13 19:41:51,431:INFO:          matplotlib: 3.4.3
2023-06-13 19:41:51,433:INFO:          scikitplot: 0.3.7
2023-06-13 19:41:51,433:INFO:         yellowbrick: 1.5
2023-06-13 19:41:51,433:INFO:              plotly: 5.15.0
2023-06-13 19:41:51,433:INFO:             kaleido: 0.2.1
2023-06-13 19:41:51,433:INFO:         statsmodels: 0.14.0
2023-06-13 19:41:51,433:INFO:              sktime: 0.17.0
2023-06-13 19:41:51,433:INFO:               tbats: 1.1.3
2023-06-13 19:41:51,433:INFO:            pmdarima: 2.0.3
2023-06-13 19:41:51,433:INFO:              psutil: 5.9.0
2023-06-13 19:41:51,433:INFO:PyCaret optional dependencies:
2023-06-13 19:41:51,433:INFO:                shap: Not installed
2023-06-13 19:41:51,433:INFO:           interpret: Not installed
2023-06-13 19:41:51,433:INFO:                umap: Not installed
2023-06-13 19:41:51,433:INFO:    pandas_profiling: Not installed
2023-06-13 19:41:51,433:INFO:  explainerdashboard: Not installed
2023-06-13 19:41:51,434:INFO:             autoviz: Not installed
2023-06-13 19:41:51,434:INFO:           fairlearn: Not installed
2023-06-13 19:41:51,434:INFO:             xgboost: Not installed
2023-06-13 19:41:51,434:INFO:            catboost: Not installed
2023-06-13 19:41:51,434:INFO:              kmodes: Not installed
2023-06-13 19:41:51,434:INFO:             mlxtend: Not installed
2023-06-13 19:41:51,434:INFO:       statsforecast: Not installed
2023-06-13 19:41:51,434:INFO:        tune_sklearn: Not installed
2023-06-13 19:41:51,434:INFO:                 ray: Not installed
2023-06-13 19:41:51,434:INFO:            hyperopt: Not installed
2023-06-13 19:41:51,435:INFO:              optuna: Not installed
2023-06-13 19:41:51,435:INFO:               skopt: Not installed
2023-06-13 19:41:51,435:INFO:              mlflow: Not installed
2023-06-13 19:41:51,435:INFO:              gradio: Not installed
2023-06-13 19:41:51,435:INFO:             fastapi: Not installed
2023-06-13 19:41:51,435:INFO:             uvicorn: Not installed
2023-06-13 19:41:51,435:INFO:              m2cgen: Not installed
2023-06-13 19:41:51,435:INFO:           evidently: Not installed
2023-06-13 19:41:51,436:INFO:               fugue: Not installed
2023-06-13 19:41:51,436:INFO:           streamlit: Not installed
2023-06-13 19:41:51,436:INFO:             prophet: 1.1.4
2023-06-13 19:41:51,436:INFO:None
2023-06-13 19:41:51,436:INFO:Set up data.
2023-06-13 19:41:51,476:INFO:Set up train/test split.
2023-06-13 19:41:51,506:INFO:Set up index.
2023-06-13 19:41:51,508:INFO:Set up folding strategy.
2023-06-13 19:41:51,508:INFO:Assigning column types.
2023-06-13 19:41:51,525:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-13 19:41:51,564:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 19:41:51,571:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-13 19:41:51,613:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 19:41:51,659:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 19:41:51,697:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 19:41:51,698:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-13 19:41:51,725:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 19:41:51,725:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 19:41:51,725:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-13 19:41:51,765:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-13 19:41:51,792:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 19:41:51,792:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 19:41:51,834:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-13 19:41:51,860:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 19:41:51,861:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 19:41:51,861:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-13 19:41:51,940:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 19:41:51,940:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 19:41:52,010:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 19:41:52,010:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 19:41:52,012:INFO:Preparing preprocessing pipeline...
2023-06-13 19:41:52,017:INFO:Set up date feature engineering.
2023-06-13 19:41:52,017:INFO:Set up simple imputation.
2023-06-13 19:41:52,130:INFO:Finished creating preprocessing pipeline.
2023-06-13 19:41:52,140:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\choib\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['ds'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['disk_id', 'r_1', 'n_5', 'r_5',
                                             'r_9', 'r_12', 'n_171', 'r_171',
                                             'n...
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-06-13 19:41:52,140:INFO:Creating final display dataframe.
2023-06-13 19:41:52,506:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             label
2                   Target type            Binary
3           Original data shape       (52838, 31)
4        Transformed data shape       (52838, 33)
5   Transformed train set shape       (36986, 33)
6    Transformed test set shape       (15852, 33)
7              Numeric features                29
8                 Date features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              89fe
2023-06-13 19:41:52,584:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 19:41:52,584:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 19:41:52,648:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 19:41:52,648:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 19:41:52,649:INFO:setup() successfully completed in 1.45s...............
2023-06-13 19:41:52,649:INFO:Initializing compare_models()
2023-06-13 19:41:52,649:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA1C6E1C70>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001FA1C6E1C70>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-06-13 19:41:52,650:INFO:Checking exceptions
2023-06-13 19:41:52,668:INFO:Preparing display monitor
2023-06-13 19:41:52,712:INFO:Initializing Logistic Regression
2023-06-13 19:41:52,712:INFO:Total runtime is 0.0 minutes
2023-06-13 19:41:52,717:INFO:SubProcess create_model() called ==================================
2023-06-13 19:41:52,718:INFO:Initializing create_model()
2023-06-13 19:41:52,718:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA1C6E1C70>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA1B32A2B0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 19:41:52,718:INFO:Checking exceptions
2023-06-13 19:41:52,719:INFO:Importing libraries
2023-06-13 19:41:52,719:INFO:Copying training dataset
2023-06-13 19:41:52,745:INFO:Defining folds
2023-06-13 19:41:52,746:INFO:Declaring metric variables
2023-06-13 19:41:52,753:INFO:Importing untrained model
2023-06-13 19:41:52,758:INFO:Logistic Regression Imported successfully
2023-06-13 19:41:52,768:INFO:Starting cross validation
2023-06-13 19:41:52,770:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 19:41:58,085:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=2):
ABNORMAL_TERMINATION_IN_LNSRCH.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-13 19:41:58,085:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=2):
ABNORMAL_TERMINATION_IN_LNSRCH.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-13 19:41:58,086:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=2):
ABNORMAL_TERMINATION_IN_LNSRCH.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-13 19:41:58,087:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=2):
ABNORMAL_TERMINATION_IN_LNSRCH.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-13 19:41:58,091:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=2):
ABNORMAL_TERMINATION_IN_LNSRCH.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-13 19:41:58,102:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=2):
ABNORMAL_TERMINATION_IN_LNSRCH.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-13 19:41:58,331:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:41:58,331:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:41:58,331:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:41:58,331:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:41:58,331:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:41:58,332:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:41:58,342:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:41:59,276:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=2):
ABNORMAL_TERMINATION_IN_LNSRCH.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-13 19:41:59,293:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=2):
ABNORMAL_TERMINATION_IN_LNSRCH.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-13 19:41:59,362:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:41:59,380:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:42:00,850:INFO:Calculating mean and std
2023-06-13 19:42:00,852:INFO:Creating metrics dataframe
2023-06-13 19:42:01,126:INFO:Uploading results into container
2023-06-13 19:42:01,127:INFO:Uploading model into container now
2023-06-13 19:42:01,128:INFO:_master_model_container: 1
2023-06-13 19:42:01,128:INFO:_display_container: 2
2023-06-13 19:42:01,129:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-06-13 19:42:01,129:INFO:create_model() successfully completed......................................
2023-06-13 19:42:01,211:INFO:SubProcess create_model() end ==================================
2023-06-13 19:42:01,211:INFO:Creating metrics dataframe
2023-06-13 19:42:01,221:INFO:Initializing K Neighbors Classifier
2023-06-13 19:42:01,221:INFO:Total runtime is 0.14181113640467327 minutes
2023-06-13 19:42:01,224:INFO:SubProcess create_model() called ==================================
2023-06-13 19:42:01,224:INFO:Initializing create_model()
2023-06-13 19:42:01,225:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA1C6E1C70>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA1B32A2B0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 19:42:01,225:INFO:Checking exceptions
2023-06-13 19:42:01,225:INFO:Importing libraries
2023-06-13 19:42:01,225:INFO:Copying training dataset
2023-06-13 19:42:01,248:INFO:Defining folds
2023-06-13 19:42:01,248:INFO:Declaring metric variables
2023-06-13 19:42:01,254:INFO:Importing untrained model
2023-06-13 19:42:01,259:INFO:K Neighbors Classifier Imported successfully
2023-06-13 19:42:01,265:INFO:Starting cross validation
2023-06-13 19:42:01,267:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 19:42:04,016:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:42:04,100:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:42:04,269:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:42:04,307:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:42:04,382:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:42:04,417:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:42:06,235:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:42:06,883:INFO:Calculating mean and std
2023-06-13 19:42:06,884:INFO:Creating metrics dataframe
2023-06-13 19:42:07,130:INFO:Uploading results into container
2023-06-13 19:42:07,132:INFO:Uploading model into container now
2023-06-13 19:42:07,133:INFO:_master_model_container: 2
2023-06-13 19:42:07,133:INFO:_display_container: 2
2023-06-13 19:42:07,133:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-06-13 19:42:07,133:INFO:create_model() successfully completed......................................
2023-06-13 19:42:07,212:INFO:SubProcess create_model() end ==================================
2023-06-13 19:42:07,212:INFO:Creating metrics dataframe
2023-06-13 19:42:07,222:INFO:Initializing Naive Bayes
2023-06-13 19:42:07,222:INFO:Total runtime is 0.24183317025502524 minutes
2023-06-13 19:42:07,226:INFO:SubProcess create_model() called ==================================
2023-06-13 19:42:07,226:INFO:Initializing create_model()
2023-06-13 19:42:07,226:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA1C6E1C70>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA1B32A2B0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 19:42:07,226:INFO:Checking exceptions
2023-06-13 19:42:07,226:INFO:Importing libraries
2023-06-13 19:42:07,226:INFO:Copying training dataset
2023-06-13 19:42:07,253:INFO:Defining folds
2023-06-13 19:42:07,253:INFO:Declaring metric variables
2023-06-13 19:42:07,257:INFO:Importing untrained model
2023-06-13 19:42:07,261:INFO:Naive Bayes Imported successfully
2023-06-13 19:42:07,271:INFO:Starting cross validation
2023-06-13 19:42:07,273:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 19:42:10,076:INFO:Calculating mean and std
2023-06-13 19:42:10,077:INFO:Creating metrics dataframe
2023-06-13 19:42:10,316:INFO:Uploading results into container
2023-06-13 19:42:10,316:INFO:Uploading model into container now
2023-06-13 19:42:10,317:INFO:_master_model_container: 3
2023-06-13 19:42:10,317:INFO:_display_container: 2
2023-06-13 19:42:10,317:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-06-13 19:42:10,317:INFO:create_model() successfully completed......................................
2023-06-13 19:42:10,389:INFO:SubProcess create_model() end ==================================
2023-06-13 19:42:10,389:INFO:Creating metrics dataframe
2023-06-13 19:42:10,400:INFO:Initializing Decision Tree Classifier
2023-06-13 19:42:10,400:INFO:Total runtime is 0.29479929208755495 minutes
2023-06-13 19:42:10,405:INFO:SubProcess create_model() called ==================================
2023-06-13 19:42:10,405:INFO:Initializing create_model()
2023-06-13 19:42:10,405:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA1C6E1C70>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA1B32A2B0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 19:42:10,405:INFO:Checking exceptions
2023-06-13 19:42:10,405:INFO:Importing libraries
2023-06-13 19:42:10,405:INFO:Copying training dataset
2023-06-13 19:42:10,431:INFO:Defining folds
2023-06-13 19:42:10,432:INFO:Declaring metric variables
2023-06-13 19:42:10,436:INFO:Importing untrained model
2023-06-13 19:42:10,464:INFO:Decision Tree Classifier Imported successfully
2023-06-13 19:42:10,487:INFO:Starting cross validation
2023-06-13 19:42:10,489:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 19:42:13,858:INFO:Calculating mean and std
2023-06-13 19:42:13,859:INFO:Creating metrics dataframe
2023-06-13 19:42:14,100:INFO:Uploading results into container
2023-06-13 19:42:14,101:INFO:Uploading model into container now
2023-06-13 19:42:14,102:INFO:_master_model_container: 4
2023-06-13 19:42:14,102:INFO:_display_container: 2
2023-06-13 19:42:14,102:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-06-13 19:42:14,102:INFO:create_model() successfully completed......................................
2023-06-13 19:42:14,174:INFO:SubProcess create_model() end ==================================
2023-06-13 19:42:14,174:INFO:Creating metrics dataframe
2023-06-13 19:42:14,185:INFO:Initializing SVM - Linear Kernel
2023-06-13 19:42:14,186:INFO:Total runtime is 0.35790410041809084 minutes
2023-06-13 19:42:14,190:INFO:SubProcess create_model() called ==================================
2023-06-13 19:42:14,190:INFO:Initializing create_model()
2023-06-13 19:42:14,190:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA1C6E1C70>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA1B32A2B0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 19:42:14,190:INFO:Checking exceptions
2023-06-13 19:42:14,190:INFO:Importing libraries
2023-06-13 19:42:14,190:INFO:Copying training dataset
2023-06-13 19:42:14,212:INFO:Defining folds
2023-06-13 19:42:14,212:INFO:Declaring metric variables
2023-06-13 19:42:14,219:INFO:Importing untrained model
2023-06-13 19:42:14,224:INFO:SVM - Linear Kernel Imported successfully
2023-06-13 19:42:14,230:INFO:Starting cross validation
2023-06-13 19:42:14,232:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 19:42:16,515:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-13 19:42:16,523:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:42:16,529:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-13 19:42:16,532:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-13 19:42:16,536:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:42:16,540:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:42:16,600:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-13 19:42:16,608:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:42:16,795:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-13 19:42:16,804:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:42:16,861:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-13 19:42:16,868:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:42:16,920:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-13 19:42:16,927:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:42:17,251:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-13 19:42:17,257:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:42:18,615:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-13 19:42:18,620:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:42:19,027:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-13 19:42:19,526:INFO:Calculating mean and std
2023-06-13 19:42:19,527:INFO:Creating metrics dataframe
2023-06-13 19:42:19,774:INFO:Uploading results into container
2023-06-13 19:42:19,776:INFO:Uploading model into container now
2023-06-13 19:42:19,776:INFO:_master_model_container: 5
2023-06-13 19:42:19,776:INFO:_display_container: 2
2023-06-13 19:42:19,777:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-06-13 19:42:19,777:INFO:create_model() successfully completed......................................
2023-06-13 19:42:19,849:INFO:SubProcess create_model() end ==================================
2023-06-13 19:42:19,849:INFO:Creating metrics dataframe
2023-06-13 19:42:19,859:INFO:Initializing Ridge Classifier
2023-06-13 19:42:19,859:INFO:Total runtime is 0.4524382869402568 minutes
2023-06-13 19:42:19,862:INFO:SubProcess create_model() called ==================================
2023-06-13 19:42:19,862:INFO:Initializing create_model()
2023-06-13 19:42:19,862:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA1C6E1C70>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA1B32A2B0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 19:42:19,862:INFO:Checking exceptions
2023-06-13 19:42:19,863:INFO:Importing libraries
2023-06-13 19:42:19,863:INFO:Copying training dataset
2023-06-13 19:42:19,884:INFO:Defining folds
2023-06-13 19:42:19,885:INFO:Declaring metric variables
2023-06-13 19:42:19,888:INFO:Importing untrained model
2023-06-13 19:42:19,894:INFO:Ridge Classifier Imported successfully
2023-06-13 19:42:19,904:INFO:Starting cross validation
2023-06-13 19:42:19,905:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 19:42:20,165:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.18952e-27): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-06-13 19:42:20,166:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.1934e-27): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T


2023-06-13 19:42:20,181:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.18075e-27): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-06-13 19:42:20,182:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.18421e-27): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-06-13 19:42:20,199:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.19339e-27): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-06-13 19:42:20,210:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.18387e-27): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-06-13 19:42:20,216:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.18323e-27): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-06-13 19:42:20,223:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-13 19:42:20,226:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-13 19:42:20,228:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-13 19:42:20,231:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:42:20,235:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:42:20,236:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:42:20,241:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-13 19:42:20,242:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-13 19:42:20,250:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:42:20,255:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:42:20,256:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-13 19:42:20,263:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:42:20,271:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-13 19:42:20,277:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-13 19:42:20,278:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:42:20,285:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:42:21,061:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.19229e-27): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-06-13 19:42:21,077:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.18282e-27): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-06-13 19:42:21,102:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-13 19:42:21,105:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:42:21,110:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-13 19:42:21,114:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:42:22,805:INFO:Calculating mean and std
2023-06-13 19:42:22,806:INFO:Creating metrics dataframe
2023-06-13 19:42:23,069:INFO:Uploading results into container
2023-06-13 19:42:23,070:INFO:Uploading model into container now
2023-06-13 19:42:23,070:INFO:_master_model_container: 6
2023-06-13 19:42:23,070:INFO:_display_container: 2
2023-06-13 19:42:23,071:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-06-13 19:42:23,071:INFO:create_model() successfully completed......................................
2023-06-13 19:42:23,145:INFO:SubProcess create_model() end ==================================
2023-06-13 19:42:23,145:INFO:Creating metrics dataframe
2023-06-13 19:42:23,156:INFO:Initializing Random Forest Classifier
2023-06-13 19:42:23,156:INFO:Total runtime is 0.5073893507321676 minutes
2023-06-13 19:42:23,160:INFO:SubProcess create_model() called ==================================
2023-06-13 19:42:23,160:INFO:Initializing create_model()
2023-06-13 19:42:23,160:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA1C6E1C70>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA1B32A2B0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 19:42:23,161:INFO:Checking exceptions
2023-06-13 19:42:23,161:INFO:Importing libraries
2023-06-13 19:42:23,161:INFO:Copying training dataset
2023-06-13 19:42:23,186:INFO:Defining folds
2023-06-13 19:42:23,187:INFO:Declaring metric variables
2023-06-13 19:42:23,191:INFO:Importing untrained model
2023-06-13 19:42:23,195:INFO:Random Forest Classifier Imported successfully
2023-06-13 19:42:23,204:INFO:Starting cross validation
2023-06-13 19:42:23,205:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 19:42:28,699:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.40s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 19:42:29,289:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 19:42:30,541:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:42:34,121:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:42:35,348:INFO:Calculating mean and std
2023-06-13 19:42:35,349:INFO:Creating metrics dataframe
2023-06-13 19:42:35,613:INFO:Uploading results into container
2023-06-13 19:42:35,614:INFO:Uploading model into container now
2023-06-13 19:42:35,614:INFO:_master_model_container: 7
2023-06-13 19:42:35,614:INFO:_display_container: 2
2023-06-13 19:42:35,615:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-13 19:42:35,615:INFO:create_model() successfully completed......................................
2023-06-13 19:42:35,688:INFO:SubProcess create_model() end ==================================
2023-06-13 19:42:35,688:INFO:Creating metrics dataframe
2023-06-13 19:42:35,698:INFO:Initializing Quadratic Discriminant Analysis
2023-06-13 19:42:35,699:INFO:Total runtime is 0.7164443095525106 minutes
2023-06-13 19:42:35,704:INFO:SubProcess create_model() called ==================================
2023-06-13 19:42:35,705:INFO:Initializing create_model()
2023-06-13 19:42:35,705:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA1C6E1C70>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA1B32A2B0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 19:42:35,705:INFO:Checking exceptions
2023-06-13 19:42:35,705:INFO:Importing libraries
2023-06-13 19:42:35,705:INFO:Copying training dataset
2023-06-13 19:42:35,727:INFO:Defining folds
2023-06-13 19:42:35,727:INFO:Declaring metric variables
2023-06-13 19:42:35,731:INFO:Importing untrained model
2023-06-13 19:42:35,736:INFO:Quadratic Discriminant Analysis Imported successfully
2023-06-13 19:42:35,747:INFO:Starting cross validation
2023-06-13 19:42:35,748:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 19:42:39,477:INFO:Calculating mean and std
2023-06-13 19:42:39,478:INFO:Creating metrics dataframe
2023-06-13 19:42:39,740:INFO:Uploading results into container
2023-06-13 19:42:39,741:INFO:Uploading model into container now
2023-06-13 19:42:39,742:INFO:_master_model_container: 8
2023-06-13 19:42:39,742:INFO:_display_container: 2
2023-06-13 19:42:39,742:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-06-13 19:42:39,742:INFO:create_model() successfully completed......................................
2023-06-13 19:42:39,814:INFO:SubProcess create_model() end ==================================
2023-06-13 19:42:39,814:INFO:Creating metrics dataframe
2023-06-13 19:42:39,824:INFO:Initializing Ada Boost Classifier
2023-06-13 19:42:39,825:INFO:Total runtime is 0.7852011601130168 minutes
2023-06-13 19:42:39,830:INFO:SubProcess create_model() called ==================================
2023-06-13 19:42:39,831:INFO:Initializing create_model()
2023-06-13 19:42:39,831:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA1C6E1C70>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA1B32A2B0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 19:42:39,831:INFO:Checking exceptions
2023-06-13 19:42:39,831:INFO:Importing libraries
2023-06-13 19:42:39,831:INFO:Copying training dataset
2023-06-13 19:42:39,855:INFO:Defining folds
2023-06-13 19:42:39,856:INFO:Declaring metric variables
2023-06-13 19:42:39,861:INFO:Importing untrained model
2023-06-13 19:42:39,866:INFO:Ada Boost Classifier Imported successfully
2023-06-13 19:42:39,873:INFO:Starting cross validation
2023-06-13 19:42:39,874:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 19:42:44,802:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:42:44,998:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:42:45,739:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:42:45,751:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:42:45,799:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:42:45,881:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:42:46,012:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:42:48,526:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:42:49,046:INFO:Calculating mean and std
2023-06-13 19:42:49,047:INFO:Creating metrics dataframe
2023-06-13 19:42:49,373:INFO:Uploading results into container
2023-06-13 19:42:49,374:INFO:Uploading model into container now
2023-06-13 19:42:49,376:INFO:_master_model_container: 9
2023-06-13 19:42:49,376:INFO:_display_container: 2
2023-06-13 19:42:49,377:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-06-13 19:42:49,377:INFO:create_model() successfully completed......................................
2023-06-13 19:42:49,450:INFO:SubProcess create_model() end ==================================
2023-06-13 19:42:49,450:INFO:Creating metrics dataframe
2023-06-13 19:42:49,462:INFO:Initializing Gradient Boosting Classifier
2023-06-13 19:42:49,462:INFO:Total runtime is 0.9458211779594421 minutes
2023-06-13 19:42:49,466:INFO:SubProcess create_model() called ==================================
2023-06-13 19:42:49,466:INFO:Initializing create_model()
2023-06-13 19:42:49,466:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA1C6E1C70>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA1B32A2B0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 19:42:49,466:INFO:Checking exceptions
2023-06-13 19:42:49,466:INFO:Importing libraries
2023-06-13 19:42:49,466:INFO:Copying training dataset
2023-06-13 19:42:49,491:INFO:Defining folds
2023-06-13 19:42:49,491:INFO:Declaring metric variables
2023-06-13 19:42:49,496:INFO:Importing untrained model
2023-06-13 19:42:49,502:INFO:Gradient Boosting Classifier Imported successfully
2023-06-13 19:42:49,510:INFO:Starting cross validation
2023-06-13 19:42:49,512:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 19:43:15,946:INFO:Calculating mean and std
2023-06-13 19:43:15,947:INFO:Creating metrics dataframe
2023-06-13 19:43:16,254:INFO:Uploading results into container
2023-06-13 19:43:16,256:INFO:Uploading model into container now
2023-06-13 19:43:16,256:INFO:_master_model_container: 10
2023-06-13 19:43:16,256:INFO:_display_container: 2
2023-06-13 19:43:16,257:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-13 19:43:16,257:INFO:create_model() successfully completed......................................
2023-06-13 19:43:16,330:INFO:SubProcess create_model() end ==================================
2023-06-13 19:43:16,331:INFO:Creating metrics dataframe
2023-06-13 19:43:16,341:INFO:Initializing Linear Discriminant Analysis
2023-06-13 19:43:16,342:INFO:Total runtime is 1.3938324411710104 minutes
2023-06-13 19:43:16,346:INFO:SubProcess create_model() called ==================================
2023-06-13 19:43:16,346:INFO:Initializing create_model()
2023-06-13 19:43:16,346:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA1C6E1C70>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA1B32A2B0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 19:43:16,346:INFO:Checking exceptions
2023-06-13 19:43:16,346:INFO:Importing libraries
2023-06-13 19:43:16,347:INFO:Copying training dataset
2023-06-13 19:43:16,370:INFO:Defining folds
2023-06-13 19:43:16,370:INFO:Declaring metric variables
2023-06-13 19:43:16,374:INFO:Importing untrained model
2023-06-13 19:43:16,379:INFO:Linear Discriminant Analysis Imported successfully
2023-06-13 19:43:16,388:INFO:Starting cross validation
2023-06-13 19:43:16,390:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 19:43:17,224:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:43:20,476:INFO:Calculating mean and std
2023-06-13 19:43:20,478:INFO:Creating metrics dataframe
2023-06-13 19:43:20,767:INFO:Uploading results into container
2023-06-13 19:43:20,768:INFO:Uploading model into container now
2023-06-13 19:43:20,769:INFO:_master_model_container: 11
2023-06-13 19:43:20,769:INFO:_display_container: 2
2023-06-13 19:43:20,769:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-06-13 19:43:20,769:INFO:create_model() successfully completed......................................
2023-06-13 19:43:20,844:INFO:SubProcess create_model() end ==================================
2023-06-13 19:43:20,844:INFO:Creating metrics dataframe
2023-06-13 19:43:20,854:INFO:Initializing Extra Trees Classifier
2023-06-13 19:43:20,854:INFO:Total runtime is 1.469036630789439 minutes
2023-06-13 19:43:20,860:INFO:SubProcess create_model() called ==================================
2023-06-13 19:43:20,860:INFO:Initializing create_model()
2023-06-13 19:43:20,860:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA1C6E1C70>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA1B32A2B0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 19:43:20,860:INFO:Checking exceptions
2023-06-13 19:43:20,861:INFO:Importing libraries
2023-06-13 19:43:20,861:INFO:Copying training dataset
2023-06-13 19:43:20,881:INFO:Defining folds
2023-06-13 19:43:20,882:INFO:Declaring metric variables
2023-06-13 19:43:20,885:INFO:Importing untrained model
2023-06-13 19:43:20,890:INFO:Extra Trees Classifier Imported successfully
2023-06-13 19:43:20,897:INFO:Starting cross validation
2023-06-13 19:43:20,899:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 19:43:24,272:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 19:43:24,339:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.27s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 19:43:24,660:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 19:43:29,766:INFO:Calculating mean and std
2023-06-13 19:43:29,767:INFO:Creating metrics dataframe
2023-06-13 19:43:30,070:INFO:Uploading results into container
2023-06-13 19:43:30,072:INFO:Uploading model into container now
2023-06-13 19:43:30,072:INFO:_master_model_container: 12
2023-06-13 19:43:30,073:INFO:_display_container: 2
2023-06-13 19:43:30,074:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-06-13 19:43:30,074:INFO:create_model() successfully completed......................................
2023-06-13 19:43:30,146:INFO:SubProcess create_model() end ==================================
2023-06-13 19:43:30,146:INFO:Creating metrics dataframe
2023-06-13 19:43:30,159:INFO:Initializing Light Gradient Boosting Machine
2023-06-13 19:43:30,159:INFO:Total runtime is 1.6241196791330974 minutes
2023-06-13 19:43:30,162:INFO:SubProcess create_model() called ==================================
2023-06-13 19:43:30,162:INFO:Initializing create_model()
2023-06-13 19:43:30,162:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA1C6E1C70>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA1B32A2B0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 19:43:30,162:INFO:Checking exceptions
2023-06-13 19:43:30,162:INFO:Importing libraries
2023-06-13 19:43:30,163:INFO:Copying training dataset
2023-06-13 19:43:30,186:INFO:Defining folds
2023-06-13 19:43:30,186:INFO:Declaring metric variables
2023-06-13 19:43:30,191:INFO:Importing untrained model
2023-06-13 19:43:30,197:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-13 19:43:30,205:INFO:Starting cross validation
2023-06-13 19:43:30,206:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 19:43:36,079:INFO:Calculating mean and std
2023-06-13 19:43:36,080:INFO:Creating metrics dataframe
2023-06-13 19:43:36,409:INFO:Uploading results into container
2023-06-13 19:43:36,410:INFO:Uploading model into container now
2023-06-13 19:43:36,411:INFO:_master_model_container: 13
2023-06-13 19:43:36,411:INFO:_display_container: 2
2023-06-13 19:43:36,412:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-13 19:43:36,412:INFO:create_model() successfully completed......................................
2023-06-13 19:43:36,486:INFO:SubProcess create_model() end ==================================
2023-06-13 19:43:36,486:INFO:Creating metrics dataframe
2023-06-13 19:43:36,498:INFO:Initializing Dummy Classifier
2023-06-13 19:43:36,498:INFO:Total runtime is 1.729756474494934 minutes
2023-06-13 19:43:36,501:INFO:SubProcess create_model() called ==================================
2023-06-13 19:43:36,502:INFO:Initializing create_model()
2023-06-13 19:43:36,502:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA1C6E1C70>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FA1B32A2B0>, model_only=True, return_train_score=False, kwargs={})
2023-06-13 19:43:36,502:INFO:Checking exceptions
2023-06-13 19:43:36,502:INFO:Importing libraries
2023-06-13 19:43:36,502:INFO:Copying training dataset
2023-06-13 19:43:36,524:INFO:Defining folds
2023-06-13 19:43:36,525:INFO:Declaring metric variables
2023-06-13 19:43:36,529:INFO:Importing untrained model
2023-06-13 19:43:36,533:INFO:Dummy Classifier Imported successfully
2023-06-13 19:43:36,542:INFO:Starting cross validation
2023-06-13 19:43:36,543:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 19:43:36,843:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:43:36,852:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:43:36,885:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:43:36,896:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:43:36,899:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:43:36,928:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:43:36,945:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:43:36,956:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:43:38,062:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:43:38,062:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:43:40,135:INFO:Calculating mean and std
2023-06-13 19:43:40,138:INFO:Creating metrics dataframe
2023-06-13 19:43:40,467:INFO:Uploading results into container
2023-06-13 19:43:40,468:INFO:Uploading model into container now
2023-06-13 19:43:40,468:INFO:_master_model_container: 14
2023-06-13 19:43:40,468:INFO:_display_container: 2
2023-06-13 19:43:40,468:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-06-13 19:43:40,469:INFO:create_model() successfully completed......................................
2023-06-13 19:43:40,541:INFO:SubProcess create_model() end ==================================
2023-06-13 19:43:40,541:INFO:Creating metrics dataframe
2023-06-13 19:43:40,563:INFO:Initializing create_model()
2023-06-13 19:43:40,563:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA1C6E1C70>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-13 19:43:40,564:INFO:Checking exceptions
2023-06-13 19:43:40,566:INFO:Importing libraries
2023-06-13 19:43:40,566:INFO:Copying training dataset
2023-06-13 19:43:40,590:INFO:Defining folds
2023-06-13 19:43:40,590:INFO:Declaring metric variables
2023-06-13 19:43:40,590:INFO:Importing untrained model
2023-06-13 19:43:40,590:INFO:Declaring custom model
2023-06-13 19:43:40,591:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-13 19:43:40,592:INFO:Cross validation set to False
2023-06-13 19:43:40,592:INFO:Fitting Model
2023-06-13 19:43:41,214:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-13 19:43:41,215:INFO:create_model() successfully completed......................................
2023-06-13 19:43:41,323:INFO:_master_model_container: 14
2023-06-13 19:43:41,323:INFO:_display_container: 2
2023-06-13 19:43:41,324:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-13 19:43:41,324:INFO:compare_models() successfully completed......................................
2023-06-13 19:43:41,324:INFO:Initializing create_model()
2023-06-13 19:43:41,324:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA1C6E1C70>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-13 19:43:41,324:INFO:Checking exceptions
2023-06-13 19:43:41,376:INFO:Importing libraries
2023-06-13 19:43:41,377:INFO:Copying training dataset
2023-06-13 19:43:41,422:INFO:Defining folds
2023-06-13 19:43:41,422:INFO:Declaring metric variables
2023-06-13 19:43:41,426:INFO:Importing untrained model
2023-06-13 19:43:41,431:INFO:Logistic Regression Imported successfully
2023-06-13 19:43:41,441:INFO:Starting cross validation
2023-06-13 19:43:41,442:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 19:43:41,790:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:43:41,803:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:43:41,846:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:43:41,863:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:43:41,872:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:43:41,884:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:43:41,910:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:43:41,924:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:43:43,090:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=2):
ABNORMAL_TERMINATION_IN_LNSRCH.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-13 19:43:43,120:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=2):
ABNORMAL_TERMINATION_IN_LNSRCH.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-13 19:43:43,199:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:43:43,203:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 19:43:45,237:INFO:Calculating mean and std
2023-06-13 19:43:45,238:INFO:Creating metrics dataframe
2023-06-13 19:43:45,243:INFO:Finalizing model
2023-06-13 19:43:45,420:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=2):
ABNORMAL_TERMINATION_IN_LNSRCH.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-13 19:43:45,734:INFO:Uploading results into container
2023-06-13 19:43:45,735:INFO:Uploading model into container now
2023-06-13 19:43:45,746:INFO:_master_model_container: 15
2023-06-13 19:43:45,746:INFO:_display_container: 3
2023-06-13 19:43:45,746:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-06-13 19:43:45,746:INFO:create_model() successfully completed......................................
2023-06-13 19:43:45,850:INFO:Initializing predict_model()
2023-06-13 19:43:45,850:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA1C6E1C70>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FA1B32E160>)
2023-06-13 19:43:45,850:INFO:Checking exceptions
2023-06-13 19:43:45,850:INFO:Preloading libraries
2023-06-13 19:43:45,852:INFO:Set up data.
2023-06-13 19:43:45,873:INFO:Set up index.
2023-06-13 19:43:45,957:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-13 20:19:12,396:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\tqdm\std.py:1178: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.
  for obj in iterable:

2023-06-13 20:20:13,548:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\tqdm\std.py:1178: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.
  for obj in iterable:

2023-06-13 20:28:38,812:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\tqdm\std.py:1178: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.
  for obj in iterable:

2023-06-13 20:31:31,583:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\tqdm\std.py:1178: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.
  for obj in iterable:

2023-06-13 20:36:10,892:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\tqdm\std.py:1178: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.
  for obj in iterable:

2023-06-13 20:36:50,841:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\tqdm\std.py:1178: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.
  for obj in iterable:

2023-06-13 20:37:30,429:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\tqdm\std.py:1178: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.
  for obj in iterable:

2023-06-13 20:57:32,019:INFO:Initializing create_model()
2023-06-13 20:57:32,020:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA1C6E1C70>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-13 20:57:32,020:INFO:Checking exceptions
2023-06-13 20:57:32,050:INFO:Importing libraries
2023-06-13 20:57:32,050:INFO:Copying training dataset
2023-06-13 20:57:32,081:INFO:Defining folds
2023-06-13 20:57:32,081:INFO:Declaring metric variables
2023-06-13 20:57:32,084:INFO:Importing untrained model
2023-06-13 20:57:32,088:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-13 20:57:32,096:INFO:Starting cross validation
2023-06-13 20:57:32,098:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 20:57:41,056:INFO:Calculating mean and std
2023-06-13 20:57:41,057:INFO:Creating metrics dataframe
2023-06-13 20:57:41,063:INFO:Finalizing model
2023-06-13 20:57:41,464:INFO:Uploading results into container
2023-06-13 20:57:41,465:INFO:Uploading model into container now
2023-06-13 20:57:41,476:INFO:_master_model_container: 16
2023-06-13 20:57:41,476:INFO:_display_container: 5
2023-06-13 20:57:41,477:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-13 20:57:41,477:INFO:create_model() successfully completed......................................
2023-06-13 20:57:41,597:INFO:Initializing predict_model()
2023-06-13 20:57:41,597:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FA1C6E1C70>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FA00230310>)
2023-06-13 20:57:41,597:INFO:Checking exceptions
2023-06-13 20:57:41,597:INFO:Preloading libraries
2023-06-13 20:57:41,599:INFO:Set up data.
2023-06-13 20:57:41,621:INFO:Set up index.
2023-06-13 23:51:13,395:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\3380775872.py:1: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.
  for disk in grouped:

2023-06-13 23:57:30,135:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\98681368.py:6: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.
  for name,disk in grouped:

2023-06-13 23:58:03,825:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\3376584169.py:6: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.
  for name,disk in grouped:

2023-06-13 23:58:08,801:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1142762787.py:6: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.
  for name,disk in grouped:

2023-06-13 23:59:11,586:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\854030263.py:6: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.
  for name,disk in grouped:

2023-06-14 00:02:23,784:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\4152817161.py:6: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.
  for name,disk in grouped:

2023-06-14 00:06:39,439:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,441:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,442:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,443:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,445:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,446:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,447:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,448:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,448:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,449:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,450:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,451:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,452:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,479:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,480:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,481:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,482:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,483:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,483:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,484:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,485:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,486:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,488:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,490:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,491:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,492:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,493:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,494:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,494:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,495:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,495:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,497:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,498:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,498:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,499:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,500:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,500:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,501:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,503:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,505:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,506:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,507:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,509:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,510:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,511:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,512:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,513:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,513:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,514:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,515:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,515:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,516:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,516:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,517:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,517:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,518:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,519:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,519:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,520:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,522:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,523:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,524:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,524:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,526:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,527:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,527:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,528:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,528:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,529:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,529:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:06:39,530:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\393370866.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:05,604:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\925733326.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:05,605:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\925733326.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:05,606:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\925733326.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:05,607:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\925733326.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:05,608:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\925733326.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:05,609:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\925733326.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:05,610:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\925733326.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:05,612:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\925733326.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:05,612:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\925733326.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:05,613:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\925733326.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:05,614:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\925733326.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:05,614:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\925733326.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:05,615:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\925733326.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:05,616:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\925733326.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:05,616:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\925733326.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:05,617:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\925733326.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:05,618:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\925733326.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:05,618:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\925733326.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:05,619:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\925733326.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:05,620:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\925733326.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:05,620:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\925733326.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:05,621:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\925733326.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:05,622:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\925733326.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:05,622:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\925733326.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:05,624:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\925733326.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:05,625:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\925733326.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:05,626:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\925733326.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:05,627:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\925733326.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:05,628:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\925733326.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:05,629:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\925733326.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:05,630:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\925733326.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:05,631:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\925733326.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:05,632:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\925733326.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:05,632:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\925733326.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:05,633:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\925733326.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:05,634:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\925733326.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:05,635:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\925733326.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:05,636:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\925733326.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:05,636:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\925733326.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:05,638:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\925733326.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:30,757:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\2125446987.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:30,759:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\2125446987.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:30,760:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\2125446987.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:30,760:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\2125446987.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:30,761:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\2125446987.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:30,762:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\2125446987.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:30,763:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\2125446987.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:30,764:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\2125446987.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:30,765:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\2125446987.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:30,766:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\2125446987.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:30,767:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\2125446987.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:30,768:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\2125446987.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:30,769:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\2125446987.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:30,770:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\2125446987.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:30,771:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\2125446987.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:30,772:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\2125446987.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:30,773:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\2125446987.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:30,773:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\2125446987.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:30,774:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\2125446987.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:30,775:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\2125446987.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:30,775:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\2125446987.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:30,776:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\2125446987.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:30,776:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\2125446987.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:30,777:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\2125446987.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:30,778:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\2125446987.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:30,778:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\2125446987.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:30,779:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\2125446987.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:30,780:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\2125446987.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:30,781:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\2125446987.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:30,782:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\2125446987.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:30,783:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\2125446987.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:30,784:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\2125446987.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:30,784:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\2125446987.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:30,785:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\2125446987.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:30,786:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\2125446987.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:30,786:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\2125446987.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:30,787:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\2125446987.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:30,788:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\2125446987.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:30,789:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\2125446987.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:07:30,790:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\2125446987.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:08:52,770:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:6: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.
  for name,disk in grouped:

2023-06-14 00:08:52,874:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:08:52,874:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:08:52,875:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:08:52,876:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:08:52,876:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:08:52,878:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:08:52,878:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:08:52,879:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:08:52,879:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:08:52,880:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:08:52,880:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:08:52,881:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:08:52,881:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:08:52,882:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:08:52,882:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:08:52,883:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:08:52,883:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:08:52,884:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:08:52,884:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:08:52,885:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:08:52,885:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:08:52,886:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:08:52,886:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:08:52,887:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:08:52,887:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:08:52,888:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:08:52,888:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:08:52,889:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:08:52,889:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:08:52,890:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:08:52,891:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:08:52,891:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:08:52,892:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:08:52,893:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:08:52,894:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:08:52,894:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:08:52,895:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:08:52,895:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:08:52,896:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:08:52,896:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:08:52,897:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:08:52,897:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:08:52,897:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\235375230.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:09:05,798:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\tqdm\std.py:1178: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.
  for obj in iterable:

2023-06-14 00:09:05,873:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1786854406.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:09:05,874:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1786854406.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:09:05,874:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1786854406.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:09:05,875:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1786854406.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:09:05,875:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1786854406.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:09:05,876:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1786854406.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:09:05,877:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1786854406.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:09:05,877:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1786854406.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:09:05,878:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1786854406.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:09:05,879:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1786854406.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:09:05,879:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1786854406.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:09:05,880:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1786854406.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:09:05,880:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1786854406.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:09:05,881:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1786854406.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:09:05,881:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1786854406.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:09:05,882:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1786854406.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:09:05,882:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1786854406.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:09:05,883:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1786854406.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:09:05,883:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1786854406.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:09:05,884:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1786854406.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:09:05,885:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1786854406.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:09:05,885:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1786854406.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:09:05,886:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1786854406.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:09:05,886:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1786854406.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:09:05,887:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1786854406.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:09:05,887:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1786854406.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:09:05,887:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1786854406.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:09:05,888:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1786854406.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:09:05,888:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1786854406.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:09:05,889:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1786854406.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:09:05,889:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1786854406.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:09:05,891:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1786854406.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:09:05,891:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1786854406.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:09:05,892:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1786854406.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:09:05,892:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1786854406.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:09:05,893:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1786854406.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:09:05,893:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1786854406.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:09:05,894:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1786854406.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:09:05,894:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1786854406.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:09:05,894:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1786854406.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:09:05,895:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1786854406.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:09:05,895:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1786854406.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:09:05,896:WARNING:C:\Users\choib\AppData\Local\Temp\ipykernel_35092\1786854406.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  window_5_df[f'{column}_t_{i}'] = features[column].shift(-i)

2023-06-14 00:44:42,425:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\base.py:432: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names
  warnings.warn(

2023-06-14 00:48:54,148:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\base.py:432: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names
  warnings.warn(

2023-06-18 22:28:01,874:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-18 22:28:01,875:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-18 22:28:01,875:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-18 22:28:01,875:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-18 22:28:04,292:INFO:Soft dependency imported: prophet: 1.1.4
2023-06-19 21:49:21,455:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-19 21:49:21,455:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-19 21:49:21,455:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-19 21:49:21,455:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-19 21:49:22,730:INFO:Soft dependency imported: prophet: 1.1.4
2023-06-19 21:49:23,293:INFO:PyCaret ClassificationExperiment
2023-06-19 21:49:23,293:INFO:Logging name: clf-default-name
2023-06-19 21:49:23,293:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-19 21:49:23,293:INFO:version 3.0.2
2023-06-19 21:49:23,293:INFO:Initializing setup()
2023-06-19 21:49:23,293:INFO:self.USI: 9e41
2023-06-19 21:49:23,293:INFO:self._variable_keys: {'idx', 'y', 'fold_generator', 'fold_shuffle_param', 'fold_groups_param', 'n_jobs_param', 'gpu_param', 'html_param', 'data', 'USI', 'is_multiclass', 'X_test', 'exp_name_log', 'memory', 'pipeline', 'y_train', 'target_param', 'fix_imbalance', 'log_plots_param', 'X', '_available_plots', 'gpu_n_jobs_param', 'X_train', 'seed', 'y_test', 'logging_param', '_ml_usecase', 'exp_id'}
2023-06-19 21:49:23,293:INFO:Checking environment
2023-06-19 21:49:23,293:INFO:python_version: 3.8.12
2023-06-19 21:49:23,295:INFO:python_build: ('default', 'Oct 12 2021 03:01:40')
2023-06-19 21:49:23,295:INFO:machine: AMD64
2023-06-19 21:49:23,295:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-19 21:49:23,295:INFO:Memory: svmem(total=16861405184, available=4040290304, percent=76.0, used=12821114880, free=4040290304)
2023-06-19 21:49:23,295:INFO:Physical Core: 4
2023-06-19 21:49:23,295:INFO:Logical Core: 8
2023-06-19 21:49:23,295:INFO:Checking libraries
2023-06-19 21:49:23,296:INFO:System:
2023-06-19 21:49:23,296:INFO:    python: 3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]
2023-06-19 21:49:23,296:INFO:executable: c:\Users\choib\anaconda3\envs\iise-python\python.exe
2023-06-19 21:49:23,296:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-19 21:49:23,296:INFO:PyCaret required dependencies:
2023-06-19 21:49:23,296:INFO:                 pip: 21.0.1
2023-06-19 21:49:23,296:INFO:          setuptools: 58.0.4
2023-06-19 21:49:23,296:INFO:             pycaret: 3.0.2
2023-06-19 21:49:23,296:INFO:             IPython: 8.12.0
2023-06-19 21:49:23,296:INFO:          ipywidgets: 8.0.6
2023-06-19 21:49:23,296:INFO:                tqdm: 4.65.0
2023-06-19 21:49:23,296:INFO:               numpy: 1.21.4
2023-06-19 21:49:23,297:INFO:              pandas: 1.5.3
2023-06-19 21:49:23,297:INFO:              jinja2: 3.1.2
2023-06-19 21:49:23,297:INFO:               scipy: 1.10.1
2023-06-19 21:49:23,297:INFO:              joblib: 1.2.0
2023-06-19 21:49:23,297:INFO:             sklearn: 1.2.2
2023-06-19 21:49:23,297:INFO:                pyod: 1.0.9
2023-06-19 21:49:23,297:INFO:            imblearn: 0.10.1
2023-06-19 21:49:23,297:INFO:   category_encoders: 2.6.1
2023-06-19 21:49:23,297:INFO:            lightgbm: 3.3.5
2023-06-19 21:49:23,297:INFO:               numba: 0.57.0
2023-06-19 21:49:23,297:INFO:            requests: 2.31.0
2023-06-19 21:49:23,297:INFO:          matplotlib: 3.4.3
2023-06-19 21:49:23,298:INFO:          scikitplot: 0.3.7
2023-06-19 21:49:23,298:INFO:         yellowbrick: 1.5
2023-06-19 21:49:23,298:INFO:              plotly: 5.15.0
2023-06-19 21:49:23,298:INFO:             kaleido: 0.2.1
2023-06-19 21:49:23,298:INFO:         statsmodels: 0.14.0
2023-06-19 21:49:23,298:INFO:              sktime: 0.17.0
2023-06-19 21:49:23,298:INFO:               tbats: 1.1.3
2023-06-19 21:49:23,298:INFO:            pmdarima: 2.0.3
2023-06-19 21:49:23,298:INFO:              psutil: 5.9.0
2023-06-19 21:49:23,298:INFO:PyCaret optional dependencies:
2023-06-19 21:49:23,324:INFO:                shap: Not installed
2023-06-19 21:49:23,324:INFO:           interpret: Not installed
2023-06-19 21:49:23,324:INFO:                umap: Not installed
2023-06-19 21:49:23,324:INFO:    pandas_profiling: Not installed
2023-06-19 21:49:23,324:INFO:  explainerdashboard: Not installed
2023-06-19 21:49:23,324:INFO:             autoviz: Not installed
2023-06-19 21:49:23,324:INFO:           fairlearn: Not installed
2023-06-19 21:49:23,324:INFO:             xgboost: Not installed
2023-06-19 21:49:23,324:INFO:            catboost: Not installed
2023-06-19 21:49:23,324:INFO:              kmodes: Not installed
2023-06-19 21:49:23,324:INFO:             mlxtend: Not installed
2023-06-19 21:49:23,324:INFO:       statsforecast: Not installed
2023-06-19 21:49:23,324:INFO:        tune_sklearn: Not installed
2023-06-19 21:49:23,324:INFO:                 ray: Not installed
2023-06-19 21:49:23,324:INFO:            hyperopt: Not installed
2023-06-19 21:49:23,325:INFO:              optuna: Not installed
2023-06-19 21:49:23,325:INFO:               skopt: Not installed
2023-06-19 21:49:23,325:INFO:              mlflow: Not installed
2023-06-19 21:49:23,325:INFO:              gradio: Not installed
2023-06-19 21:49:23,325:INFO:             fastapi: Not installed
2023-06-19 21:49:23,325:INFO:             uvicorn: Not installed
2023-06-19 21:49:23,325:INFO:              m2cgen: Not installed
2023-06-19 21:49:23,325:INFO:           evidently: Not installed
2023-06-19 21:49:23,325:INFO:               fugue: Not installed
2023-06-19 21:49:23,325:INFO:           streamlit: Not installed
2023-06-19 21:49:23,325:INFO:             prophet: 1.1.4
2023-06-19 21:49:23,325:INFO:None
2023-06-19 21:49:23,325:INFO:Set up data.
2023-06-19 21:49:23,357:INFO:Set up train/test split.
2023-06-19 21:49:23,395:INFO:Set up index.
2023-06-19 21:49:23,398:INFO:Set up folding strategy.
2023-06-19 21:49:23,398:INFO:Assigning column types.
2023-06-19 21:49:23,413:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-19 21:49:23,457:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-19 21:49:23,463:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-19 21:49:23,510:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 21:49:23,571:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 21:49:23,610:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-19 21:49:23,611:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-19 21:49:23,634:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 21:49:23,634:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 21:49:23,634:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-19 21:49:23,671:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-19 21:49:23,694:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 21:49:23,695:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 21:49:23,732:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-19 21:49:23,755:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 21:49:23,755:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 21:49:23,755:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-19 21:49:23,818:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 21:49:23,819:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 21:49:23,884:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 21:49:23,884:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 21:49:23,890:INFO:Preparing preprocessing pipeline...
2023-06-19 21:49:23,895:INFO:Set up simple imputation.
2023-06-19 21:49:23,904:INFO:Set up encoding of categorical features.
2023-06-19 21:49:24,054:INFO:Finished creating preprocessing pipeline.
2023-06-19 21:49:24,059:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\choib\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['disk_id', 'r_1', 'n_5', 'r_5',
                                             'r_9', 'r_12', 'n_171', 'r_171',
                                             'n_172', 'r_172', 'n_173', 'r_174',
                                             'n_180', 'r_180', 'n_184', 'r_184',
                                             'r_187', 'r_188', 'n_190', 'r_190',
                                             'r_194', 'r_195', 'n_196', 'r_196',
                                             'r_197', 'r_198', 'r...
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['ds'],
                                    transformer=TargetEncoder(cols=['ds'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2023-06-19 21:49:24,060:INFO:Creating final display dataframe.
2023-06-19 21:49:24,447:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             label
2                   Target type            Binary
3           Original data shape       (52838, 31)
4        Transformed data shape       (52838, 31)
5   Transformed train set shape       (36986, 31)
6    Transformed test set shape       (15852, 31)
7              Numeric features                29
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              9e41
2023-06-19 21:49:24,527:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 21:49:24,528:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 21:49:24,587:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 21:49:24,587:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 21:49:24,588:INFO:setup() successfully completed in 1.46s...............
2023-06-19 21:49:24,588:INFO:Initializing compare_models()
2023-06-19 21:49:24,588:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C750A1A550>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001C750A1A550>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-06-19 21:49:24,588:INFO:Checking exceptions
2023-06-19 21:49:24,604:INFO:Preparing display monitor
2023-06-19 21:49:24,646:INFO:Initializing Logistic Regression
2023-06-19 21:49:24,646:INFO:Total runtime is 0.0 minutes
2023-06-19 21:49:24,651:INFO:SubProcess create_model() called ==================================
2023-06-19 21:49:24,651:INFO:Initializing create_model()
2023-06-19 21:49:24,652:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C750A1A550>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C73DEE2100>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 21:49:24,652:INFO:Checking exceptions
2023-06-19 21:49:24,652:INFO:Importing libraries
2023-06-19 21:49:24,652:INFO:Copying training dataset
2023-06-19 21:49:24,680:INFO:Defining folds
2023-06-19 21:49:24,680:INFO:Declaring metric variables
2023-06-19 21:49:24,686:INFO:Importing untrained model
2023-06-19 21:49:24,692:INFO:Logistic Regression Imported successfully
2023-06-19 21:49:24,700:INFO:Starting cross validation
2023-06-19 21:49:24,701:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 21:49:31,736:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 21:49:31,745:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 21:49:31,766:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 21:49:31,798:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 21:49:31,816:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 21:49:31,822:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 21:49:31,823:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 21:49:31,943:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 21:49:32,551:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 21:49:32,588:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 21:49:32,783:INFO:Calculating mean and std
2023-06-19 21:49:32,786:INFO:Creating metrics dataframe
2023-06-19 21:49:32,867:INFO:Uploading results into container
2023-06-19 21:49:32,868:INFO:Uploading model into container now
2023-06-19 21:49:32,868:INFO:_master_model_container: 1
2023-06-19 21:49:32,868:INFO:_display_container: 2
2023-06-19 21:49:32,868:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-06-19 21:49:32,868:INFO:create_model() successfully completed......................................
2023-06-19 21:49:32,936:INFO:SubProcess create_model() end ==================================
2023-06-19 21:49:32,937:INFO:Creating metrics dataframe
2023-06-19 21:49:32,945:INFO:Initializing K Neighbors Classifier
2023-06-19 21:49:32,945:INFO:Total runtime is 0.13831597963968914 minutes
2023-06-19 21:49:32,949:INFO:SubProcess create_model() called ==================================
2023-06-19 21:49:32,949:INFO:Initializing create_model()
2023-06-19 21:49:32,949:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C750A1A550>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C73DEE2100>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 21:49:32,949:INFO:Checking exceptions
2023-06-19 21:49:32,949:INFO:Importing libraries
2023-06-19 21:49:32,950:INFO:Copying training dataset
2023-06-19 21:49:32,969:INFO:Defining folds
2023-06-19 21:49:32,970:INFO:Declaring metric variables
2023-06-19 21:49:32,974:INFO:Importing untrained model
2023-06-19 21:49:32,978:INFO:K Neighbors Classifier Imported successfully
2023-06-19 21:49:32,988:INFO:Starting cross validation
2023-06-19 21:49:32,990:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 21:49:37,552:INFO:Calculating mean and std
2023-06-19 21:49:37,553:INFO:Creating metrics dataframe
2023-06-19 21:49:37,633:INFO:Uploading results into container
2023-06-19 21:49:37,633:INFO:Uploading model into container now
2023-06-19 21:49:37,633:INFO:_master_model_container: 2
2023-06-19 21:49:37,634:INFO:_display_container: 2
2023-06-19 21:49:37,634:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-06-19 21:49:37,634:INFO:create_model() successfully completed......................................
2023-06-19 21:49:37,701:INFO:SubProcess create_model() end ==================================
2023-06-19 21:49:37,702:INFO:Creating metrics dataframe
2023-06-19 21:49:37,709:INFO:Initializing Naive Bayes
2023-06-19 21:49:37,710:INFO:Total runtime is 0.217731507619222 minutes
2023-06-19 21:49:37,714:INFO:SubProcess create_model() called ==================================
2023-06-19 21:49:37,714:INFO:Initializing create_model()
2023-06-19 21:49:37,715:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C750A1A550>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C73DEE2100>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 21:49:37,715:INFO:Checking exceptions
2023-06-19 21:49:37,715:INFO:Importing libraries
2023-06-19 21:49:37,715:INFO:Copying training dataset
2023-06-19 21:49:37,737:INFO:Defining folds
2023-06-19 21:49:37,737:INFO:Declaring metric variables
2023-06-19 21:49:37,741:INFO:Importing untrained model
2023-06-19 21:49:37,746:INFO:Naive Bayes Imported successfully
2023-06-19 21:49:37,754:INFO:Starting cross validation
2023-06-19 21:49:37,755:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 21:49:39,199:INFO:Calculating mean and std
2023-06-19 21:49:39,200:INFO:Creating metrics dataframe
2023-06-19 21:49:39,265:INFO:Uploading results into container
2023-06-19 21:49:39,266:INFO:Uploading model into container now
2023-06-19 21:49:39,266:INFO:_master_model_container: 3
2023-06-19 21:49:39,266:INFO:_display_container: 2
2023-06-19 21:49:39,267:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-06-19 21:49:39,267:INFO:create_model() successfully completed......................................
2023-06-19 21:49:39,335:INFO:SubProcess create_model() end ==================================
2023-06-19 21:49:39,335:INFO:Creating metrics dataframe
2023-06-19 21:49:39,344:INFO:Initializing Decision Tree Classifier
2023-06-19 21:49:39,344:INFO:Total runtime is 0.2449656327565511 minutes
2023-06-19 21:49:39,348:INFO:SubProcess create_model() called ==================================
2023-06-19 21:49:39,349:INFO:Initializing create_model()
2023-06-19 21:49:39,349:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C750A1A550>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C73DEE2100>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 21:49:39,349:INFO:Checking exceptions
2023-06-19 21:49:39,349:INFO:Importing libraries
2023-06-19 21:49:39,349:INFO:Copying training dataset
2023-06-19 21:49:39,370:INFO:Defining folds
2023-06-19 21:49:39,370:INFO:Declaring metric variables
2023-06-19 21:49:39,375:INFO:Importing untrained model
2023-06-19 21:49:39,379:INFO:Decision Tree Classifier Imported successfully
2023-06-19 21:49:39,386:INFO:Starting cross validation
2023-06-19 21:49:39,388:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 21:49:41,421:INFO:Calculating mean and std
2023-06-19 21:49:41,422:INFO:Creating metrics dataframe
2023-06-19 21:49:41,499:INFO:Uploading results into container
2023-06-19 21:49:41,499:INFO:Uploading model into container now
2023-06-19 21:49:41,500:INFO:_master_model_container: 4
2023-06-19 21:49:41,500:INFO:_display_container: 2
2023-06-19 21:49:41,500:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-06-19 21:49:41,500:INFO:create_model() successfully completed......................................
2023-06-19 21:49:41,570:INFO:SubProcess create_model() end ==================================
2023-06-19 21:49:41,570:INFO:Creating metrics dataframe
2023-06-19 21:49:41,580:INFO:Initializing SVM - Linear Kernel
2023-06-19 21:49:41,580:INFO:Total runtime is 0.2822197914123535 minutes
2023-06-19 21:49:41,583:INFO:SubProcess create_model() called ==================================
2023-06-19 21:49:41,583:INFO:Initializing create_model()
2023-06-19 21:49:41,584:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C750A1A550>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C73DEE2100>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 21:49:41,584:INFO:Checking exceptions
2023-06-19 21:49:41,584:INFO:Importing libraries
2023-06-19 21:49:41,584:INFO:Copying training dataset
2023-06-19 21:49:41,607:INFO:Defining folds
2023-06-19 21:49:41,608:INFO:Declaring metric variables
2023-06-19 21:49:41,612:INFO:Importing untrained model
2023-06-19 21:49:41,617:INFO:SVM - Linear Kernel Imported successfully
2023-06-19 21:49:41,624:INFO:Starting cross validation
2023-06-19 21:49:41,625:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 21:49:44,761:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-19 21:49:44,768:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 21:49:44,801:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-19 21:49:44,832:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-19 21:49:45,144:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-19 21:49:45,176:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-19 21:49:45,522:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-19 21:49:45,670:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-19 21:49:45,676:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 21:49:45,889:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-19 21:49:46,946:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-19 21:49:46,954:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-19 21:49:47,203:INFO:Calculating mean and std
2023-06-19 21:49:47,204:INFO:Creating metrics dataframe
2023-06-19 21:49:47,282:INFO:Uploading results into container
2023-06-19 21:49:47,283:INFO:Uploading model into container now
2023-06-19 21:49:47,283:INFO:_master_model_container: 5
2023-06-19 21:49:47,283:INFO:_display_container: 2
2023-06-19 21:49:47,283:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-06-19 21:49:47,283:INFO:create_model() successfully completed......................................
2023-06-19 21:49:47,351:INFO:SubProcess create_model() end ==================================
2023-06-19 21:49:47,351:INFO:Creating metrics dataframe
2023-06-19 21:49:47,360:INFO:Initializing Ridge Classifier
2023-06-19 21:49:47,360:INFO:Total runtime is 0.3785590847333272 minutes
2023-06-19 21:49:47,363:INFO:SubProcess create_model() called ==================================
2023-06-19 21:49:47,365:INFO:Initializing create_model()
2023-06-19 21:49:47,365:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C750A1A550>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C73DEE2100>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 21:49:47,365:INFO:Checking exceptions
2023-06-19 21:49:47,365:INFO:Importing libraries
2023-06-19 21:49:47,365:INFO:Copying training dataset
2023-06-19 21:49:47,388:INFO:Defining folds
2023-06-19 21:49:47,388:INFO:Declaring metric variables
2023-06-19 21:49:47,392:INFO:Importing untrained model
2023-06-19 21:49:47,397:INFO:Ridge Classifier Imported successfully
2023-06-19 21:49:47,404:INFO:Starting cross validation
2023-06-19 21:49:47,406:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 21:49:47,744:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.20058e-27): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-06-19 21:49:47,751:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.19001e-27): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-06-19 21:49:47,771:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.19001e-27): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-06-19 21:49:47,778:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.18974e-27): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-06-19 21:49:47,792:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.1987e-27): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-06-19 21:49:47,804:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.18863e-27): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-06-19 21:49:47,805:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.20029e-27): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-06-19 21:49:47,834:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-19 21:49:47,834:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-19 21:49:47,841:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-19 21:49:47,843:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 21:49:47,860:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-19 21:49:47,867:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 21:49:47,876:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-19 21:49:47,878:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-19 21:49:47,883:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 21:49:47,885:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 21:49:47,893:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-19 21:49:47,899:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 21:49:47,903:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-19 21:49:47,910:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 21:49:48,285:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.1916e-27): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-06-19 21:49:48,308:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.19751e-27): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-06-19 21:49:48,336:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-19 21:49:48,341:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 21:49:48,358:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-19 21:49:48,361:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 21:49:48,950:INFO:Calculating mean and std
2023-06-19 21:49:48,952:INFO:Creating metrics dataframe
2023-06-19 21:49:49,029:INFO:Uploading results into container
2023-06-19 21:49:49,030:INFO:Uploading model into container now
2023-06-19 21:49:49,030:INFO:_master_model_container: 6
2023-06-19 21:49:49,030:INFO:_display_container: 2
2023-06-19 21:49:49,031:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-06-19 21:49:49,031:INFO:create_model() successfully completed......................................
2023-06-19 21:49:49,097:INFO:SubProcess create_model() end ==================================
2023-06-19 21:49:49,097:INFO:Creating metrics dataframe
2023-06-19 21:49:49,106:INFO:Initializing Random Forest Classifier
2023-06-19 21:49:49,106:INFO:Total runtime is 0.40765996774037677 minutes
2023-06-19 21:49:49,111:INFO:SubProcess create_model() called ==================================
2023-06-19 21:49:49,111:INFO:Initializing create_model()
2023-06-19 21:49:49,111:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C750A1A550>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C73DEE2100>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 21:49:49,111:INFO:Checking exceptions
2023-06-19 21:49:49,111:INFO:Importing libraries
2023-06-19 21:49:49,112:INFO:Copying training dataset
2023-06-19 21:49:49,133:INFO:Defining folds
2023-06-19 21:49:49,133:INFO:Declaring metric variables
2023-06-19 21:49:49,137:INFO:Importing untrained model
2023-06-19 21:49:49,144:INFO:Random Forest Classifier Imported successfully
2023-06-19 21:49:49,153:INFO:Starting cross validation
2023-06-19 21:49:49,154:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 21:49:54,007:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 21:49:54,200:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 21:49:54,310:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 21:49:55,659:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-06-19 21:49:56,800:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 21:49:56,833:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 21:49:56,845:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 21:50:00,645:INFO:Calculating mean and std
2023-06-19 21:50:00,646:INFO:Creating metrics dataframe
2023-06-19 21:50:00,734:INFO:Uploading results into container
2023-06-19 21:50:00,735:INFO:Uploading model into container now
2023-06-19 21:50:00,735:INFO:_master_model_container: 7
2023-06-19 21:50:00,735:INFO:_display_container: 2
2023-06-19 21:50:00,736:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-19 21:50:00,736:INFO:create_model() successfully completed......................................
2023-06-19 21:50:00,811:INFO:SubProcess create_model() end ==================================
2023-06-19 21:50:00,811:INFO:Creating metrics dataframe
2023-06-19 21:50:00,819:INFO:Initializing Quadratic Discriminant Analysis
2023-06-19 21:50:00,820:INFO:Total runtime is 0.6028985977172852 minutes
2023-06-19 21:50:00,826:INFO:SubProcess create_model() called ==================================
2023-06-19 21:50:00,826:INFO:Initializing create_model()
2023-06-19 21:50:00,826:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C750A1A550>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C73DEE2100>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 21:50:00,826:INFO:Checking exceptions
2023-06-19 21:50:00,827:INFO:Importing libraries
2023-06-19 21:50:00,827:INFO:Copying training dataset
2023-06-19 21:50:00,848:INFO:Defining folds
2023-06-19 21:50:00,849:INFO:Declaring metric variables
2023-06-19 21:50:00,853:INFO:Importing untrained model
2023-06-19 21:50:00,857:INFO:Quadratic Discriminant Analysis Imported successfully
2023-06-19 21:50:00,866:INFO:Starting cross validation
2023-06-19 21:50:00,868:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 21:50:02,928:INFO:Calculating mean and std
2023-06-19 21:50:02,930:INFO:Creating metrics dataframe
2023-06-19 21:50:03,037:INFO:Uploading results into container
2023-06-19 21:50:03,038:INFO:Uploading model into container now
2023-06-19 21:50:03,039:INFO:_master_model_container: 8
2023-06-19 21:50:03,039:INFO:_display_container: 2
2023-06-19 21:50:03,040:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-06-19 21:50:03,040:INFO:create_model() successfully completed......................................
2023-06-19 21:50:03,121:INFO:SubProcess create_model() end ==================================
2023-06-19 21:50:03,123:INFO:Creating metrics dataframe
2023-06-19 21:50:03,132:INFO:Initializing Ada Boost Classifier
2023-06-19 21:50:03,132:INFO:Total runtime is 0.6414221247037252 minutes
2023-06-19 21:50:03,137:INFO:SubProcess create_model() called ==================================
2023-06-19 21:50:03,137:INFO:Initializing create_model()
2023-06-19 21:50:03,137:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C750A1A550>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C73DEE2100>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 21:50:03,137:INFO:Checking exceptions
2023-06-19 21:50:03,137:INFO:Importing libraries
2023-06-19 21:50:03,137:INFO:Copying training dataset
2023-06-19 21:50:03,163:INFO:Defining folds
2023-06-19 21:50:03,164:INFO:Declaring metric variables
2023-06-19 21:50:03,169:INFO:Importing untrained model
2023-06-19 21:50:03,175:INFO:Ada Boost Classifier Imported successfully
2023-06-19 21:50:03,184:INFO:Starting cross validation
2023-06-19 21:50:03,185:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 21:50:10,574:INFO:Calculating mean and std
2023-06-19 21:50:10,576:INFO:Creating metrics dataframe
2023-06-19 21:50:10,668:INFO:Uploading results into container
2023-06-19 21:50:10,669:INFO:Uploading model into container now
2023-06-19 21:50:10,670:INFO:_master_model_container: 9
2023-06-19 21:50:10,670:INFO:_display_container: 2
2023-06-19 21:50:10,670:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-06-19 21:50:10,670:INFO:create_model() successfully completed......................................
2023-06-19 21:50:10,743:INFO:SubProcess create_model() end ==================================
2023-06-19 21:50:10,743:INFO:Creating metrics dataframe
2023-06-19 21:50:10,754:INFO:Initializing Gradient Boosting Classifier
2023-06-19 21:50:10,755:INFO:Total runtime is 0.7684749921162923 minutes
2023-06-19 21:50:10,759:INFO:SubProcess create_model() called ==================================
2023-06-19 21:50:10,759:INFO:Initializing create_model()
2023-06-19 21:50:10,759:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C750A1A550>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C73DEE2100>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 21:50:10,760:INFO:Checking exceptions
2023-06-19 21:50:10,760:INFO:Importing libraries
2023-06-19 21:50:10,760:INFO:Copying training dataset
2023-06-19 21:50:10,784:INFO:Defining folds
2023-06-19 21:50:10,785:INFO:Declaring metric variables
2023-06-19 21:50:10,789:INFO:Importing untrained model
2023-06-19 21:50:10,794:INFO:Gradient Boosting Classifier Imported successfully
2023-06-19 21:50:10,802:INFO:Starting cross validation
2023-06-19 21:50:10,804:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 21:50:34,691:INFO:Calculating mean and std
2023-06-19 21:50:34,692:INFO:Creating metrics dataframe
2023-06-19 21:50:34,789:INFO:Uploading results into container
2023-06-19 21:50:34,790:INFO:Uploading model into container now
2023-06-19 21:50:34,790:INFO:_master_model_container: 10
2023-06-19 21:50:34,790:INFO:_display_container: 2
2023-06-19 21:50:34,791:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-19 21:50:34,791:INFO:create_model() successfully completed......................................
2023-06-19 21:50:34,856:INFO:SubProcess create_model() end ==================================
2023-06-19 21:50:34,856:INFO:Creating metrics dataframe
2023-06-19 21:50:34,865:INFO:Initializing Linear Discriminant Analysis
2023-06-19 21:50:34,866:INFO:Total runtime is 1.1703133304913838 minutes
2023-06-19 21:50:34,870:INFO:SubProcess create_model() called ==================================
2023-06-19 21:50:34,871:INFO:Initializing create_model()
2023-06-19 21:50:34,871:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C750A1A550>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C73DEE2100>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 21:50:34,871:INFO:Checking exceptions
2023-06-19 21:50:34,871:INFO:Importing libraries
2023-06-19 21:50:34,871:INFO:Copying training dataset
2023-06-19 21:50:34,894:INFO:Defining folds
2023-06-19 21:50:34,895:INFO:Declaring metric variables
2023-06-19 21:50:34,898:INFO:Importing untrained model
2023-06-19 21:50:34,902:INFO:Linear Discriminant Analysis Imported successfully
2023-06-19 21:50:34,910:INFO:Starting cross validation
2023-06-19 21:50:34,912:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 21:50:37,329:INFO:Calculating mean and std
2023-06-19 21:50:37,330:INFO:Creating metrics dataframe
2023-06-19 21:50:37,431:INFO:Uploading results into container
2023-06-19 21:50:37,433:INFO:Uploading model into container now
2023-06-19 21:50:37,434:INFO:_master_model_container: 11
2023-06-19 21:50:37,434:INFO:_display_container: 2
2023-06-19 21:50:37,434:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-06-19 21:50:37,434:INFO:create_model() successfully completed......................................
2023-06-19 21:50:37,503:INFO:SubProcess create_model() end ==================================
2023-06-19 21:50:37,503:INFO:Creating metrics dataframe
2023-06-19 21:50:37,513:INFO:Initializing Extra Trees Classifier
2023-06-19 21:50:37,513:INFO:Total runtime is 1.214445646603902 minutes
2023-06-19 21:50:37,516:INFO:SubProcess create_model() called ==================================
2023-06-19 21:50:37,517:INFO:Initializing create_model()
2023-06-19 21:50:37,517:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C750A1A550>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C73DEE2100>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 21:50:37,517:INFO:Checking exceptions
2023-06-19 21:50:37,517:INFO:Importing libraries
2023-06-19 21:50:37,517:INFO:Copying training dataset
2023-06-19 21:50:37,540:INFO:Defining folds
2023-06-19 21:50:37,541:INFO:Declaring metric variables
2023-06-19 21:50:37,545:INFO:Importing untrained model
2023-06-19 21:50:37,549:INFO:Extra Trees Classifier Imported successfully
2023-06-19 21:50:37,557:INFO:Starting cross validation
2023-06-19 21:50:37,559:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 21:50:41,616:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 21:50:41,798:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 21:50:45,839:INFO:Calculating mean and std
2023-06-19 21:50:45,840:INFO:Creating metrics dataframe
2023-06-19 21:50:45,986:INFO:Uploading results into container
2023-06-19 21:50:45,987:INFO:Uploading model into container now
2023-06-19 21:50:45,987:INFO:_master_model_container: 12
2023-06-19 21:50:45,987:INFO:_display_container: 2
2023-06-19 21:50:45,987:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-06-19 21:50:45,987:INFO:create_model() successfully completed......................................
2023-06-19 21:50:46,055:INFO:SubProcess create_model() end ==================================
2023-06-19 21:50:46,056:INFO:Creating metrics dataframe
2023-06-19 21:50:46,067:INFO:Initializing Light Gradient Boosting Machine
2023-06-19 21:50:46,067:INFO:Total runtime is 1.3570143739382423 minutes
2023-06-19 21:50:46,072:INFO:SubProcess create_model() called ==================================
2023-06-19 21:50:46,072:INFO:Initializing create_model()
2023-06-19 21:50:46,072:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C750A1A550>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C73DEE2100>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 21:50:46,072:INFO:Checking exceptions
2023-06-19 21:50:46,074:INFO:Importing libraries
2023-06-19 21:50:46,074:INFO:Copying training dataset
2023-06-19 21:50:46,095:INFO:Defining folds
2023-06-19 21:50:46,095:INFO:Declaring metric variables
2023-06-19 21:50:46,099:INFO:Importing untrained model
2023-06-19 21:50:46,103:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-19 21:50:46,111:INFO:Starting cross validation
2023-06-19 21:50:46,113:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 21:50:50,562:INFO:Calculating mean and std
2023-06-19 21:50:50,563:INFO:Creating metrics dataframe
2023-06-19 21:50:50,690:INFO:Uploading results into container
2023-06-19 21:50:50,691:INFO:Uploading model into container now
2023-06-19 21:50:50,691:INFO:_master_model_container: 13
2023-06-19 21:50:50,691:INFO:_display_container: 2
2023-06-19 21:50:50,691:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-19 21:50:50,691:INFO:create_model() successfully completed......................................
2023-06-19 21:50:50,758:INFO:SubProcess create_model() end ==================================
2023-06-19 21:50:50,758:INFO:Creating metrics dataframe
2023-06-19 21:50:50,773:INFO:Initializing Dummy Classifier
2023-06-19 21:50:50,773:INFO:Total runtime is 1.4354402383168536 minutes
2023-06-19 21:50:50,776:INFO:SubProcess create_model() called ==================================
2023-06-19 21:50:50,777:INFO:Initializing create_model()
2023-06-19 21:50:50,777:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C750A1A550>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C73DEE2100>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 21:50:50,777:INFO:Checking exceptions
2023-06-19 21:50:50,777:INFO:Importing libraries
2023-06-19 21:50:50,777:INFO:Copying training dataset
2023-06-19 21:50:50,797:INFO:Defining folds
2023-06-19 21:50:50,798:INFO:Declaring metric variables
2023-06-19 21:50:50,802:INFO:Importing untrained model
2023-06-19 21:50:50,806:INFO:Dummy Classifier Imported successfully
2023-06-19 21:50:50,813:INFO:Starting cross validation
2023-06-19 21:50:50,815:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 21:50:51,277:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 21:50:51,317:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 21:50:51,325:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 21:50:51,348:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 21:50:51,351:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 21:50:51,369:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 21:50:51,380:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 21:50:51,453:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 21:50:52,056:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 21:50:52,073:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 21:50:53,042:INFO:Calculating mean and std
2023-06-19 21:50:53,043:INFO:Creating metrics dataframe
2023-06-19 21:50:53,174:INFO:Uploading results into container
2023-06-19 21:50:53,174:INFO:Uploading model into container now
2023-06-19 21:50:53,175:INFO:_master_model_container: 14
2023-06-19 21:50:53,175:INFO:_display_container: 2
2023-06-19 21:50:53,175:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-06-19 21:50:53,175:INFO:create_model() successfully completed......................................
2023-06-19 21:50:53,242:INFO:SubProcess create_model() end ==================================
2023-06-19 21:50:53,242:INFO:Creating metrics dataframe
2023-06-19 21:50:53,267:INFO:Initializing create_model()
2023-06-19 21:50:53,268:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C750A1A550>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-19 21:50:53,268:INFO:Checking exceptions
2023-06-19 21:50:53,270:INFO:Importing libraries
2023-06-19 21:50:53,271:INFO:Copying training dataset
2023-06-19 21:50:53,291:INFO:Defining folds
2023-06-19 21:50:53,291:INFO:Declaring metric variables
2023-06-19 21:50:53,291:INFO:Importing untrained model
2023-06-19 21:50:53,291:INFO:Declaring custom model
2023-06-19 21:50:53,292:INFO:Random Forest Classifier Imported successfully
2023-06-19 21:50:53,292:INFO:Cross validation set to False
2023-06-19 21:50:53,293:INFO:Fitting Model
2023-06-19 21:50:55,026:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-19 21:50:55,026:INFO:create_model() successfully completed......................................
2023-06-19 21:50:55,135:INFO:_master_model_container: 14
2023-06-19 21:50:55,136:INFO:_display_container: 2
2023-06-19 21:50:55,136:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-19 21:50:55,136:INFO:compare_models() successfully completed......................................
2023-06-19 21:51:14,452:INFO:Initializing create_model()
2023-06-19 21:51:14,452:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C750A1A550>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-19 21:51:14,452:INFO:Checking exceptions
2023-06-19 21:51:14,489:INFO:Importing libraries
2023-06-19 21:51:14,490:INFO:Copying training dataset
2023-06-19 21:51:14,518:INFO:Defining folds
2023-06-19 21:51:14,518:INFO:Declaring metric variables
2023-06-19 21:51:14,543:INFO:Importing untrained model
2023-06-19 21:51:14,548:INFO:Random Forest Classifier Imported successfully
2023-06-19 21:51:14,559:INFO:Starting cross validation
2023-06-19 21:51:14,561:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 21:51:17,269:INFO:Calculating mean and std
2023-06-19 21:51:17,270:INFO:Creating metrics dataframe
2023-06-19 21:51:17,277:INFO:Finalizing model
2023-06-19 21:51:17,627:INFO:Uploading results into container
2023-06-19 21:51:17,628:INFO:Uploading model into container now
2023-06-19 21:51:17,639:INFO:_master_model_container: 15
2023-06-19 21:51:17,639:INFO:_display_container: 3
2023-06-19 21:51:17,640:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-19 21:51:17,640:INFO:create_model() successfully completed......................................
2023-06-19 21:51:17,726:INFO:Initializing predict_model()
2023-06-19 21:51:17,726:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C750A1A550>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001C75355E3A0>)
2023-06-19 21:51:17,726:INFO:Checking exceptions
2023-06-19 21:51:17,726:INFO:Preloading libraries
2023-06-19 21:51:17,729:INFO:Set up data.
2023-06-19 21:51:17,750:INFO:Set up index.
2023-06-19 22:01:19,464:INFO:Initializing tune_model()
2023-06-19 22:01:19,464:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C750A1A550>)
2023-06-19 22:01:19,465:INFO:Checking exceptions
2023-06-19 22:01:19,521:INFO:Copying training dataset
2023-06-19 22:01:19,542:INFO:Checking base model
2023-06-19 22:01:19,542:INFO:Base model : Random Forest Classifier
2023-06-19 22:01:19,550:INFO:Declaring metric variables
2023-06-19 22:01:19,554:INFO:Defining Hyperparameters
2023-06-19 22:01:19,719:INFO:Tuning with n_jobs=-1
2023-06-19 22:01:19,719:INFO:Initializing RandomizedSearchCV
2023-06-19 22:01:30,933:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:01:30,989:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:01:38,370:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:01:44,373:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:01:46,385:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:01:46,608:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:01:46,775:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:01:48,415:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:01:48,676:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:01:49,649:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:01:49,738:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:01:49,934:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:01:50,561:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:01:50,794:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:01:50,867:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:01:50,978:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:01:51,804:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:01:51,949:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:01:52,492:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:01:52,890:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:01:53,459:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:01:53,581:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:01:54,340:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:01:55,008:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:01:55,222:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:01:56,774:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:01:56,981:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:02:00,280:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:02:00,920:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:02:01,161:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-19 22:02:02,302:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:02:03,030:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:02:03,205:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:02:04,699:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:02:04,828:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:02:05,213:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:02:05,554:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:02:06,330:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:02:06,944:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:02:07,341:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:02:07,758:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:02:08,218:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-19 22:02:08,884:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.45s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:02:10,834:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:02:10,945:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:02:12,221:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:02:12,780:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:02:13,289:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:02:13,532:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:02:13,692:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:02:14,207:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:02:14,555:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:02:14,590:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:02:14,821:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:02:15,088:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:02:16,131:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:02:16,136:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:02:17,047:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:02:17,596:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:02:17,935:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:02:18,445:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:02:18,586:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:02:19,039:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:02:19,067:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:02:19,946:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:02:20,681:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:03:03,263:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:03:07,287:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:03:09,172:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:03:11,877:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:03:12,138:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:03:17,252:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:03:17,770:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:03:17,802:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:03:18,453:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:03:18,774:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:03:19,537:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:03:20,651:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:03:20,729:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:03:21,058:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:03:21,240:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:03:29,456:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:03:32,106:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:03:32,364:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:03:33,891:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:03:34,200:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:03:34,253:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:03:34,257:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:03:34,578:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:03:35,743:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:03:36,183:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:03:36,390:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:03:36,404:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:03:45,369:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:03:46,551:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:03:46,713:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:03:48,110:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:03:48,457:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.34s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:03:48,610:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:03:49,028:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:03:49,213:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:03:49,302:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:03:50,344:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:03:50,360:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:03:51,286:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:04:14,368:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:04:15,736:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:04:18,104:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:04:19,411:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:04:27,864:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-19 22:04:38,002:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:04:38,892:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:04:39,865:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:04:41,163:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:04:41,372:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.27s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:04:41,725:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:04:41,813:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:04:42,239:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:04:42,344:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.31s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:04:43,722:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:04:44,462:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:04:44,718:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:04:54,864:INFO:best_params: {'actual_estimator__n_estimators': 150, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.0002, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 5, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': False}
2023-06-19 22:04:54,865:INFO:Hyperparameter search completed
2023-06-19 22:04:54,866:INFO:SubProcess create_model() called ==================================
2023-06-19 22:04:54,867:INFO:Initializing create_model()
2023-06-19 22:04:54,867:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C750A1A550>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C750A1A790>, model_only=True, return_train_score=False, kwargs={'n_estimators': 150, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.0002, 'max_features': 1.0, 'max_depth': 5, 'criterion': 'entropy', 'class_weight': {}, 'bootstrap': False})
2023-06-19 22:04:54,867:INFO:Checking exceptions
2023-06-19 22:04:54,867:INFO:Importing libraries
2023-06-19 22:04:54,868:INFO:Copying training dataset
2023-06-19 22:04:54,911:INFO:Defining folds
2023-06-19 22:04:54,911:INFO:Declaring metric variables
2023-06-19 22:04:54,916:INFO:Importing untrained model
2023-06-19 22:04:54,916:INFO:Declaring custom model
2023-06-19 22:04:54,921:INFO:Random Forest Classifier Imported successfully
2023-06-19 22:04:54,931:INFO:Starting cross validation
2023-06-19 22:04:54,933:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 22:04:56,468:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:04:56,490:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:05:01,042:INFO:Calculating mean and std
2023-06-19 22:05:01,043:INFO:Creating metrics dataframe
2023-06-19 22:05:01,051:INFO:Finalizing model
2023-06-19 22:05:09,790:INFO:Uploading results into container
2023-06-19 22:05:09,791:INFO:Uploading model into container now
2023-06-19 22:05:09,792:INFO:_master_model_container: 16
2023-06-19 22:05:09,793:INFO:_display_container: 5
2023-06-19 22:05:09,793:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=5, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0002, min_samples_leaf=5,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       n_estimators=150, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-19 22:05:09,793:INFO:create_model() successfully completed......................................
2023-06-19 22:05:09,885:INFO:SubProcess create_model() end ==================================
2023-06-19 22:05:09,895:INFO:choose_better activated
2023-06-19 22:05:09,899:INFO:SubProcess create_model() called ==================================
2023-06-19 22:05:09,900:INFO:Initializing create_model()
2023-06-19 22:05:09,901:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C750A1A550>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-19 22:05:09,901:INFO:Checking exceptions
2023-06-19 22:05:09,904:INFO:Importing libraries
2023-06-19 22:05:09,905:INFO:Copying training dataset
2023-06-19 22:05:09,930:INFO:Defining folds
2023-06-19 22:05:09,930:INFO:Declaring metric variables
2023-06-19 22:05:09,930:INFO:Importing untrained model
2023-06-19 22:05:09,930:INFO:Declaring custom model
2023-06-19 22:05:09,931:INFO:Random Forest Classifier Imported successfully
2023-06-19 22:05:09,931:INFO:Starting cross validation
2023-06-19 22:05:09,933:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 22:05:11,180:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:05:11,410:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:05:14,996:INFO:Calculating mean and std
2023-06-19 22:05:14,996:INFO:Creating metrics dataframe
2023-06-19 22:05:14,998:INFO:Finalizing model
2023-06-19 22:05:15,563:INFO:Uploading results into container
2023-06-19 22:05:15,564:INFO:Uploading model into container now
2023-06-19 22:05:15,564:INFO:_master_model_container: 17
2023-06-19 22:05:15,564:INFO:_display_container: 6
2023-06-19 22:05:15,565:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-19 22:05:15,565:INFO:create_model() successfully completed......................................
2023-06-19 22:05:15,645:INFO:SubProcess create_model() end ==================================
2023-06-19 22:05:15,646:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) result for Accuracy is 0.9883
2023-06-19 22:05:15,646:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=5, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0002, min_samples_leaf=5,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       n_estimators=150, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) result for Accuracy is 0.943
2023-06-19 22:05:15,647:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) is best model
2023-06-19 22:05:15,647:INFO:choose_better completed
2023-06-19 22:05:15,647:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-06-19 22:05:15,659:INFO:_master_model_container: 17
2023-06-19 22:05:15,659:INFO:_display_container: 5
2023-06-19 22:05:15,660:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-19 22:05:15,660:INFO:tune_model() successfully completed......................................
2023-06-19 22:05:42,592:INFO:Initializing predict_model()
2023-06-19 22:05:42,592:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C750A1A550>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001C751D2AC10>)
2023-06-19 22:05:42,592:INFO:Checking exceptions
2023-06-19 22:05:42,593:INFO:Preloading libraries
2023-06-19 22:05:42,594:INFO:Set up data.
2023-06-19 22:05:42,619:INFO:Set up index.
2023-06-19 22:28:12,833:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-19 22:28:12,833:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-19 22:28:12,833:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-19 22:28:12,833:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-19 22:28:13,708:INFO:Soft dependency imported: prophet: 1.1.4
2023-06-19 22:28:14,128:INFO:PyCaret ClassificationExperiment
2023-06-19 22:28:14,128:INFO:Logging name: clf-default-name
2023-06-19 22:28:14,128:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-19 22:28:14,128:INFO:version 3.0.2
2023-06-19 22:28:14,128:INFO:Initializing setup()
2023-06-19 22:28:14,128:INFO:self.USI: 1a69
2023-06-19 22:28:14,129:INFO:self._variable_keys: {'gpu_param', 'fold_shuffle_param', 'X', 'seed', 'idx', 'memory', 'logging_param', 'log_plots_param', 'y_train', '_ml_usecase', 'pipeline', 'y_test', 'fold_groups_param', 'X_test', 'target_param', 'html_param', 'n_jobs_param', 'fix_imbalance', '_available_plots', 'X_train', 'exp_id', 'y', 'exp_name_log', 'fold_generator', 'is_multiclass', 'USI', 'data', 'gpu_n_jobs_param'}
2023-06-19 22:28:14,129:INFO:Checking environment
2023-06-19 22:28:14,129:INFO:python_version: 3.8.12
2023-06-19 22:28:14,129:INFO:python_build: ('default', 'Oct 12 2021 03:01:40')
2023-06-19 22:28:14,129:INFO:machine: AMD64
2023-06-19 22:28:14,129:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-19 22:28:14,129:INFO:Memory: svmem(total=16861405184, available=4199063552, percent=75.1, used=12662341632, free=4199063552)
2023-06-19 22:28:14,129:INFO:Physical Core: 4
2023-06-19 22:28:14,129:INFO:Logical Core: 8
2023-06-19 22:28:14,129:INFO:Checking libraries
2023-06-19 22:28:14,130:INFO:System:
2023-06-19 22:28:14,130:INFO:    python: 3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]
2023-06-19 22:28:14,130:INFO:executable: c:\Users\choib\anaconda3\envs\iise-python\python.exe
2023-06-19 22:28:14,130:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-19 22:28:14,130:INFO:PyCaret required dependencies:
2023-06-19 22:28:14,130:INFO:                 pip: 21.0.1
2023-06-19 22:28:14,130:INFO:          setuptools: 58.0.4
2023-06-19 22:28:14,130:INFO:             pycaret: 3.0.2
2023-06-19 22:28:14,130:INFO:             IPython: 8.12.0
2023-06-19 22:28:14,130:INFO:          ipywidgets: 8.0.6
2023-06-19 22:28:14,130:INFO:                tqdm: 4.65.0
2023-06-19 22:28:14,130:INFO:               numpy: 1.21.4
2023-06-19 22:28:14,130:INFO:              pandas: 1.5.3
2023-06-19 22:28:14,130:INFO:              jinja2: 3.1.2
2023-06-19 22:28:14,130:INFO:               scipy: 1.10.1
2023-06-19 22:28:14,130:INFO:              joblib: 1.2.0
2023-06-19 22:28:14,130:INFO:             sklearn: 1.2.2
2023-06-19 22:28:14,130:INFO:                pyod: 1.0.9
2023-06-19 22:28:14,130:INFO:            imblearn: 0.10.1
2023-06-19 22:28:14,131:INFO:   category_encoders: 2.6.1
2023-06-19 22:28:14,131:INFO:            lightgbm: 3.3.5
2023-06-19 22:28:14,131:INFO:               numba: 0.57.0
2023-06-19 22:28:14,131:INFO:            requests: 2.31.0
2023-06-19 22:28:14,131:INFO:          matplotlib: 3.4.3
2023-06-19 22:28:14,131:INFO:          scikitplot: 0.3.7
2023-06-19 22:28:14,131:INFO:         yellowbrick: 1.5
2023-06-19 22:28:14,131:INFO:              plotly: 5.15.0
2023-06-19 22:28:14,131:INFO:             kaleido: 0.2.1
2023-06-19 22:28:14,131:INFO:         statsmodels: 0.14.0
2023-06-19 22:28:14,131:INFO:              sktime: 0.17.0
2023-06-19 22:28:14,131:INFO:               tbats: 1.1.3
2023-06-19 22:28:14,131:INFO:            pmdarima: 2.0.3
2023-06-19 22:28:14,131:INFO:              psutil: 5.9.0
2023-06-19 22:28:14,131:INFO:PyCaret optional dependencies:
2023-06-19 22:28:14,154:INFO:                shap: Not installed
2023-06-19 22:28:14,154:INFO:           interpret: Not installed
2023-06-19 22:28:14,154:INFO:                umap: Not installed
2023-06-19 22:28:14,154:INFO:    pandas_profiling: Not installed
2023-06-19 22:28:14,154:INFO:  explainerdashboard: Not installed
2023-06-19 22:28:14,154:INFO:             autoviz: Not installed
2023-06-19 22:28:14,154:INFO:           fairlearn: Not installed
2023-06-19 22:28:14,154:INFO:             xgboost: Not installed
2023-06-19 22:28:14,154:INFO:            catboost: Not installed
2023-06-19 22:28:14,154:INFO:              kmodes: Not installed
2023-06-19 22:28:14,154:INFO:             mlxtend: Not installed
2023-06-19 22:28:14,154:INFO:       statsforecast: Not installed
2023-06-19 22:28:14,154:INFO:        tune_sklearn: Not installed
2023-06-19 22:28:14,154:INFO:                 ray: Not installed
2023-06-19 22:28:14,155:INFO:            hyperopt: Not installed
2023-06-19 22:28:14,155:INFO:              optuna: Not installed
2023-06-19 22:28:14,155:INFO:               skopt: Not installed
2023-06-19 22:28:14,155:INFO:              mlflow: Not installed
2023-06-19 22:28:14,155:INFO:              gradio: Not installed
2023-06-19 22:28:14,155:INFO:             fastapi: Not installed
2023-06-19 22:28:14,155:INFO:             uvicorn: Not installed
2023-06-19 22:28:14,155:INFO:              m2cgen: Not installed
2023-06-19 22:28:14,155:INFO:           evidently: Not installed
2023-06-19 22:28:14,155:INFO:               fugue: Not installed
2023-06-19 22:28:14,155:INFO:           streamlit: Not installed
2023-06-19 22:28:14,155:INFO:             prophet: 1.1.4
2023-06-19 22:28:14,155:INFO:None
2023-06-19 22:28:14,155:INFO:Set up data.
2023-06-19 22:28:14,181:INFO:Set up train/test split.
2023-06-19 22:28:14,203:INFO:Set up index.
2023-06-19 22:28:14,204:INFO:Set up folding strategy.
2023-06-19 22:28:14,204:INFO:Assigning column types.
2023-06-19 22:28:14,218:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-19 22:28:14,263:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-19 22:28:14,267:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-19 22:28:14,311:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 22:28:14,327:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 22:28:14,365:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-19 22:28:14,366:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-19 22:28:14,393:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 22:28:14,393:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 22:28:14,394:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-19 22:28:14,440:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-19 22:28:14,469:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 22:28:14,469:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 22:28:14,516:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-19 22:28:14,541:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 22:28:14,542:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 22:28:14,542:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-19 22:28:14,666:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 22:28:14,666:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 22:28:14,743:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 22:28:14,744:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 22:28:14,746:INFO:Preparing preprocessing pipeline...
2023-06-19 22:28:14,750:INFO:Set up simple imputation.
2023-06-19 22:28:14,760:INFO:Set up encoding of categorical features.
2023-06-19 22:28:14,938:INFO:Finished creating preprocessing pipeline.
2023-06-19 22:28:14,946:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\choib\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['disk_id', 'r_1', 'n_5', 'r_5',
                                             'r_9', 'r_12', 'n_171', 'r_171',
                                             'n_172', 'r_172', 'n_173', 'r_174',
                                             'n_180', 'r_180', 'n_184', 'r_184',
                                             'r_187', 'r_188', 'n_190', 'r_190',
                                             'r_194', 'r_195', 'n_196', 'r_196',
                                             'r_197', 'r_198', 'r...
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['ds'],
                                    transformer=TargetEncoder(cols=['ds'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2023-06-19 22:28:14,946:INFO:Creating final display dataframe.
2023-06-19 22:28:15,329:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             label
2                   Target type            Binary
3           Original data shape       (37002, 31)
4        Transformed data shape       (37002, 31)
5   Transformed train set shape       (25901, 31)
6    Transformed test set shape       (11101, 31)
7              Numeric features                29
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                 5
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              1a69
2023-06-19 22:28:15,412:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 22:28:15,412:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 22:28:15,493:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 22:28:15,494:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 22:28:15,495:INFO:setup() successfully completed in 1.59s...............
2023-06-19 22:28:15,495:INFO:Initializing compare_models()
2023-06-19 22:28:15,495:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001462B5355E0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001462B5355E0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-06-19 22:28:15,495:INFO:Checking exceptions
2023-06-19 22:28:15,506:INFO:Preparing display monitor
2023-06-19 22:28:15,557:INFO:Initializing Logistic Regression
2023-06-19 22:28:15,557:INFO:Total runtime is 0.0 minutes
2023-06-19 22:28:15,563:INFO:SubProcess create_model() called ==================================
2023-06-19 22:28:15,563:INFO:Initializing create_model()
2023-06-19 22:28:15,563:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001462B5355E0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001462C7E2430>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 22:28:15,563:INFO:Checking exceptions
2023-06-19 22:28:15,563:INFO:Importing libraries
2023-06-19 22:28:15,563:INFO:Copying training dataset
2023-06-19 22:28:15,584:INFO:Defining folds
2023-06-19 22:28:15,584:INFO:Declaring metric variables
2023-06-19 22:28:15,587:INFO:Importing untrained model
2023-06-19 22:28:15,593:INFO:Logistic Regression Imported successfully
2023-06-19 22:28:15,600:INFO:Starting cross validation
2023-06-19 22:28:15,602:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 22:28:21,548:INFO:Calculating mean and std
2023-06-19 22:28:21,549:INFO:Creating metrics dataframe
2023-06-19 22:28:21,837:INFO:Uploading results into container
2023-06-19 22:28:21,837:INFO:Uploading model into container now
2023-06-19 22:28:21,838:INFO:_master_model_container: 1
2023-06-19 22:28:21,838:INFO:_display_container: 2
2023-06-19 22:28:21,839:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-06-19 22:28:21,839:INFO:create_model() successfully completed......................................
2023-06-19 22:28:21,913:INFO:SubProcess create_model() end ==================================
2023-06-19 22:28:21,913:INFO:Creating metrics dataframe
2023-06-19 22:28:21,923:INFO:Initializing K Neighbors Classifier
2023-06-19 22:28:21,923:INFO:Total runtime is 0.10610626141230266 minutes
2023-06-19 22:28:21,927:INFO:SubProcess create_model() called ==================================
2023-06-19 22:28:21,927:INFO:Initializing create_model()
2023-06-19 22:28:21,927:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001462B5355E0>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001462C7E2430>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 22:28:21,928:INFO:Checking exceptions
2023-06-19 22:28:21,928:INFO:Importing libraries
2023-06-19 22:28:21,928:INFO:Copying training dataset
2023-06-19 22:28:21,946:INFO:Defining folds
2023-06-19 22:28:21,946:INFO:Declaring metric variables
2023-06-19 22:28:21,949:INFO:Importing untrained model
2023-06-19 22:28:21,952:INFO:K Neighbors Classifier Imported successfully
2023-06-19 22:28:21,958:INFO:Starting cross validation
2023-06-19 22:28:21,959:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 22:28:27,735:INFO:Calculating mean and std
2023-06-19 22:28:27,736:INFO:Creating metrics dataframe
2023-06-19 22:28:28,019:INFO:Uploading results into container
2023-06-19 22:28:28,020:INFO:Uploading model into container now
2023-06-19 22:28:28,021:INFO:_master_model_container: 2
2023-06-19 22:28:28,021:INFO:_display_container: 2
2023-06-19 22:28:28,022:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-06-19 22:28:28,023:INFO:create_model() successfully completed......................................
2023-06-19 22:28:28,107:INFO:SubProcess create_model() end ==================================
2023-06-19 22:28:28,108:INFO:Creating metrics dataframe
2023-06-19 22:28:28,116:INFO:Initializing Naive Bayes
2023-06-19 22:28:28,116:INFO:Total runtime is 0.2093202829360962 minutes
2023-06-19 22:28:28,120:INFO:SubProcess create_model() called ==================================
2023-06-19 22:28:28,121:INFO:Initializing create_model()
2023-06-19 22:28:28,121:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001462B5355E0>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001462C7E2430>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 22:28:28,121:INFO:Checking exceptions
2023-06-19 22:28:28,121:INFO:Importing libraries
2023-06-19 22:28:28,121:INFO:Copying training dataset
2023-06-19 22:28:28,146:INFO:Defining folds
2023-06-19 22:28:28,147:INFO:Declaring metric variables
2023-06-19 22:28:28,151:INFO:Importing untrained model
2023-06-19 22:28:28,158:INFO:Naive Bayes Imported successfully
2023-06-19 22:28:28,167:INFO:Starting cross validation
2023-06-19 22:28:28,168:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 22:28:29,977:INFO:Calculating mean and std
2023-06-19 22:28:29,978:INFO:Creating metrics dataframe
2023-06-19 22:28:30,301:INFO:Uploading results into container
2023-06-19 22:28:30,302:INFO:Uploading model into container now
2023-06-19 22:28:30,302:INFO:_master_model_container: 3
2023-06-19 22:28:30,302:INFO:_display_container: 2
2023-06-19 22:28:30,303:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-06-19 22:28:30,303:INFO:create_model() successfully completed......................................
2023-06-19 22:28:30,382:INFO:SubProcess create_model() end ==================================
2023-06-19 22:28:30,383:INFO:Creating metrics dataframe
2023-06-19 22:28:30,395:INFO:Initializing Decision Tree Classifier
2023-06-19 22:28:30,395:INFO:Total runtime is 0.2472951650619507 minutes
2023-06-19 22:28:30,398:INFO:SubProcess create_model() called ==================================
2023-06-19 22:28:30,399:INFO:Initializing create_model()
2023-06-19 22:28:30,399:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001462B5355E0>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001462C7E2430>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 22:28:30,399:INFO:Checking exceptions
2023-06-19 22:28:30,399:INFO:Importing libraries
2023-06-19 22:28:30,399:INFO:Copying training dataset
2023-06-19 22:28:30,417:INFO:Defining folds
2023-06-19 22:28:30,417:INFO:Declaring metric variables
2023-06-19 22:28:30,422:INFO:Importing untrained model
2023-06-19 22:28:30,427:INFO:Decision Tree Classifier Imported successfully
2023-06-19 22:28:30,435:INFO:Starting cross validation
2023-06-19 22:28:30,437:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 22:28:32,618:INFO:Calculating mean and std
2023-06-19 22:28:32,619:INFO:Creating metrics dataframe
2023-06-19 22:28:32,908:INFO:Uploading results into container
2023-06-19 22:28:32,909:INFO:Uploading model into container now
2023-06-19 22:28:32,910:INFO:_master_model_container: 4
2023-06-19 22:28:32,910:INFO:_display_container: 2
2023-06-19 22:28:32,910:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-06-19 22:28:32,911:INFO:create_model() successfully completed......................................
2023-06-19 22:28:32,983:INFO:SubProcess create_model() end ==================================
2023-06-19 22:28:32,983:INFO:Creating metrics dataframe
2023-06-19 22:28:32,993:INFO:Initializing SVM - Linear Kernel
2023-06-19 22:28:32,993:INFO:Total runtime is 0.29059530099232994 minutes
2023-06-19 22:28:32,996:INFO:SubProcess create_model() called ==================================
2023-06-19 22:28:32,997:INFO:Initializing create_model()
2023-06-19 22:28:32,997:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001462B5355E0>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001462C7E2430>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 22:28:32,997:INFO:Checking exceptions
2023-06-19 22:28:32,997:INFO:Importing libraries
2023-06-19 22:28:32,997:INFO:Copying training dataset
2023-06-19 22:28:33,014:INFO:Defining folds
2023-06-19 22:28:33,014:INFO:Declaring metric variables
2023-06-19 22:28:33,018:INFO:Importing untrained model
2023-06-19 22:28:33,023:INFO:SVM - Linear Kernel Imported successfully
2023-06-19 22:28:33,031:INFO:Starting cross validation
2023-06-19 22:28:33,032:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 22:28:34,326:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-19 22:28:34,333:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 22:28:34,392:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-19 22:28:34,399:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-19 22:28:34,407:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 22:28:34,477:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-19 22:28:34,483:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 22:28:34,545:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-19 22:28:34,551:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 22:28:35,690:INFO:Calculating mean and std
2023-06-19 22:28:35,691:INFO:Creating metrics dataframe
2023-06-19 22:28:35,989:INFO:Uploading results into container
2023-06-19 22:28:35,989:INFO:Uploading model into container now
2023-06-19 22:28:35,990:INFO:_master_model_container: 5
2023-06-19 22:28:35,990:INFO:_display_container: 2
2023-06-19 22:28:35,990:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-06-19 22:28:35,990:INFO:create_model() successfully completed......................................
2023-06-19 22:28:36,059:INFO:SubProcess create_model() end ==================================
2023-06-19 22:28:36,059:INFO:Creating metrics dataframe
2023-06-19 22:28:36,072:INFO:Initializing Ridge Classifier
2023-06-19 22:28:36,072:INFO:Total runtime is 0.3419219215710958 minutes
2023-06-19 22:28:36,075:INFO:SubProcess create_model() called ==================================
2023-06-19 22:28:36,076:INFO:Initializing create_model()
2023-06-19 22:28:36,076:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001462B5355E0>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001462C7E2430>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 22:28:36,076:INFO:Checking exceptions
2023-06-19 22:28:36,076:INFO:Importing libraries
2023-06-19 22:28:36,076:INFO:Copying training dataset
2023-06-19 22:28:36,092:INFO:Defining folds
2023-06-19 22:28:36,093:INFO:Declaring metric variables
2023-06-19 22:28:36,096:INFO:Importing untrained model
2023-06-19 22:28:36,099:INFO:Ridge Classifier Imported successfully
2023-06-19 22:28:36,107:INFO:Starting cross validation
2023-06-19 22:28:36,108:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 22:28:36,309:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.46663e-27): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-06-19 22:28:36,326:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.4767e-27): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-06-19 22:28:36,334:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.51902e-27): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-06-19 22:28:36,356:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.50128e-27): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-06-19 22:28:36,368:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.49276e-27): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-06-19 22:28:36,383:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-19 22:28:36,400:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-19 22:28:36,419:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-19 22:28:36,423:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-19 22:28:36,430:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-19 22:28:37,724:INFO:Calculating mean and std
2023-06-19 22:28:37,724:INFO:Creating metrics dataframe
2023-06-19 22:28:38,008:INFO:Uploading results into container
2023-06-19 22:28:38,008:INFO:Uploading model into container now
2023-06-19 22:28:38,008:INFO:_master_model_container: 6
2023-06-19 22:28:38,008:INFO:_display_container: 2
2023-06-19 22:28:38,008:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-06-19 22:28:38,008:INFO:create_model() successfully completed......................................
2023-06-19 22:28:38,081:INFO:SubProcess create_model() end ==================================
2023-06-19 22:28:38,089:INFO:Creating metrics dataframe
2023-06-19 22:28:38,097:INFO:Initializing Random Forest Classifier
2023-06-19 22:28:38,097:INFO:Total runtime is 0.3756628155708313 minutes
2023-06-19 22:28:38,105:INFO:SubProcess create_model() called ==================================
2023-06-19 22:28:38,105:INFO:Initializing create_model()
2023-06-19 22:28:38,105:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001462B5355E0>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001462C7E2430>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 22:28:38,105:INFO:Checking exceptions
2023-06-19 22:28:38,105:INFO:Importing libraries
2023-06-19 22:28:38,105:INFO:Copying training dataset
2023-06-19 22:28:38,129:INFO:Defining folds
2023-06-19 22:28:38,129:INFO:Declaring metric variables
2023-06-19 22:28:38,129:INFO:Importing untrained model
2023-06-19 22:28:38,137:INFO:Random Forest Classifier Imported successfully
2023-06-19 22:28:38,145:INFO:Starting cross validation
2023-06-19 22:28:38,145:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 22:28:40,364:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:28:40,447:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:28:42,941:INFO:Calculating mean and std
2023-06-19 22:28:42,941:INFO:Creating metrics dataframe
2023-06-19 22:28:43,229:INFO:Uploading results into container
2023-06-19 22:28:43,229:INFO:Uploading model into container now
2023-06-19 22:28:43,230:INFO:_master_model_container: 7
2023-06-19 22:28:43,230:INFO:_display_container: 2
2023-06-19 22:28:43,230:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-19 22:28:43,230:INFO:create_model() successfully completed......................................
2023-06-19 22:28:43,299:INFO:SubProcess create_model() end ==================================
2023-06-19 22:28:43,300:INFO:Creating metrics dataframe
2023-06-19 22:28:43,311:INFO:Initializing Quadratic Discriminant Analysis
2023-06-19 22:28:43,311:INFO:Total runtime is 0.46257601579030355 minutes
2023-06-19 22:28:43,315:INFO:SubProcess create_model() called ==================================
2023-06-19 22:28:43,316:INFO:Initializing create_model()
2023-06-19 22:28:43,316:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001462B5355E0>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001462C7E2430>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 22:28:43,316:INFO:Checking exceptions
2023-06-19 22:28:43,316:INFO:Importing libraries
2023-06-19 22:28:43,316:INFO:Copying training dataset
2023-06-19 22:28:43,333:INFO:Defining folds
2023-06-19 22:28:43,333:INFO:Declaring metric variables
2023-06-19 22:28:43,337:INFO:Importing untrained model
2023-06-19 22:28:43,342:INFO:Quadratic Discriminant Analysis Imported successfully
2023-06-19 22:28:43,351:INFO:Starting cross validation
2023-06-19 22:28:43,353:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 22:28:45,326:INFO:Calculating mean and std
2023-06-19 22:28:45,327:INFO:Creating metrics dataframe
2023-06-19 22:28:45,631:INFO:Uploading results into container
2023-06-19 22:28:45,632:INFO:Uploading model into container now
2023-06-19 22:28:45,632:INFO:_master_model_container: 8
2023-06-19 22:28:45,632:INFO:_display_container: 2
2023-06-19 22:28:45,633:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-06-19 22:28:45,633:INFO:create_model() successfully completed......................................
2023-06-19 22:28:45,705:INFO:SubProcess create_model() end ==================================
2023-06-19 22:28:45,705:INFO:Creating metrics dataframe
2023-06-19 22:28:45,714:INFO:Initializing Ada Boost Classifier
2023-06-19 22:28:45,714:INFO:Total runtime is 0.5026166995366415 minutes
2023-06-19 22:28:45,717:INFO:SubProcess create_model() called ==================================
2023-06-19 22:28:45,718:INFO:Initializing create_model()
2023-06-19 22:28:45,718:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001462B5355E0>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001462C7E2430>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 22:28:45,718:INFO:Checking exceptions
2023-06-19 22:28:45,718:INFO:Importing libraries
2023-06-19 22:28:45,718:INFO:Copying training dataset
2023-06-19 22:28:45,733:INFO:Defining folds
2023-06-19 22:28:45,733:INFO:Declaring metric variables
2023-06-19 22:28:45,738:INFO:Importing untrained model
2023-06-19 22:28:45,741:INFO:Ada Boost Classifier Imported successfully
2023-06-19 22:28:45,748:INFO:Starting cross validation
2023-06-19 22:28:45,749:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 22:28:49,888:INFO:Calculating mean and std
2023-06-19 22:28:49,889:INFO:Creating metrics dataframe
2023-06-19 22:28:50,228:INFO:Uploading results into container
2023-06-19 22:28:50,229:INFO:Uploading model into container now
2023-06-19 22:28:50,229:INFO:_master_model_container: 9
2023-06-19 22:28:50,229:INFO:_display_container: 2
2023-06-19 22:28:50,230:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-06-19 22:28:50,230:INFO:create_model() successfully completed......................................
2023-06-19 22:28:50,302:INFO:SubProcess create_model() end ==================================
2023-06-19 22:28:50,303:INFO:Creating metrics dataframe
2023-06-19 22:28:50,313:INFO:Initializing Gradient Boosting Classifier
2023-06-19 22:28:50,314:INFO:Total runtime is 0.5792897899945577 minutes
2023-06-19 22:28:50,317:INFO:SubProcess create_model() called ==================================
2023-06-19 22:28:50,318:INFO:Initializing create_model()
2023-06-19 22:28:50,318:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001462B5355E0>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001462C7E2430>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 22:28:50,318:INFO:Checking exceptions
2023-06-19 22:28:50,318:INFO:Importing libraries
2023-06-19 22:28:50,318:INFO:Copying training dataset
2023-06-19 22:28:50,335:INFO:Defining folds
2023-06-19 22:28:50,336:INFO:Declaring metric variables
2023-06-19 22:28:50,339:INFO:Importing untrained model
2023-06-19 22:28:50,344:INFO:Gradient Boosting Classifier Imported successfully
2023-06-19 22:28:50,351:INFO:Starting cross validation
2023-06-19 22:28:50,353:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 22:29:00,017:INFO:Calculating mean and std
2023-06-19 22:29:00,019:INFO:Creating metrics dataframe
2023-06-19 22:29:00,360:INFO:Uploading results into container
2023-06-19 22:29:00,361:INFO:Uploading model into container now
2023-06-19 22:29:00,362:INFO:_master_model_container: 10
2023-06-19 22:29:00,362:INFO:_display_container: 2
2023-06-19 22:29:00,362:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-19 22:29:00,362:INFO:create_model() successfully completed......................................
2023-06-19 22:29:00,434:INFO:SubProcess create_model() end ==================================
2023-06-19 22:29:00,434:INFO:Creating metrics dataframe
2023-06-19 22:29:00,444:INFO:Initializing Linear Discriminant Analysis
2023-06-19 22:29:00,444:INFO:Total runtime is 0.7481245716412862 minutes
2023-06-19 22:29:00,447:INFO:SubProcess create_model() called ==================================
2023-06-19 22:29:00,447:INFO:Initializing create_model()
2023-06-19 22:29:00,447:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001462B5355E0>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001462C7E2430>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 22:29:00,447:INFO:Checking exceptions
2023-06-19 22:29:00,447:INFO:Importing libraries
2023-06-19 22:29:00,447:INFO:Copying training dataset
2023-06-19 22:29:00,478:INFO:Defining folds
2023-06-19 22:29:00,479:INFO:Declaring metric variables
2023-06-19 22:29:00,483:INFO:Importing untrained model
2023-06-19 22:29:00,489:INFO:Linear Discriminant Analysis Imported successfully
2023-06-19 22:29:00,497:INFO:Starting cross validation
2023-06-19 22:29:00,499:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 22:29:02,752:INFO:Calculating mean and std
2023-06-19 22:29:02,753:INFO:Creating metrics dataframe
2023-06-19 22:29:03,051:INFO:Uploading results into container
2023-06-19 22:29:03,052:INFO:Uploading model into container now
2023-06-19 22:29:03,053:INFO:_master_model_container: 11
2023-06-19 22:29:03,053:INFO:_display_container: 2
2023-06-19 22:29:03,053:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-06-19 22:29:03,053:INFO:create_model() successfully completed......................................
2023-06-19 22:29:03,132:INFO:SubProcess create_model() end ==================================
2023-06-19 22:29:03,134:INFO:Creating metrics dataframe
2023-06-19 22:29:03,145:INFO:Initializing Extra Trees Classifier
2023-06-19 22:29:03,145:INFO:Total runtime is 0.7931369105974833 minutes
2023-06-19 22:29:03,149:INFO:SubProcess create_model() called ==================================
2023-06-19 22:29:03,149:INFO:Initializing create_model()
2023-06-19 22:29:03,149:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001462B5355E0>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001462C7E2430>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 22:29:03,150:INFO:Checking exceptions
2023-06-19 22:29:03,150:INFO:Importing libraries
2023-06-19 22:29:03,150:INFO:Copying training dataset
2023-06-19 22:29:03,165:INFO:Defining folds
2023-06-19 22:29:03,166:INFO:Declaring metric variables
2023-06-19 22:29:03,170:INFO:Importing untrained model
2023-06-19 22:29:03,174:INFO:Extra Trees Classifier Imported successfully
2023-06-19 22:29:03,180:INFO:Starting cross validation
2023-06-19 22:29:03,182:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 22:29:07,518:INFO:Calculating mean and std
2023-06-19 22:29:07,519:INFO:Creating metrics dataframe
2023-06-19 22:29:07,841:INFO:Uploading results into container
2023-06-19 22:29:07,842:INFO:Uploading model into container now
2023-06-19 22:29:07,842:INFO:_master_model_container: 12
2023-06-19 22:29:07,842:INFO:_display_container: 2
2023-06-19 22:29:07,843:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-06-19 22:29:07,843:INFO:create_model() successfully completed......................................
2023-06-19 22:29:07,914:INFO:SubProcess create_model() end ==================================
2023-06-19 22:29:07,914:INFO:Creating metrics dataframe
2023-06-19 22:29:07,927:INFO:Initializing Light Gradient Boosting Machine
2023-06-19 22:29:07,927:INFO:Total runtime is 0.8728442152341206 minutes
2023-06-19 22:29:07,932:INFO:SubProcess create_model() called ==================================
2023-06-19 22:29:07,933:INFO:Initializing create_model()
2023-06-19 22:29:07,933:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001462B5355E0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001462C7E2430>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 22:29:07,933:INFO:Checking exceptions
2023-06-19 22:29:07,934:INFO:Importing libraries
2023-06-19 22:29:07,934:INFO:Copying training dataset
2023-06-19 22:29:07,949:INFO:Defining folds
2023-06-19 22:29:07,949:INFO:Declaring metric variables
2023-06-19 22:29:07,954:INFO:Importing untrained model
2023-06-19 22:29:07,958:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-19 22:29:07,964:INFO:Starting cross validation
2023-06-19 22:29:07,966:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 22:29:11,441:INFO:Calculating mean and std
2023-06-19 22:29:11,443:INFO:Creating metrics dataframe
2023-06-19 22:29:11,769:INFO:Uploading results into container
2023-06-19 22:29:11,769:INFO:Uploading model into container now
2023-06-19 22:29:11,770:INFO:_master_model_container: 13
2023-06-19 22:29:11,770:INFO:_display_container: 2
2023-06-19 22:29:11,771:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-19 22:29:11,771:INFO:create_model() successfully completed......................................
2023-06-19 22:29:11,846:INFO:SubProcess create_model() end ==================================
2023-06-19 22:29:11,846:INFO:Creating metrics dataframe
2023-06-19 22:29:11,858:INFO:Initializing Dummy Classifier
2023-06-19 22:29:11,858:INFO:Total runtime is 0.9383551359176635 minutes
2023-06-19 22:29:11,861:INFO:SubProcess create_model() called ==================================
2023-06-19 22:29:11,861:INFO:Initializing create_model()
2023-06-19 22:29:11,861:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001462B5355E0>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001462C7E2430>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 22:29:11,862:INFO:Checking exceptions
2023-06-19 22:29:11,862:INFO:Importing libraries
2023-06-19 22:29:11,862:INFO:Copying training dataset
2023-06-19 22:29:11,877:INFO:Defining folds
2023-06-19 22:29:11,877:INFO:Declaring metric variables
2023-06-19 22:29:11,880:INFO:Importing untrained model
2023-06-19 22:29:11,887:INFO:Dummy Classifier Imported successfully
2023-06-19 22:29:11,894:INFO:Starting cross validation
2023-06-19 22:29:11,895:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 22:29:12,179:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 22:29:12,236:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 22:29:12,252:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 22:29:12,257:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 22:29:12,257:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 22:29:13,831:INFO:Calculating mean and std
2023-06-19 22:29:13,834:INFO:Creating metrics dataframe
2023-06-19 22:29:14,138:INFO:Uploading results into container
2023-06-19 22:29:14,140:INFO:Uploading model into container now
2023-06-19 22:29:14,140:INFO:_master_model_container: 14
2023-06-19 22:29:14,140:INFO:_display_container: 2
2023-06-19 22:29:14,140:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-06-19 22:29:14,140:INFO:create_model() successfully completed......................................
2023-06-19 22:29:14,209:INFO:SubProcess create_model() end ==================================
2023-06-19 22:29:14,210:INFO:Creating metrics dataframe
2023-06-19 22:29:14,231:INFO:Initializing create_model()
2023-06-19 22:29:14,231:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001462B5355E0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-19 22:29:14,231:INFO:Checking exceptions
2023-06-19 22:29:14,234:INFO:Importing libraries
2023-06-19 22:29:14,234:INFO:Copying training dataset
2023-06-19 22:29:14,248:INFO:Defining folds
2023-06-19 22:29:14,248:INFO:Declaring metric variables
2023-06-19 22:29:14,248:INFO:Importing untrained model
2023-06-19 22:29:14,248:INFO:Declaring custom model
2023-06-19 22:29:14,249:INFO:Random Forest Classifier Imported successfully
2023-06-19 22:29:14,250:INFO:Cross validation set to False
2023-06-19 22:29:14,250:INFO:Fitting Model
2023-06-19 22:29:15,643:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-19 22:29:15,643:INFO:create_model() successfully completed......................................
2023-06-19 22:29:15,793:INFO:_master_model_container: 14
2023-06-19 22:29:15,793:INFO:_display_container: 2
2023-06-19 22:29:15,793:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-19 22:29:15,793:INFO:compare_models() successfully completed......................................
2023-06-19 22:29:15,868:INFO:Initializing create_model()
2023-06-19 22:29:15,868:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001462B5355E0>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-19 22:29:15,868:INFO:Checking exceptions
2023-06-19 22:29:15,897:INFO:Importing libraries
2023-06-19 22:29:15,897:INFO:Copying training dataset
2023-06-19 22:29:15,918:INFO:Defining folds
2023-06-19 22:29:15,919:INFO:Declaring metric variables
2023-06-19 22:29:15,923:INFO:Importing untrained model
2023-06-19 22:29:15,927:INFO:Random Forest Classifier Imported successfully
2023-06-19 22:29:15,936:INFO:Starting cross validation
2023-06-19 22:29:15,939:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 22:29:18,340:INFO:Calculating mean and std
2023-06-19 22:29:18,341:INFO:Creating metrics dataframe
2023-06-19 22:29:18,345:INFO:Finalizing model
2023-06-19 22:29:18,809:INFO:Uploading results into container
2023-06-19 22:29:18,810:INFO:Uploading model into container now
2023-06-19 22:29:18,819:INFO:_master_model_container: 15
2023-06-19 22:29:18,819:INFO:_display_container: 3
2023-06-19 22:29:18,819:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-19 22:29:18,819:INFO:create_model() successfully completed......................................
2023-06-19 22:29:18,892:INFO:Initializing predict_model()
2023-06-19 22:29:18,892:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001462B5355E0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001462C6FB4C0>)
2023-06-19 22:29:18,892:INFO:Checking exceptions
2023-06-19 22:29:18,892:INFO:Preloading libraries
2023-06-19 22:29:18,894:INFO:Set up data.
2023-06-19 22:29:18,912:INFO:Set up index.
2023-06-19 22:29:19,312:INFO:Initializing tune_model()
2023-06-19 22:29:19,312:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001462B5355E0>)
2023-06-19 22:29:19,313:INFO:Checking exceptions
2023-06-19 22:29:19,356:INFO:Copying training dataset
2023-06-19 22:29:19,368:INFO:Checking base model
2023-06-19 22:29:19,369:INFO:Base model : Random Forest Classifier
2023-06-19 22:29:19,373:INFO:Declaring metric variables
2023-06-19 22:29:19,376:INFO:Defining Hyperparameters
2023-06-19 22:29:19,452:INFO:Tuning with n_jobs=-1
2023-06-19 22:29:19,452:INFO:Initializing RandomizedSearchCV
2023-06-19 22:29:20,688:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:29:20,916:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:29:24,549:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:29:24,587:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:29:24,776:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:29:24,935:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:29:25,819:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:29:25,874:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:29:25,965:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:29:26,267:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:29:26,677:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:29:26,951:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:29:28,981:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:29:29,266:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:29:29,583:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:29:30,356:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:29:30,589:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:29:31,046:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:29:31,203:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:29:32,376:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:29:32,724:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:29:32,802:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:29:32,888:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:29:33,800:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:29:33,832:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:29:34,748:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:29:34,870:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:29:35,629:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:29:35,641:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:29:36,079:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:29:36,279:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:29:36,602:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:29:37,336:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:29:37,680:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:29:38,554:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:29:38,868:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:29:40,655:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:29:40,764:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:29:41,931:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:29:42,888:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:29:43,009:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:29:43,578:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:29:43,754:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:29:44,240:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:29:44,673:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:29:45,008:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:29:45,095:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:29:45,697:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:29:47,910:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:29:49,165:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:29:59,476:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-19 22:30:07,281:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:30:10,158:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:30:11,117:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:30:11,445:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:30:13,550:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-06-19 22:30:14,081:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:30:14,326:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.27s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:30:14,975:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:30:15,531:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.31s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:30:16,635:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:30:17,277:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:30:18,000:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:30:19,286:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:30:19,632:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:30:22,008:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:30:22,013:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:30:22,540:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:30:23,310:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:30:23,776:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-06-19 22:30:23,880:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:30:24,667:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-06-19 22:30:25,875:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:30:26,825:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:30:38,260:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.45s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:30:41,471:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:30:41,896:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:30:42,741:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:30:43,281:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 22:30:47,992:INFO:best_params: {'actual_estimator__n_estimators': 150, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.0002, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 5, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': False}
2023-06-19 22:30:47,993:INFO:Hyperparameter search completed
2023-06-19 22:30:47,993:INFO:SubProcess create_model() called ==================================
2023-06-19 22:30:47,994:INFO:Initializing create_model()
2023-06-19 22:30:47,994:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001462B5355E0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001462C577760>, model_only=True, return_train_score=False, kwargs={'n_estimators': 150, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.0002, 'max_features': 1.0, 'max_depth': 5, 'criterion': 'entropy', 'class_weight': {}, 'bootstrap': False})
2023-06-19 22:30:47,995:INFO:Checking exceptions
2023-06-19 22:30:47,995:INFO:Importing libraries
2023-06-19 22:30:47,995:INFO:Copying training dataset
2023-06-19 22:30:48,019:INFO:Defining folds
2023-06-19 22:30:48,019:INFO:Declaring metric variables
2023-06-19 22:30:48,024:INFO:Importing untrained model
2023-06-19 22:30:48,024:INFO:Declaring custom model
2023-06-19 22:30:48,027:INFO:Random Forest Classifier Imported successfully
2023-06-19 22:30:48,034:INFO:Starting cross validation
2023-06-19 22:30:48,036:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 22:30:50,973:INFO:Calculating mean and std
2023-06-19 22:30:50,975:INFO:Creating metrics dataframe
2023-06-19 22:30:50,980:INFO:Finalizing model
2023-06-19 22:30:57,008:INFO:Uploading results into container
2023-06-19 22:30:57,010:INFO:Uploading model into container now
2023-06-19 22:30:57,010:INFO:_master_model_container: 16
2023-06-19 22:30:57,011:INFO:_display_container: 5
2023-06-19 22:30:57,011:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=5, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0002, min_samples_leaf=5,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       n_estimators=150, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-19 22:30:57,011:INFO:create_model() successfully completed......................................
2023-06-19 22:30:57,088:INFO:SubProcess create_model() end ==================================
2023-06-19 22:30:57,089:INFO:choose_better activated
2023-06-19 22:30:57,092:INFO:SubProcess create_model() called ==================================
2023-06-19 22:30:57,094:INFO:Initializing create_model()
2023-06-19 22:30:57,094:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001462B5355E0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-19 22:30:57,094:INFO:Checking exceptions
2023-06-19 22:30:57,095:INFO:Importing libraries
2023-06-19 22:30:57,095:INFO:Copying training dataset
2023-06-19 22:30:57,115:INFO:Defining folds
2023-06-19 22:30:57,115:INFO:Declaring metric variables
2023-06-19 22:30:57,115:INFO:Importing untrained model
2023-06-19 22:30:57,115:INFO:Declaring custom model
2023-06-19 22:30:57,116:INFO:Random Forest Classifier Imported successfully
2023-06-19 22:30:57,116:INFO:Starting cross validation
2023-06-19 22:30:57,117:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 22:31:01,146:INFO:Calculating mean and std
2023-06-19 22:31:01,146:INFO:Creating metrics dataframe
2023-06-19 22:31:01,149:INFO:Finalizing model
2023-06-19 22:31:02,015:INFO:Uploading results into container
2023-06-19 22:31:02,015:INFO:Uploading model into container now
2023-06-19 22:31:02,016:INFO:_master_model_container: 17
2023-06-19 22:31:02,016:INFO:_display_container: 6
2023-06-19 22:31:02,016:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-19 22:31:02,016:INFO:create_model() successfully completed......................................
2023-06-19 22:31:02,091:INFO:SubProcess create_model() end ==================================
2023-06-19 22:31:02,092:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) result for Accuracy is 0.993
2023-06-19 22:31:02,092:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=5, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0002, min_samples_leaf=5,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       n_estimators=150, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) result for Accuracy is 0.9316
2023-06-19 22:31:02,093:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) is best model
2023-06-19 22:31:02,093:INFO:choose_better completed
2023-06-19 22:31:02,093:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-06-19 22:31:02,102:INFO:_master_model_container: 17
2023-06-19 22:31:02,102:INFO:_display_container: 5
2023-06-19 22:31:02,103:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-19 22:31:02,103:INFO:tune_model() successfully completed......................................
2023-06-19 22:31:33,080:INFO:Initializing predict_model()
2023-06-19 22:31:33,080:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001462B5355E0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000014643BDBD30>)
2023-06-19 22:31:33,081:INFO:Checking exceptions
2023-06-19 22:31:33,081:INFO:Preloading libraries
2023-06-19 22:31:33,083:INFO:Set up data.
2023-06-19 22:31:33,103:INFO:Set up index.
2023-06-19 22:31:45,376:INFO:PyCaret TSForecastingExperiment
2023-06-19 22:31:45,376:INFO:Logging name: ts-default-name
2023-06-19 22:31:45,376:INFO:ML Usecase: MLUsecase.TIME_SERIES
2023-06-19 22:31:45,376:INFO:version 3.0.2
2023-06-19 22:31:45,376:INFO:Initializing setup()
2023-06-19 22:31:45,376:INFO:self.USI: 80e0
2023-06-19 22:31:45,376:INFO:self._variable_keys: {'all_sps_to_use', 'gpu_param', 'idx', 'seasonality_present', 'X_train_transformed', 'candidate_sps', 'logging_param', 'y_transformed', 'y_train', 'y_test_transformed', 'pipeline', 'y_test', 'X_test', 'enforce_pi', 'model_engines', 'enforce_exogenous', 'n_jobs_param', 'exp_name_log', 'fold_generator', 'USI', 'X_transformed', 'fold_param', 'index_type', 'y_train_transformed', 'X', 'seed', 'memory', 'log_plots_param', 'significant_sps', '_ml_usecase', 'significant_sps_no_harmonics', 'html_param', 'fh', 'primary_sp_to_use', '_available_plots', 'X_test_transformed', 'X_train', 'exp_id', 'y', 'approach_type', 'data', 'gpu_n_jobs_param', 'exogenous_present', 'strictly_positive'}
2023-06-19 22:31:45,376:INFO:Checking environment
2023-06-19 22:31:45,376:INFO:python_version: 3.8.12
2023-06-19 22:31:45,376:INFO:python_build: ('default', 'Oct 12 2021 03:01:40')
2023-06-19 22:31:45,376:INFO:machine: AMD64
2023-06-19 22:31:45,376:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-19 22:31:45,376:INFO:Memory: svmem(total=16861405184, available=3336536064, percent=80.2, used=13524869120, free=3336536064)
2023-06-19 22:31:45,376:INFO:Physical Core: 4
2023-06-19 22:31:45,376:INFO:Logical Core: 8
2023-06-19 22:31:45,377:INFO:Checking libraries
2023-06-19 22:31:45,377:INFO:System:
2023-06-19 22:31:45,377:INFO:    python: 3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]
2023-06-19 22:31:45,377:INFO:executable: c:\Users\choib\anaconda3\envs\iise-python\python.exe
2023-06-19 22:31:45,377:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-19 22:31:45,377:INFO:PyCaret required dependencies:
2023-06-19 22:31:45,377:INFO:                 pip: 21.0.1
2023-06-19 22:31:45,377:INFO:          setuptools: 58.0.4
2023-06-19 22:31:45,377:INFO:             pycaret: 3.0.2
2023-06-19 22:31:45,377:INFO:             IPython: 8.12.0
2023-06-19 22:31:45,377:INFO:          ipywidgets: 8.0.6
2023-06-19 22:31:45,378:INFO:                tqdm: 4.65.0
2023-06-19 22:31:45,378:INFO:               numpy: 1.21.4
2023-06-19 22:31:45,378:INFO:              pandas: 1.5.3
2023-06-19 22:31:45,378:INFO:              jinja2: 3.1.2
2023-06-19 22:31:45,378:INFO:               scipy: 1.10.1
2023-06-19 22:31:45,378:INFO:              joblib: 1.2.0
2023-06-19 22:31:45,378:INFO:             sklearn: 1.2.2
2023-06-19 22:31:45,378:INFO:                pyod: 1.0.9
2023-06-19 22:31:45,378:INFO:            imblearn: 0.10.1
2023-06-19 22:31:45,379:INFO:   category_encoders: 2.6.1
2023-06-19 22:31:45,379:INFO:            lightgbm: 3.3.5
2023-06-19 22:31:45,379:INFO:               numba: 0.57.0
2023-06-19 22:31:45,379:INFO:            requests: 2.31.0
2023-06-19 22:31:45,379:INFO:          matplotlib: 3.4.3
2023-06-19 22:31:45,379:INFO:          scikitplot: 0.3.7
2023-06-19 22:31:45,379:INFO:         yellowbrick: 1.5
2023-06-19 22:31:45,379:INFO:              plotly: 5.15.0
2023-06-19 22:31:45,379:INFO:             kaleido: 0.2.1
2023-06-19 22:31:45,379:INFO:         statsmodels: 0.14.0
2023-06-19 22:31:45,380:INFO:              sktime: 0.17.0
2023-06-19 22:31:45,380:INFO:               tbats: 1.1.3
2023-06-19 22:31:45,380:INFO:            pmdarima: 2.0.3
2023-06-19 22:31:45,380:INFO:              psutil: 5.9.0
2023-06-19 22:31:45,380:INFO:PyCaret optional dependencies:
2023-06-19 22:31:45,380:INFO:                shap: Not installed
2023-06-19 22:31:45,380:INFO:           interpret: Not installed
2023-06-19 22:31:45,380:INFO:                umap: Not installed
2023-06-19 22:31:45,380:INFO:    pandas_profiling: Not installed
2023-06-19 22:31:45,380:INFO:  explainerdashboard: Not installed
2023-06-19 22:31:45,380:INFO:             autoviz: Not installed
2023-06-19 22:31:45,381:INFO:           fairlearn: Not installed
2023-06-19 22:31:45,381:INFO:             xgboost: Not installed
2023-06-19 22:31:45,381:INFO:            catboost: Not installed
2023-06-19 22:31:45,381:INFO:              kmodes: Not installed
2023-06-19 22:31:45,381:INFO:             mlxtend: Not installed
2023-06-19 22:31:45,381:INFO:       statsforecast: Not installed
2023-06-19 22:31:45,381:INFO:        tune_sklearn: Not installed
2023-06-19 22:31:45,381:INFO:                 ray: Not installed
2023-06-19 22:31:45,381:INFO:            hyperopt: Not installed
2023-06-19 22:31:45,381:INFO:              optuna: Not installed
2023-06-19 22:31:45,381:INFO:               skopt: Not installed
2023-06-19 22:31:45,381:INFO:              mlflow: Not installed
2023-06-19 22:31:45,381:INFO:              gradio: Not installed
2023-06-19 22:31:45,381:INFO:             fastapi: Not installed
2023-06-19 22:31:45,381:INFO:             uvicorn: Not installed
2023-06-19 22:31:45,381:INFO:              m2cgen: Not installed
2023-06-19 22:31:45,382:INFO:           evidently: Not installed
2023-06-19 22:31:45,382:INFO:               fugue: Not installed
2023-06-19 22:31:45,382:INFO:           streamlit: Not installed
2023-06-19 22:31:45,382:INFO:             prophet: 1.1.4
2023-06-19 22:31:45,382:INFO:None
2023-06-19 22:31:45,390:INFO:Set Forecast Horizon.
2023-06-19 22:31:45,394:INFO:Set up Train-Test Splits.
2023-06-19 22:33:54,888:INFO:PyCaret TSForecastingExperiment
2023-06-19 22:33:54,888:INFO:Logging name: ts-default-name
2023-06-19 22:33:54,888:INFO:ML Usecase: MLUsecase.TIME_SERIES
2023-06-19 22:33:54,888:INFO:version 3.0.2
2023-06-19 22:33:54,888:INFO:Initializing setup()
2023-06-19 22:33:54,889:INFO:self.USI: a404
2023-06-19 22:33:54,889:INFO:self._variable_keys: {'all_sps_to_use', 'gpu_param', 'idx', 'seasonality_present', 'X_train_transformed', 'candidate_sps', 'logging_param', 'y_transformed', 'y_train', 'y_test_transformed', 'pipeline', 'y_test', 'X_test', 'enforce_pi', 'model_engines', 'enforce_exogenous', 'n_jobs_param', 'exp_name_log', 'fold_generator', 'USI', 'X_transformed', 'fold_param', 'index_type', 'y_train_transformed', 'X', 'seed', 'memory', 'log_plots_param', 'significant_sps', '_ml_usecase', 'significant_sps_no_harmonics', 'html_param', 'fh', 'primary_sp_to_use', '_available_plots', 'X_test_transformed', 'X_train', 'exp_id', 'y', 'approach_type', 'data', 'gpu_n_jobs_param', 'exogenous_present', 'strictly_positive'}
2023-06-19 22:33:54,889:INFO:Checking environment
2023-06-19 22:33:54,889:INFO:python_version: 3.8.12
2023-06-19 22:33:54,889:INFO:python_build: ('default', 'Oct 12 2021 03:01:40')
2023-06-19 22:33:54,889:INFO:machine: AMD64
2023-06-19 22:33:54,889:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-19 22:33:54,889:INFO:Memory: svmem(total=16861405184, available=3120750592, percent=81.5, used=13740654592, free=3120750592)
2023-06-19 22:33:54,889:INFO:Physical Core: 4
2023-06-19 22:33:54,889:INFO:Logical Core: 8
2023-06-19 22:33:54,889:INFO:Checking libraries
2023-06-19 22:33:54,889:INFO:System:
2023-06-19 22:33:54,889:INFO:    python: 3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]
2023-06-19 22:33:54,889:INFO:executable: c:\Users\choib\anaconda3\envs\iise-python\python.exe
2023-06-19 22:33:54,889:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-19 22:33:54,889:INFO:PyCaret required dependencies:
2023-06-19 22:33:54,889:INFO:                 pip: 21.0.1
2023-06-19 22:33:54,889:INFO:          setuptools: 58.0.4
2023-06-19 22:33:54,889:INFO:             pycaret: 3.0.2
2023-06-19 22:33:54,889:INFO:             IPython: 8.12.0
2023-06-19 22:33:54,890:INFO:          ipywidgets: 8.0.6
2023-06-19 22:33:54,890:INFO:                tqdm: 4.65.0
2023-06-19 22:33:54,890:INFO:               numpy: 1.21.4
2023-06-19 22:33:54,890:INFO:              pandas: 1.5.3
2023-06-19 22:33:54,890:INFO:              jinja2: 3.1.2
2023-06-19 22:33:54,890:INFO:               scipy: 1.10.1
2023-06-19 22:33:54,890:INFO:              joblib: 1.2.0
2023-06-19 22:33:54,890:INFO:             sklearn: 1.2.2
2023-06-19 22:33:54,890:INFO:                pyod: 1.0.9
2023-06-19 22:33:54,890:INFO:            imblearn: 0.10.1
2023-06-19 22:33:54,890:INFO:   category_encoders: 2.6.1
2023-06-19 22:33:54,890:INFO:            lightgbm: 3.3.5
2023-06-19 22:33:54,890:INFO:               numba: 0.57.0
2023-06-19 22:33:54,891:INFO:            requests: 2.31.0
2023-06-19 22:33:54,891:INFO:          matplotlib: 3.4.3
2023-06-19 22:33:54,891:INFO:          scikitplot: 0.3.7
2023-06-19 22:33:54,891:INFO:         yellowbrick: 1.5
2023-06-19 22:33:54,891:INFO:              plotly: 5.15.0
2023-06-19 22:33:54,891:INFO:             kaleido: 0.2.1
2023-06-19 22:33:54,891:INFO:         statsmodels: 0.14.0
2023-06-19 22:33:54,891:INFO:              sktime: 0.17.0
2023-06-19 22:33:54,891:INFO:               tbats: 1.1.3
2023-06-19 22:33:54,891:INFO:            pmdarima: 2.0.3
2023-06-19 22:33:54,891:INFO:              psutil: 5.9.0
2023-06-19 22:33:54,891:INFO:PyCaret optional dependencies:
2023-06-19 22:33:54,891:INFO:                shap: Not installed
2023-06-19 22:33:54,891:INFO:           interpret: Not installed
2023-06-19 22:33:54,891:INFO:                umap: Not installed
2023-06-19 22:33:54,891:INFO:    pandas_profiling: Not installed
2023-06-19 22:33:54,891:INFO:  explainerdashboard: Not installed
2023-06-19 22:33:54,892:INFO:             autoviz: Not installed
2023-06-19 22:33:54,892:INFO:           fairlearn: Not installed
2023-06-19 22:33:54,892:INFO:             xgboost: Not installed
2023-06-19 22:33:54,892:INFO:            catboost: Not installed
2023-06-19 22:33:54,892:INFO:              kmodes: Not installed
2023-06-19 22:33:54,892:INFO:             mlxtend: Not installed
2023-06-19 22:33:54,892:INFO:       statsforecast: Not installed
2023-06-19 22:33:54,892:INFO:        tune_sklearn: Not installed
2023-06-19 22:33:54,892:INFO:                 ray: Not installed
2023-06-19 22:33:54,892:INFO:            hyperopt: Not installed
2023-06-19 22:33:54,892:INFO:              optuna: Not installed
2023-06-19 22:33:54,892:INFO:               skopt: Not installed
2023-06-19 22:33:54,892:INFO:              mlflow: Not installed
2023-06-19 22:33:54,892:INFO:              gradio: Not installed
2023-06-19 22:33:54,893:INFO:             fastapi: Not installed
2023-06-19 22:33:54,893:INFO:             uvicorn: Not installed
2023-06-19 22:33:54,893:INFO:              m2cgen: Not installed
2023-06-19 22:33:54,893:INFO:           evidently: Not installed
2023-06-19 22:33:54,893:INFO:               fugue: Not installed
2023-06-19 22:33:54,893:INFO:           streamlit: Not installed
2023-06-19 22:33:54,893:INFO:             prophet: 1.1.4
2023-06-19 22:33:54,893:INFO:None
2023-06-19 22:33:54,902:INFO:Set Forecast Horizon.
2023-06-19 22:33:54,902:INFO:Set up Train-Test Splits.
2023-06-19 22:55:12,983:INFO:PyCaret ClassificationExperiment
2023-06-19 22:55:12,983:INFO:Logging name: clf-default-name
2023-06-19 22:55:12,983:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-19 22:55:12,984:INFO:version 3.0.2
2023-06-19 22:55:12,984:INFO:Initializing setup()
2023-06-19 22:55:12,984:INFO:self.USI: 31a0
2023-06-19 22:55:12,984:INFO:self._variable_keys: {'gpu_param', 'fold_shuffle_param', 'X', 'seed', 'idx', 'memory', 'logging_param', 'log_plots_param', 'y_train', '_ml_usecase', 'pipeline', 'y_test', 'fold_groups_param', 'X_test', 'target_param', 'html_param', 'n_jobs_param', 'fix_imbalance', '_available_plots', 'X_train', 'exp_id', 'y', 'exp_name_log', 'fold_generator', 'is_multiclass', 'USI', 'data', 'gpu_n_jobs_param'}
2023-06-19 22:55:12,984:INFO:Checking environment
2023-06-19 22:55:12,984:INFO:python_version: 3.8.12
2023-06-19 22:55:12,984:INFO:python_build: ('default', 'Oct 12 2021 03:01:40')
2023-06-19 22:55:12,984:INFO:machine: AMD64
2023-06-19 22:55:12,984:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-19 22:55:12,984:INFO:Memory: svmem(total=16861405184, available=4077928448, percent=75.8, used=12783476736, free=4077928448)
2023-06-19 22:55:12,984:INFO:Physical Core: 4
2023-06-19 22:55:12,984:INFO:Logical Core: 8
2023-06-19 22:55:12,984:INFO:Checking libraries
2023-06-19 22:55:12,984:INFO:System:
2023-06-19 22:55:12,984:INFO:    python: 3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]
2023-06-19 22:55:12,984:INFO:executable: c:\Users\choib\anaconda3\envs\iise-python\python.exe
2023-06-19 22:55:12,984:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-19 22:55:12,984:INFO:PyCaret required dependencies:
2023-06-19 22:55:12,985:INFO:                 pip: 21.0.1
2023-06-19 22:55:12,985:INFO:          setuptools: 58.0.4
2023-06-19 22:55:12,985:INFO:             pycaret: 3.0.2
2023-06-19 22:55:12,985:INFO:             IPython: 8.12.0
2023-06-19 22:55:12,985:INFO:          ipywidgets: 8.0.6
2023-06-19 22:55:12,985:INFO:                tqdm: 4.65.0
2023-06-19 22:55:12,985:INFO:               numpy: 1.21.4
2023-06-19 22:55:12,985:INFO:              pandas: 1.5.3
2023-06-19 22:55:12,985:INFO:              jinja2: 3.1.2
2023-06-19 22:55:12,985:INFO:               scipy: 1.10.1
2023-06-19 22:55:12,985:INFO:              joblib: 1.2.0
2023-06-19 22:55:12,985:INFO:             sklearn: 1.2.2
2023-06-19 22:55:12,985:INFO:                pyod: 1.0.9
2023-06-19 22:55:12,985:INFO:            imblearn: 0.10.1
2023-06-19 22:55:12,985:INFO:   category_encoders: 2.6.1
2023-06-19 22:55:12,985:INFO:            lightgbm: 3.3.5
2023-06-19 22:55:12,986:INFO:               numba: 0.57.0
2023-06-19 22:55:12,986:INFO:            requests: 2.31.0
2023-06-19 22:55:12,986:INFO:          matplotlib: 3.4.3
2023-06-19 22:55:12,986:INFO:          scikitplot: 0.3.7
2023-06-19 22:55:12,986:INFO:         yellowbrick: 1.5
2023-06-19 22:55:12,986:INFO:              plotly: 5.15.0
2023-06-19 22:55:12,986:INFO:             kaleido: 0.2.1
2023-06-19 22:55:12,986:INFO:         statsmodels: 0.14.0
2023-06-19 22:55:12,986:INFO:              sktime: 0.17.0
2023-06-19 22:55:12,986:INFO:               tbats: 1.1.3
2023-06-19 22:55:12,986:INFO:            pmdarima: 2.0.3
2023-06-19 22:55:12,986:INFO:              psutil: 5.9.0
2023-06-19 22:55:12,986:INFO:PyCaret optional dependencies:
2023-06-19 22:55:12,986:INFO:                shap: Not installed
2023-06-19 22:55:12,988:INFO:           interpret: Not installed
2023-06-19 22:55:12,988:INFO:                umap: Not installed
2023-06-19 22:55:12,988:INFO:    pandas_profiling: Not installed
2023-06-19 22:55:12,988:INFO:  explainerdashboard: Not installed
2023-06-19 22:55:12,988:INFO:             autoviz: Not installed
2023-06-19 22:55:12,988:INFO:           fairlearn: Not installed
2023-06-19 22:55:12,988:INFO:             xgboost: Not installed
2023-06-19 22:55:12,988:INFO:            catboost: Not installed
2023-06-19 22:55:12,988:INFO:              kmodes: Not installed
2023-06-19 22:55:12,989:INFO:             mlxtend: Not installed
2023-06-19 22:55:12,989:INFO:       statsforecast: Not installed
2023-06-19 22:55:12,989:INFO:        tune_sklearn: Not installed
2023-06-19 22:55:12,989:INFO:                 ray: Not installed
2023-06-19 22:55:12,989:INFO:            hyperopt: Not installed
2023-06-19 22:55:12,989:INFO:              optuna: Not installed
2023-06-19 22:55:12,989:INFO:               skopt: Not installed
2023-06-19 22:55:12,989:INFO:              mlflow: Not installed
2023-06-19 22:55:12,989:INFO:              gradio: Not installed
2023-06-19 22:55:12,989:INFO:             fastapi: Not installed
2023-06-19 22:55:12,989:INFO:             uvicorn: Not installed
2023-06-19 22:55:12,989:INFO:              m2cgen: Not installed
2023-06-19 22:55:12,989:INFO:           evidently: Not installed
2023-06-19 22:55:12,989:INFO:               fugue: Not installed
2023-06-19 22:55:12,989:INFO:           streamlit: Not installed
2023-06-19 22:55:12,989:INFO:             prophet: 1.1.4
2023-06-19 22:55:12,989:INFO:None
2023-06-19 22:55:12,989:INFO:Set up data.
2023-06-19 22:55:13,019:INFO:Set up train/test split.
2023-06-19 22:55:13,040:INFO:Set up index.
2023-06-19 22:55:13,041:INFO:Set up folding strategy.
2023-06-19 22:55:13,041:INFO:Assigning column types.
2023-06-19 22:55:13,053:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-19 22:55:13,094:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-19 22:55:13,095:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-19 22:55:13,122:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 22:55:13,122:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 22:55:13,167:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-19 22:55:13,168:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-19 22:55:13,198:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 22:55:13,199:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 22:55:13,199:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-19 22:55:13,248:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-19 22:55:13,285:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 22:55:13,285:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 22:55:13,332:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-19 22:55:13,359:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 22:55:13,360:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 22:55:13,360:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-19 22:55:13,434:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 22:55:13,435:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 22:55:13,500:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 22:55:13,501:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 22:55:13,502:INFO:Preparing preprocessing pipeline...
2023-06-19 22:55:13,504:INFO:Set up simple imputation.
2023-06-19 22:55:13,509:INFO:Set up encoding of categorical features.
2023-06-19 22:55:13,509:INFO:Set up feature normalization.
2023-06-19 22:55:13,662:INFO:Finished creating preprocessing pipeline.
2023-06-19 22:55:13,671:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\choib\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['disk_id', 'r_1', 'n_5', 'r_5',
                                             'r_9', 'r_12', 'n_171', 'r_171',
                                             'n_172', 'r_172', 'n_173', 'r_174',
                                             'n_180', 'r_180', 'n_184', 'r_184',
                                             'r_187', 'r_188', 'n_190', 'r_190',
                                             'r_194', 'r_195', 'n_196', 'r_196',
                                             'r_197', 'r_198', 'r...
                 TransformerWrapper(exclude=None, include=['ds'],
                                    transformer=TargetEncoder(cols=['ds'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1))))],
         verbose=False)
2023-06-19 22:55:13,671:INFO:Creating final display dataframe.
2023-06-19 22:55:14,033:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             label
2                   Target type            Binary
3           Original data shape       (37002, 31)
4        Transformed data shape       (37002, 31)
5   Transformed train set shape       (25901, 31)
6    Transformed test set shape       (11101, 31)
7              Numeric features                29
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            minmax
17               Fold Generator   StratifiedKFold
18                  Fold Number                 5
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              31a0
2023-06-19 22:55:14,118:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 22:55:14,118:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 22:55:14,190:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 22:55:14,191:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 22:55:14,192:INFO:setup() successfully completed in 1.53s...............
2023-06-19 22:55:14,480:INFO:Initializing compare_models()
2023-06-19 22:55:14,480:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014640B53370>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000014640B53370>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-06-19 22:55:14,480:INFO:Checking exceptions
2023-06-19 22:55:14,490:INFO:Preparing display monitor
2023-06-19 22:55:14,538:INFO:Initializing Logistic Regression
2023-06-19 22:55:14,538:INFO:Total runtime is 0.0 minutes
2023-06-19 22:55:14,543:INFO:SubProcess create_model() called ==================================
2023-06-19 22:55:14,543:INFO:Initializing create_model()
2023-06-19 22:55:14,543:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014640B53370>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001462C72E0D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 22:55:14,544:INFO:Checking exceptions
2023-06-19 22:55:14,544:INFO:Importing libraries
2023-06-19 22:55:14,544:INFO:Copying training dataset
2023-06-19 22:55:14,565:INFO:Defining folds
2023-06-19 22:55:14,565:INFO:Declaring metric variables
2023-06-19 22:55:14,572:INFO:Importing untrained model
2023-06-19 22:55:14,575:INFO:Logistic Regression Imported successfully
2023-06-19 22:55:14,583:INFO:Starting cross validation
2023-06-19 22:55:14,585:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 22:55:21,128:INFO:Calculating mean and std
2023-06-19 22:55:21,130:INFO:Creating metrics dataframe
2023-06-19 22:55:21,542:INFO:Uploading results into container
2023-06-19 22:55:21,543:INFO:Uploading model into container now
2023-06-19 22:55:21,543:INFO:_master_model_container: 1
2023-06-19 22:55:21,543:INFO:_display_container: 2
2023-06-19 22:55:21,545:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-06-19 22:55:21,545:INFO:create_model() successfully completed......................................
2023-06-19 22:55:21,655:INFO:SubProcess create_model() end ==================================
2023-06-19 22:55:21,655:INFO:Creating metrics dataframe
2023-06-19 22:55:21,663:INFO:Initializing K Neighbors Classifier
2023-06-19 22:55:21,663:INFO:Total runtime is 0.1187512199083964 minutes
2023-06-19 22:55:21,667:INFO:SubProcess create_model() called ==================================
2023-06-19 22:55:21,668:INFO:Initializing create_model()
2023-06-19 22:55:21,668:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014640B53370>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001462C72E0D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 22:55:21,668:INFO:Checking exceptions
2023-06-19 22:55:21,668:INFO:Importing libraries
2023-06-19 22:55:21,668:INFO:Copying training dataset
2023-06-19 22:55:21,691:INFO:Defining folds
2023-06-19 22:55:21,691:INFO:Declaring metric variables
2023-06-19 22:55:21,695:INFO:Importing untrained model
2023-06-19 22:55:21,698:INFO:K Neighbors Classifier Imported successfully
2023-06-19 22:55:21,708:INFO:Starting cross validation
2023-06-19 22:55:21,710:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 22:55:27,327:INFO:Calculating mean and std
2023-06-19 22:55:27,328:INFO:Creating metrics dataframe
2023-06-19 22:55:27,724:INFO:Uploading results into container
2023-06-19 22:55:27,725:INFO:Uploading model into container now
2023-06-19 22:55:27,725:INFO:_master_model_container: 2
2023-06-19 22:55:27,725:INFO:_display_container: 2
2023-06-19 22:55:27,726:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-06-19 22:55:27,726:INFO:create_model() successfully completed......................................
2023-06-19 22:55:27,836:INFO:SubProcess create_model() end ==================================
2023-06-19 22:55:27,836:INFO:Creating metrics dataframe
2023-06-19 22:55:27,843:INFO:Initializing Naive Bayes
2023-06-19 22:55:27,843:INFO:Total runtime is 0.2217516779899597 minutes
2023-06-19 22:55:27,847:INFO:SubProcess create_model() called ==================================
2023-06-19 22:55:27,848:INFO:Initializing create_model()
2023-06-19 22:55:27,848:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014640B53370>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001462C72E0D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 22:55:27,848:INFO:Checking exceptions
2023-06-19 22:55:27,848:INFO:Importing libraries
2023-06-19 22:55:27,848:INFO:Copying training dataset
2023-06-19 22:55:27,868:INFO:Defining folds
2023-06-19 22:55:27,868:INFO:Declaring metric variables
2023-06-19 22:55:27,871:INFO:Importing untrained model
2023-06-19 22:55:27,874:INFO:Naive Bayes Imported successfully
2023-06-19 22:55:27,885:INFO:Starting cross validation
2023-06-19 22:55:27,886:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 22:55:29,928:INFO:Calculating mean and std
2023-06-19 22:55:29,930:INFO:Creating metrics dataframe
2023-06-19 22:55:30,307:INFO:Uploading results into container
2023-06-19 22:55:30,308:INFO:Uploading model into container now
2023-06-19 22:55:30,308:INFO:_master_model_container: 3
2023-06-19 22:55:30,308:INFO:_display_container: 2
2023-06-19 22:55:30,309:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-06-19 22:55:30,309:INFO:create_model() successfully completed......................................
2023-06-19 22:55:30,409:INFO:SubProcess create_model() end ==================================
2023-06-19 22:55:30,409:INFO:Creating metrics dataframe
2023-06-19 22:55:30,420:INFO:Initializing Decision Tree Classifier
2023-06-19 22:55:30,420:INFO:Total runtime is 0.2646978219350179 minutes
2023-06-19 22:55:30,422:INFO:SubProcess create_model() called ==================================
2023-06-19 22:55:30,423:INFO:Initializing create_model()
2023-06-19 22:55:30,423:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014640B53370>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001462C72E0D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 22:55:30,423:INFO:Checking exceptions
2023-06-19 22:55:30,423:INFO:Importing libraries
2023-06-19 22:55:30,423:INFO:Copying training dataset
2023-06-19 22:55:30,442:INFO:Defining folds
2023-06-19 22:55:30,442:INFO:Declaring metric variables
2023-06-19 22:55:30,446:INFO:Importing untrained model
2023-06-19 22:55:30,453:INFO:Decision Tree Classifier Imported successfully
2023-06-19 22:55:30,460:INFO:Starting cross validation
2023-06-19 22:55:30,463:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 22:55:32,636:INFO:Calculating mean and std
2023-06-19 22:55:32,637:INFO:Creating metrics dataframe
2023-06-19 22:55:33,045:INFO:Uploading results into container
2023-06-19 22:55:33,046:INFO:Uploading model into container now
2023-06-19 22:55:33,046:INFO:_master_model_container: 4
2023-06-19 22:55:33,046:INFO:_display_container: 2
2023-06-19 22:55:33,047:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-06-19 22:55:33,047:INFO:create_model() successfully completed......................................
2023-06-19 22:55:33,148:INFO:SubProcess create_model() end ==================================
2023-06-19 22:55:33,148:INFO:Creating metrics dataframe
2023-06-19 22:55:33,161:INFO:Initializing SVM - Linear Kernel
2023-06-19 22:55:33,161:INFO:Total runtime is 0.3103815197944641 minutes
2023-06-19 22:55:33,165:INFO:SubProcess create_model() called ==================================
2023-06-19 22:55:33,166:INFO:Initializing create_model()
2023-06-19 22:55:33,166:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014640B53370>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001462C72E0D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 22:55:33,166:INFO:Checking exceptions
2023-06-19 22:55:33,166:INFO:Importing libraries
2023-06-19 22:55:33,166:INFO:Copying training dataset
2023-06-19 22:55:33,186:INFO:Defining folds
2023-06-19 22:55:33,186:INFO:Declaring metric variables
2023-06-19 22:55:33,190:INFO:Importing untrained model
2023-06-19 22:55:33,195:INFO:SVM - Linear Kernel Imported successfully
2023-06-19 22:55:33,205:INFO:Starting cross validation
2023-06-19 22:55:33,206:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 22:55:33,556:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-19 22:55:33,584:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-19 22:55:33,587:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-19 22:55:33,609:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-19 22:55:33,610:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-19 22:55:35,284:INFO:Calculating mean and std
2023-06-19 22:55:35,286:INFO:Creating metrics dataframe
2023-06-19 22:55:35,680:INFO:Uploading results into container
2023-06-19 22:55:35,680:INFO:Uploading model into container now
2023-06-19 22:55:35,681:INFO:_master_model_container: 5
2023-06-19 22:55:35,681:INFO:_display_container: 2
2023-06-19 22:55:35,682:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-06-19 22:55:35,682:INFO:create_model() successfully completed......................................
2023-06-19 22:55:35,788:INFO:SubProcess create_model() end ==================================
2023-06-19 22:55:35,788:INFO:Creating metrics dataframe
2023-06-19 22:55:35,799:INFO:Initializing Ridge Classifier
2023-06-19 22:55:35,799:INFO:Total runtime is 0.35434722105662025 minutes
2023-06-19 22:55:35,802:INFO:SubProcess create_model() called ==================================
2023-06-19 22:55:35,802:INFO:Initializing create_model()
2023-06-19 22:55:35,802:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014640B53370>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001462C72E0D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 22:55:35,802:INFO:Checking exceptions
2023-06-19 22:55:35,802:INFO:Importing libraries
2023-06-19 22:55:35,802:INFO:Copying training dataset
2023-06-19 22:55:35,818:INFO:Defining folds
2023-06-19 22:55:35,818:INFO:Declaring metric variables
2023-06-19 22:55:35,821:INFO:Importing untrained model
2023-06-19 22:55:35,825:INFO:Ridge Classifier Imported successfully
2023-06-19 22:55:35,835:INFO:Starting cross validation
2023-06-19 22:55:35,837:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 22:55:36,039:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-19 22:55:36,072:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-19 22:55:36,088:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-19 22:55:36,099:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-19 22:55:36,103:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-19 22:55:37,826:INFO:Calculating mean and std
2023-06-19 22:55:37,828:INFO:Creating metrics dataframe
2023-06-19 22:55:38,202:INFO:Uploading results into container
2023-06-19 22:55:38,202:INFO:Uploading model into container now
2023-06-19 22:55:38,203:INFO:_master_model_container: 6
2023-06-19 22:55:38,203:INFO:_display_container: 2
2023-06-19 22:55:38,203:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-06-19 22:55:38,204:INFO:create_model() successfully completed......................................
2023-06-19 22:55:38,303:INFO:SubProcess create_model() end ==================================
2023-06-19 22:55:38,303:INFO:Creating metrics dataframe
2023-06-19 22:55:38,314:INFO:Initializing Random Forest Classifier
2023-06-19 22:55:38,314:INFO:Total runtime is 0.39627597729365027 minutes
2023-06-19 22:55:38,317:INFO:SubProcess create_model() called ==================================
2023-06-19 22:55:38,318:INFO:Initializing create_model()
2023-06-19 22:55:38,318:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014640B53370>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001462C72E0D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 22:55:38,318:INFO:Checking exceptions
2023-06-19 22:55:38,318:INFO:Importing libraries
2023-06-19 22:55:38,318:INFO:Copying training dataset
2023-06-19 22:55:38,334:INFO:Defining folds
2023-06-19 22:55:38,335:INFO:Declaring metric variables
2023-06-19 22:55:38,342:INFO:Importing untrained model
2023-06-19 22:55:38,346:INFO:Random Forest Classifier Imported successfully
2023-06-19 22:55:38,356:INFO:Starting cross validation
2023-06-19 22:55:38,358:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 22:55:43,152:INFO:Calculating mean and std
2023-06-19 22:55:43,153:INFO:Creating metrics dataframe
2023-06-19 22:55:43,566:INFO:Uploading results into container
2023-06-19 22:55:43,567:INFO:Uploading model into container now
2023-06-19 22:55:43,567:INFO:_master_model_container: 7
2023-06-19 22:55:43,567:INFO:_display_container: 2
2023-06-19 22:55:43,568:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-19 22:55:43,568:INFO:create_model() successfully completed......................................
2023-06-19 22:55:43,669:INFO:SubProcess create_model() end ==================================
2023-06-19 22:55:43,669:INFO:Creating metrics dataframe
2023-06-19 22:55:43,679:INFO:Initializing Quadratic Discriminant Analysis
2023-06-19 22:55:43,679:INFO:Total runtime is 0.4856901129086812 minutes
2023-06-19 22:55:43,682:INFO:SubProcess create_model() called ==================================
2023-06-19 22:55:43,682:INFO:Initializing create_model()
2023-06-19 22:55:43,682:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014640B53370>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001462C72E0D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 22:55:43,682:INFO:Checking exceptions
2023-06-19 22:55:43,682:INFO:Importing libraries
2023-06-19 22:55:43,682:INFO:Copying training dataset
2023-06-19 22:55:43,698:INFO:Defining folds
2023-06-19 22:55:43,698:INFO:Declaring metric variables
2023-06-19 22:55:43,702:INFO:Importing untrained model
2023-06-19 22:55:43,705:INFO:Quadratic Discriminant Analysis Imported successfully
2023-06-19 22:55:43,716:INFO:Starting cross validation
2023-06-19 22:55:43,718:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 22:55:43,915:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-06-19 22:55:43,915:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-06-19 22:55:43,927:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-06-19 22:55:43,928:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-06-19 22:55:43,933:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-06-19 22:55:45,757:INFO:Calculating mean and std
2023-06-19 22:55:45,758:INFO:Creating metrics dataframe
2023-06-19 22:55:46,165:INFO:Uploading results into container
2023-06-19 22:55:46,166:INFO:Uploading model into container now
2023-06-19 22:55:46,166:INFO:_master_model_container: 8
2023-06-19 22:55:46,166:INFO:_display_container: 2
2023-06-19 22:55:46,167:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-06-19 22:55:46,167:INFO:create_model() successfully completed......................................
2023-06-19 22:55:46,268:INFO:SubProcess create_model() end ==================================
2023-06-19 22:55:46,269:INFO:Creating metrics dataframe
2023-06-19 22:55:46,281:INFO:Initializing Ada Boost Classifier
2023-06-19 22:55:46,281:INFO:Total runtime is 0.5290499051411947 minutes
2023-06-19 22:55:46,285:INFO:SubProcess create_model() called ==================================
2023-06-19 22:55:46,285:INFO:Initializing create_model()
2023-06-19 22:55:46,285:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014640B53370>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001462C72E0D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 22:55:46,285:INFO:Checking exceptions
2023-06-19 22:55:46,285:INFO:Importing libraries
2023-06-19 22:55:46,285:INFO:Copying training dataset
2023-06-19 22:55:46,300:INFO:Defining folds
2023-06-19 22:55:46,300:INFO:Declaring metric variables
2023-06-19 22:55:46,303:INFO:Importing untrained model
2023-06-19 22:55:46,307:INFO:Ada Boost Classifier Imported successfully
2023-06-19 22:55:46,314:INFO:Starting cross validation
2023-06-19 22:55:46,317:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 22:55:50,484:INFO:Calculating mean and std
2023-06-19 22:55:50,485:INFO:Creating metrics dataframe
2023-06-19 22:55:50,896:INFO:Uploading results into container
2023-06-19 22:55:50,896:INFO:Uploading model into container now
2023-06-19 22:55:50,897:INFO:_master_model_container: 9
2023-06-19 22:55:50,897:INFO:_display_container: 2
2023-06-19 22:55:50,898:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-06-19 22:55:50,898:INFO:create_model() successfully completed......................................
2023-06-19 22:55:51,005:INFO:SubProcess create_model() end ==================================
2023-06-19 22:55:51,005:INFO:Creating metrics dataframe
2023-06-19 22:55:51,017:INFO:Initializing Gradient Boosting Classifier
2023-06-19 22:55:51,017:INFO:Total runtime is 0.6079852104187011 minutes
2023-06-19 22:55:51,021:INFO:SubProcess create_model() called ==================================
2023-06-19 22:55:51,021:INFO:Initializing create_model()
2023-06-19 22:55:51,021:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014640B53370>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001462C72E0D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 22:55:51,022:INFO:Checking exceptions
2023-06-19 22:55:51,022:INFO:Importing libraries
2023-06-19 22:55:51,022:INFO:Copying training dataset
2023-06-19 22:55:51,040:INFO:Defining folds
2023-06-19 22:55:51,040:INFO:Declaring metric variables
2023-06-19 22:55:51,047:INFO:Importing untrained model
2023-06-19 22:55:51,051:INFO:Gradient Boosting Classifier Imported successfully
2023-06-19 22:55:51,058:INFO:Starting cross validation
2023-06-19 22:55:51,060:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 22:56:00,493:INFO:Calculating mean and std
2023-06-19 22:56:00,494:INFO:Creating metrics dataframe
2023-06-19 22:56:00,915:INFO:Uploading results into container
2023-06-19 22:56:00,916:INFO:Uploading model into container now
2023-06-19 22:56:00,916:INFO:_master_model_container: 10
2023-06-19 22:56:00,916:INFO:_display_container: 2
2023-06-19 22:56:00,916:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-19 22:56:00,916:INFO:create_model() successfully completed......................................
2023-06-19 22:56:01,016:INFO:SubProcess create_model() end ==================================
2023-06-19 22:56:01,016:INFO:Creating metrics dataframe
2023-06-19 22:56:01,029:INFO:Initializing Linear Discriminant Analysis
2023-06-19 22:56:01,029:INFO:Total runtime is 0.7748536229133606 minutes
2023-06-19 22:56:01,033:INFO:SubProcess create_model() called ==================================
2023-06-19 22:56:01,034:INFO:Initializing create_model()
2023-06-19 22:56:01,034:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014640B53370>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001462C72E0D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 22:56:01,034:INFO:Checking exceptions
2023-06-19 22:56:01,034:INFO:Importing libraries
2023-06-19 22:56:01,034:INFO:Copying training dataset
2023-06-19 22:56:01,053:INFO:Defining folds
2023-06-19 22:56:01,053:INFO:Declaring metric variables
2023-06-19 22:56:01,058:INFO:Importing untrained model
2023-06-19 22:56:01,062:INFO:Linear Discriminant Analysis Imported successfully
2023-06-19 22:56:01,071:INFO:Starting cross validation
2023-06-19 22:56:01,072:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 22:56:03,606:INFO:Calculating mean and std
2023-06-19 22:56:03,607:INFO:Creating metrics dataframe
2023-06-19 22:56:04,023:INFO:Uploading results into container
2023-06-19 22:56:04,024:INFO:Uploading model into container now
2023-06-19 22:56:04,025:INFO:_master_model_container: 11
2023-06-19 22:56:04,025:INFO:_display_container: 2
2023-06-19 22:56:04,026:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-06-19 22:56:04,026:INFO:create_model() successfully completed......................................
2023-06-19 22:56:04,131:INFO:SubProcess create_model() end ==================================
2023-06-19 22:56:04,132:INFO:Creating metrics dataframe
2023-06-19 22:56:04,144:INFO:Initializing Extra Trees Classifier
2023-06-19 22:56:04,144:INFO:Total runtime is 0.8267635107040405 minutes
2023-06-19 22:56:04,147:INFO:SubProcess create_model() called ==================================
2023-06-19 22:56:04,148:INFO:Initializing create_model()
2023-06-19 22:56:04,148:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014640B53370>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001462C72E0D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 22:56:04,148:INFO:Checking exceptions
2023-06-19 22:56:04,148:INFO:Importing libraries
2023-06-19 22:56:04,148:INFO:Copying training dataset
2023-06-19 22:56:04,167:INFO:Defining folds
2023-06-19 22:56:04,167:INFO:Declaring metric variables
2023-06-19 22:56:04,171:INFO:Importing untrained model
2023-06-19 22:56:04,177:INFO:Extra Trees Classifier Imported successfully
2023-06-19 22:56:04,185:INFO:Starting cross validation
2023-06-19 22:56:04,186:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 22:56:06,182:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 22:56:09,126:INFO:Calculating mean and std
2023-06-19 22:56:09,126:INFO:Creating metrics dataframe
2023-06-19 22:56:09,541:INFO:Uploading results into container
2023-06-19 22:56:09,541:INFO:Uploading model into container now
2023-06-19 22:56:09,541:INFO:_master_model_container: 12
2023-06-19 22:56:09,541:INFO:_display_container: 2
2023-06-19 22:56:09,541:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-06-19 22:56:09,541:INFO:create_model() successfully completed......................................
2023-06-19 22:56:09,648:INFO:SubProcess create_model() end ==================================
2023-06-19 22:56:09,648:INFO:Creating metrics dataframe
2023-06-19 22:56:09,663:INFO:Initializing Light Gradient Boosting Machine
2023-06-19 22:56:09,663:INFO:Total runtime is 0.9187502344449361 minutes
2023-06-19 22:56:09,667:INFO:SubProcess create_model() called ==================================
2023-06-19 22:56:09,667:INFO:Initializing create_model()
2023-06-19 22:56:09,668:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014640B53370>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001462C72E0D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 22:56:09,668:INFO:Checking exceptions
2023-06-19 22:56:09,668:INFO:Importing libraries
2023-06-19 22:56:09,668:INFO:Copying training dataset
2023-06-19 22:56:09,686:INFO:Defining folds
2023-06-19 22:56:09,686:INFO:Declaring metric variables
2023-06-19 22:56:09,691:INFO:Importing untrained model
2023-06-19 22:56:09,695:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-19 22:56:09,707:INFO:Starting cross validation
2023-06-19 22:56:09,710:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 22:56:13,567:INFO:Calculating mean and std
2023-06-19 22:56:13,568:INFO:Creating metrics dataframe
2023-06-19 22:56:14,023:INFO:Uploading results into container
2023-06-19 22:56:14,025:INFO:Uploading model into container now
2023-06-19 22:56:14,025:INFO:_master_model_container: 13
2023-06-19 22:56:14,025:INFO:_display_container: 2
2023-06-19 22:56:14,026:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-19 22:56:14,026:INFO:create_model() successfully completed......................................
2023-06-19 22:56:14,129:INFO:SubProcess create_model() end ==================================
2023-06-19 22:56:14,129:INFO:Creating metrics dataframe
2023-06-19 22:56:14,141:INFO:Initializing Dummy Classifier
2023-06-19 22:56:14,141:INFO:Total runtime is 0.9933882673581441 minutes
2023-06-19 22:56:14,145:INFO:SubProcess create_model() called ==================================
2023-06-19 22:56:14,145:INFO:Initializing create_model()
2023-06-19 22:56:14,145:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014640B53370>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001462C72E0D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 22:56:14,145:INFO:Checking exceptions
2023-06-19 22:56:14,145:INFO:Importing libraries
2023-06-19 22:56:14,146:INFO:Copying training dataset
2023-06-19 22:56:14,162:INFO:Defining folds
2023-06-19 22:56:14,162:INFO:Declaring metric variables
2023-06-19 22:56:14,165:INFO:Importing untrained model
2023-06-19 22:56:14,170:INFO:Dummy Classifier Imported successfully
2023-06-19 22:56:14,178:INFO:Starting cross validation
2023-06-19 22:56:14,180:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 22:56:14,431:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 22:56:14,464:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 22:56:14,475:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 22:56:14,483:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 22:56:14,526:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 22:56:16,659:INFO:Calculating mean and std
2023-06-19 22:56:16,661:INFO:Creating metrics dataframe
2023-06-19 22:56:17,092:INFO:Uploading results into container
2023-06-19 22:56:17,093:INFO:Uploading model into container now
2023-06-19 22:56:17,093:INFO:_master_model_container: 14
2023-06-19 22:56:17,093:INFO:_display_container: 2
2023-06-19 22:56:17,093:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-06-19 22:56:17,093:INFO:create_model() successfully completed......................................
2023-06-19 22:56:17,194:INFO:SubProcess create_model() end ==================================
2023-06-19 22:56:17,195:INFO:Creating metrics dataframe
2023-06-19 22:56:17,220:INFO:Initializing create_model()
2023-06-19 22:56:17,220:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014640B53370>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-19 22:56:17,221:INFO:Checking exceptions
2023-06-19 22:56:17,224:INFO:Importing libraries
2023-06-19 22:56:17,224:INFO:Copying training dataset
2023-06-19 22:56:17,238:INFO:Defining folds
2023-06-19 22:56:17,238:INFO:Declaring metric variables
2023-06-19 22:56:17,239:INFO:Importing untrained model
2023-06-19 22:56:17,239:INFO:Declaring custom model
2023-06-19 22:56:17,240:INFO:Random Forest Classifier Imported successfully
2023-06-19 22:56:17,241:INFO:Cross validation set to False
2023-06-19 22:56:17,242:INFO:Fitting Model
2023-06-19 22:56:18,777:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-19 22:56:18,777:INFO:create_model() successfully completed......................................
2023-06-19 22:56:18,906:INFO:_master_model_container: 14
2023-06-19 22:56:18,906:INFO:_display_container: 2
2023-06-19 22:56:18,907:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-19 22:56:18,907:INFO:compare_models() successfully completed......................................
2023-06-19 22:56:31,565:INFO:Initializing create_model()
2023-06-19 22:56:31,565:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014640B53370>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-19 22:56:31,565:INFO:Checking exceptions
2023-06-19 22:56:31,605:INFO:Importing libraries
2023-06-19 22:56:31,605:INFO:Copying training dataset
2023-06-19 22:56:31,634:INFO:Defining folds
2023-06-19 22:56:31,634:INFO:Declaring metric variables
2023-06-19 22:56:31,639:INFO:Importing untrained model
2023-06-19 22:56:31,655:INFO:Random Forest Classifier Imported successfully
2023-06-19 22:56:31,664:INFO:Starting cross validation
2023-06-19 22:56:31,666:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 22:56:34,109:INFO:Calculating mean and std
2023-06-19 22:56:34,110:INFO:Creating metrics dataframe
2023-06-19 22:56:34,114:INFO:Finalizing model
2023-06-19 22:56:34,713:INFO:Uploading results into container
2023-06-19 22:56:34,714:INFO:Uploading model into container now
2023-06-19 22:56:34,725:INFO:_master_model_container: 15
2023-06-19 22:56:34,725:INFO:_display_container: 3
2023-06-19 22:56:34,725:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-19 22:56:34,726:INFO:create_model() successfully completed......................................
2023-06-19 22:56:34,834:INFO:Initializing predict_model()
2023-06-19 22:56:34,834:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014640B53370>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001464683ED30>)
2023-06-19 22:56:34,834:INFO:Checking exceptions
2023-06-19 22:56:34,834:INFO:Preloading libraries
2023-06-19 22:56:34,838:INFO:Set up data.
2023-06-19 22:56:34,856:INFO:Set up index.
2023-06-19 23:22:55,530:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-19 23:22:55,530:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-19 23:22:55,531:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-19 23:22:55,531:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-19 23:22:56,155:INFO:Soft dependency imported: prophet: 1.1.4
2023-06-19 23:22:56,710:INFO:PyCaret ClassificationExperiment
2023-06-19 23:22:56,710:INFO:Logging name: clf-default-name
2023-06-19 23:22:56,710:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-19 23:22:56,710:INFO:version 3.0.2
2023-06-19 23:22:56,710:INFO:Initializing setup()
2023-06-19 23:22:56,710:INFO:self.USI: 01be
2023-06-19 23:22:56,710:INFO:self._variable_keys: {'fix_imbalance', 'seed', 'fold_groups_param', 'html_param', 'is_multiclass', 'log_plots_param', 'n_jobs_param', 'y', 'X_test', 'gpu_n_jobs_param', 'y_test', 'exp_id', '_available_plots', 'data', 'X_train', 'logging_param', 'exp_name_log', 'pipeline', 'fold_shuffle_param', 'USI', 'idx', 'y_train', 'X', 'fold_generator', 'memory', 'target_param', '_ml_usecase', 'gpu_param'}
2023-06-19 23:22:56,710:INFO:Checking environment
2023-06-19 23:22:56,710:INFO:python_version: 3.8.12
2023-06-19 23:22:56,710:INFO:python_build: ('default', 'Oct 12 2021 03:01:40')
2023-06-19 23:22:56,710:INFO:machine: AMD64
2023-06-19 23:22:56,710:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-19 23:22:56,711:INFO:Memory: svmem(total=16861405184, available=6269816832, percent=62.8, used=10591588352, free=6269816832)
2023-06-19 23:22:56,711:INFO:Physical Core: 4
2023-06-19 23:22:56,711:INFO:Logical Core: 8
2023-06-19 23:22:56,711:INFO:Checking libraries
2023-06-19 23:22:56,711:INFO:System:
2023-06-19 23:22:56,711:INFO:    python: 3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]
2023-06-19 23:22:56,711:INFO:executable: c:\Users\choib\anaconda3\envs\iise-python\python.exe
2023-06-19 23:22:56,711:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-19 23:22:56,711:INFO:PyCaret required dependencies:
2023-06-19 23:22:56,712:INFO:                 pip: 21.0.1
2023-06-19 23:22:56,712:INFO:          setuptools: 58.0.4
2023-06-19 23:22:56,712:INFO:             pycaret: 3.0.2
2023-06-19 23:22:56,712:INFO:             IPython: 8.12.0
2023-06-19 23:22:56,712:INFO:          ipywidgets: 8.0.6
2023-06-19 23:22:56,712:INFO:                tqdm: 4.65.0
2023-06-19 23:22:56,712:INFO:               numpy: 1.21.4
2023-06-19 23:22:56,712:INFO:              pandas: 1.5.3
2023-06-19 23:22:56,712:INFO:              jinja2: 3.1.2
2023-06-19 23:22:56,712:INFO:               scipy: 1.10.1
2023-06-19 23:22:56,712:INFO:              joblib: 1.2.0
2023-06-19 23:22:56,713:INFO:             sklearn: 1.2.2
2023-06-19 23:22:56,713:INFO:                pyod: 1.0.9
2023-06-19 23:22:56,713:INFO:            imblearn: 0.10.1
2023-06-19 23:22:56,713:INFO:   category_encoders: 2.6.1
2023-06-19 23:22:56,713:INFO:            lightgbm: 3.3.5
2023-06-19 23:22:56,713:INFO:               numba: 0.57.0
2023-06-19 23:22:56,713:INFO:            requests: 2.31.0
2023-06-19 23:22:56,713:INFO:          matplotlib: 3.4.3
2023-06-19 23:22:56,714:INFO:          scikitplot: 0.3.7
2023-06-19 23:22:56,714:INFO:         yellowbrick: 1.5
2023-06-19 23:22:56,714:INFO:              plotly: 5.15.0
2023-06-19 23:22:56,714:INFO:             kaleido: 0.2.1
2023-06-19 23:22:56,714:INFO:         statsmodels: 0.14.0
2023-06-19 23:22:56,714:INFO:              sktime: 0.17.0
2023-06-19 23:22:56,714:INFO:               tbats: 1.1.3
2023-06-19 23:22:56,714:INFO:            pmdarima: 2.0.3
2023-06-19 23:22:56,714:INFO:              psutil: 5.9.0
2023-06-19 23:22:56,714:INFO:PyCaret optional dependencies:
2023-06-19 23:22:56,740:INFO:                shap: Not installed
2023-06-19 23:22:56,740:INFO:           interpret: Not installed
2023-06-19 23:22:56,740:INFO:                umap: Not installed
2023-06-19 23:22:56,740:INFO:    pandas_profiling: Not installed
2023-06-19 23:22:56,740:INFO:  explainerdashboard: Not installed
2023-06-19 23:22:56,740:INFO:             autoviz: Not installed
2023-06-19 23:22:56,740:INFO:           fairlearn: Not installed
2023-06-19 23:22:56,740:INFO:             xgboost: Not installed
2023-06-19 23:22:56,740:INFO:            catboost: Not installed
2023-06-19 23:22:56,740:INFO:              kmodes: Not installed
2023-06-19 23:22:56,740:INFO:             mlxtend: Not installed
2023-06-19 23:22:56,740:INFO:       statsforecast: Not installed
2023-06-19 23:22:56,740:INFO:        tune_sklearn: Not installed
2023-06-19 23:22:56,740:INFO:                 ray: Not installed
2023-06-19 23:22:56,740:INFO:            hyperopt: Not installed
2023-06-19 23:22:56,741:INFO:              optuna: Not installed
2023-06-19 23:22:56,741:INFO:               skopt: Not installed
2023-06-19 23:22:56,741:INFO:              mlflow: Not installed
2023-06-19 23:22:56,741:INFO:              gradio: Not installed
2023-06-19 23:22:56,741:INFO:             fastapi: Not installed
2023-06-19 23:22:56,741:INFO:             uvicorn: Not installed
2023-06-19 23:22:56,741:INFO:              m2cgen: Not installed
2023-06-19 23:22:56,741:INFO:           evidently: Not installed
2023-06-19 23:22:56,741:INFO:               fugue: Not installed
2023-06-19 23:22:56,741:INFO:           streamlit: Not installed
2023-06-19 23:22:56,741:INFO:             prophet: 1.1.4
2023-06-19 23:22:56,741:INFO:None
2023-06-19 23:22:56,741:INFO:Set up data.
2023-06-19 23:22:56,775:INFO:Set up train/test split.
2023-06-19 23:22:56,807:INFO:Set up index.
2023-06-19 23:22:56,808:INFO:Set up folding strategy.
2023-06-19 23:22:56,809:INFO:Assigning column types.
2023-06-19 23:22:56,826:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-19 23:22:56,873:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-19 23:22:56,876:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-19 23:22:56,947:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 23:22:56,965:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 23:22:57,019:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-19 23:22:57,020:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-19 23:22:57,066:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 23:22:57,066:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 23:22:57,066:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-19 23:22:57,109:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-19 23:22:57,132:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 23:22:57,132:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 23:22:57,181:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-19 23:22:57,204:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 23:22:57,204:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 23:22:57,204:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-19 23:22:57,267:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 23:22:57,267:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 23:22:57,331:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 23:22:57,331:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 23:22:57,335:INFO:Preparing preprocessing pipeline...
2023-06-19 23:22:57,338:INFO:Set up simple imputation.
2023-06-19 23:22:57,346:INFO:Set up encoding of categorical features.
2023-06-19 23:22:57,346:INFO:Set up feature normalization.
2023-06-19 23:22:57,532:INFO:Finished creating preprocessing pipeline.
2023-06-19 23:22:57,539:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\choib\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['disk_id', 'r_1', 'n_5', 'r_5',
                                             'r_9', 'r_12', 'n_171', 'r_171',
                                             'n_172', 'r_172', 'n_173', 'r_174',
                                             'n_180', 'r_180', 'n_184', 'r_184',
                                             'r_187', 'r_188', 'n_190', 'r_190',
                                             'r_194', 'r_195', 'n_196', 'r_196',
                                             'r_197', 'r_198', 'r...
                 TransformerWrapper(exclude=None, include=['ds'],
                                    transformer=TargetEncoder(cols=['ds'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1))))],
         verbose=False)
2023-06-19 23:22:57,539:INFO:Creating final display dataframe.
2023-06-19 23:22:57,981:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             label
2                   Target type            Binary
3           Original data shape       (52838, 31)
4        Transformed data shape       (52838, 31)
5   Transformed train set shape       (36986, 31)
6    Transformed test set shape       (15852, 31)
7              Numeric features                29
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            minmax
17               Fold Generator   StratifiedKFold
18                  Fold Number                 5
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              01be
2023-06-19 23:22:58,057:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 23:22:58,057:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 23:22:58,121:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 23:22:58,122:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-19 23:22:58,122:INFO:setup() successfully completed in 1.79s...............
2023-06-19 23:22:58,122:INFO:Initializing compare_models()
2023-06-19 23:22:58,122:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A8E53E880>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000021A8E53E880>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-06-19 23:22:58,123:INFO:Checking exceptions
2023-06-19 23:22:58,135:INFO:Preparing display monitor
2023-06-19 23:22:58,175:INFO:Initializing Logistic Regression
2023-06-19 23:22:58,176:INFO:Total runtime is 1.6669432322184246e-05 minutes
2023-06-19 23:22:58,179:INFO:SubProcess create_model() called ==================================
2023-06-19 23:22:58,179:INFO:Initializing create_model()
2023-06-19 23:22:58,179:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A8E53E880>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AF6BF92E0>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 23:22:58,179:INFO:Checking exceptions
2023-06-19 23:22:58,180:INFO:Importing libraries
2023-06-19 23:22:58,180:INFO:Copying training dataset
2023-06-19 23:22:58,204:INFO:Defining folds
2023-06-19 23:22:58,204:INFO:Declaring metric variables
2023-06-19 23:22:58,207:INFO:Importing untrained model
2023-06-19 23:22:58,211:INFO:Logistic Regression Imported successfully
2023-06-19 23:22:58,219:INFO:Starting cross validation
2023-06-19 23:22:58,221:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 23:23:05,250:INFO:Calculating mean and std
2023-06-19 23:23:05,252:INFO:Creating metrics dataframe
2023-06-19 23:23:05,741:INFO:Uploading results into container
2023-06-19 23:23:05,743:INFO:Uploading model into container now
2023-06-19 23:23:05,743:INFO:_master_model_container: 1
2023-06-19 23:23:05,743:INFO:_display_container: 2
2023-06-19 23:23:05,743:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-06-19 23:23:05,744:INFO:create_model() successfully completed......................................
2023-06-19 23:23:05,831:INFO:SubProcess create_model() end ==================================
2023-06-19 23:23:05,831:INFO:Creating metrics dataframe
2023-06-19 23:23:05,841:INFO:Initializing K Neighbors Classifier
2023-06-19 23:23:05,841:INFO:Total runtime is 0.12776768604914346 minutes
2023-06-19 23:23:05,845:INFO:SubProcess create_model() called ==================================
2023-06-19 23:23:05,846:INFO:Initializing create_model()
2023-06-19 23:23:05,846:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A8E53E880>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AF6BF92E0>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 23:23:05,846:INFO:Checking exceptions
2023-06-19 23:23:05,847:INFO:Importing libraries
2023-06-19 23:23:05,847:INFO:Copying training dataset
2023-06-19 23:23:05,881:INFO:Defining folds
2023-06-19 23:23:05,881:INFO:Declaring metric variables
2023-06-19 23:23:05,886:INFO:Importing untrained model
2023-06-19 23:23:05,891:INFO:K Neighbors Classifier Imported successfully
2023-06-19 23:23:05,901:INFO:Starting cross validation
2023-06-19 23:23:05,903:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 23:23:13,858:INFO:Calculating mean and std
2023-06-19 23:23:13,859:INFO:Creating metrics dataframe
2023-06-19 23:23:14,288:INFO:Uploading results into container
2023-06-19 23:23:14,289:INFO:Uploading model into container now
2023-06-19 23:23:14,290:INFO:_master_model_container: 2
2023-06-19 23:23:14,290:INFO:_display_container: 2
2023-06-19 23:23:14,290:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-06-19 23:23:14,291:INFO:create_model() successfully completed......................................
2023-06-19 23:23:14,358:INFO:SubProcess create_model() end ==================================
2023-06-19 23:23:14,358:INFO:Creating metrics dataframe
2023-06-19 23:23:14,366:INFO:Initializing Naive Bayes
2023-06-19 23:23:14,366:INFO:Total runtime is 0.2698545376459757 minutes
2023-06-19 23:23:14,369:INFO:SubProcess create_model() called ==================================
2023-06-19 23:23:14,369:INFO:Initializing create_model()
2023-06-19 23:23:14,369:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A8E53E880>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AF6BF92E0>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 23:23:14,370:INFO:Checking exceptions
2023-06-19 23:23:14,370:INFO:Importing libraries
2023-06-19 23:23:14,370:INFO:Copying training dataset
2023-06-19 23:23:14,393:INFO:Defining folds
2023-06-19 23:23:14,393:INFO:Declaring metric variables
2023-06-19 23:23:14,398:INFO:Importing untrained model
2023-06-19 23:23:14,402:INFO:Naive Bayes Imported successfully
2023-06-19 23:23:14,408:INFO:Starting cross validation
2023-06-19 23:23:14,410:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 23:23:16,795:INFO:Calculating mean and std
2023-06-19 23:23:16,798:INFO:Creating metrics dataframe
2023-06-19 23:23:17,270:INFO:Uploading results into container
2023-06-19 23:23:17,271:INFO:Uploading model into container now
2023-06-19 23:23:17,272:INFO:_master_model_container: 3
2023-06-19 23:23:17,272:INFO:_display_container: 2
2023-06-19 23:23:17,272:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-06-19 23:23:17,272:INFO:create_model() successfully completed......................................
2023-06-19 23:23:17,338:INFO:SubProcess create_model() end ==================================
2023-06-19 23:23:17,338:INFO:Creating metrics dataframe
2023-06-19 23:23:17,347:INFO:Initializing Decision Tree Classifier
2023-06-19 23:23:17,347:INFO:Total runtime is 0.3195419629414876 minutes
2023-06-19 23:23:17,350:INFO:SubProcess create_model() called ==================================
2023-06-19 23:23:17,350:INFO:Initializing create_model()
2023-06-19 23:23:17,350:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A8E53E880>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AF6BF92E0>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 23:23:17,350:INFO:Checking exceptions
2023-06-19 23:23:17,350:INFO:Importing libraries
2023-06-19 23:23:17,350:INFO:Copying training dataset
2023-06-19 23:23:17,372:INFO:Defining folds
2023-06-19 23:23:17,372:INFO:Declaring metric variables
2023-06-19 23:23:17,375:INFO:Importing untrained model
2023-06-19 23:23:17,381:INFO:Decision Tree Classifier Imported successfully
2023-06-19 23:23:17,387:INFO:Starting cross validation
2023-06-19 23:23:17,389:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 23:23:20,122:INFO:Calculating mean and std
2023-06-19 23:23:20,123:INFO:Creating metrics dataframe
2023-06-19 23:23:20,608:INFO:Uploading results into container
2023-06-19 23:23:20,610:INFO:Uploading model into container now
2023-06-19 23:23:20,611:INFO:_master_model_container: 4
2023-06-19 23:23:20,611:INFO:_display_container: 2
2023-06-19 23:23:20,612:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-06-19 23:23:20,612:INFO:create_model() successfully completed......................................
2023-06-19 23:23:20,678:INFO:SubProcess create_model() end ==================================
2023-06-19 23:23:20,679:INFO:Creating metrics dataframe
2023-06-19 23:23:20,687:INFO:Initializing SVM - Linear Kernel
2023-06-19 23:23:20,687:INFO:Total runtime is 0.3752064069112142 minutes
2023-06-19 23:23:20,690:INFO:SubProcess create_model() called ==================================
2023-06-19 23:23:20,690:INFO:Initializing create_model()
2023-06-19 23:23:20,690:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A8E53E880>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AF6BF92E0>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 23:23:20,690:INFO:Checking exceptions
2023-06-19 23:23:20,690:INFO:Importing libraries
2023-06-19 23:23:20,691:INFO:Copying training dataset
2023-06-19 23:23:20,714:INFO:Defining folds
2023-06-19 23:23:20,714:INFO:Declaring metric variables
2023-06-19 23:23:20,717:INFO:Importing untrained model
2023-06-19 23:23:20,721:INFO:SVM - Linear Kernel Imported successfully
2023-06-19 23:23:20,727:INFO:Starting cross validation
2023-06-19 23:23:20,730:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 23:23:21,252:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-19 23:23:21,258:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 23:23:21,283:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-19 23:23:21,283:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-19 23:23:21,285:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-19 23:23:21,289:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 23:23:21,291:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 23:23:21,295:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 23:23:21,347:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-19 23:23:21,356:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 23:23:23,190:INFO:Calculating mean and std
2023-06-19 23:23:23,192:INFO:Creating metrics dataframe
2023-06-19 23:23:23,655:INFO:Uploading results into container
2023-06-19 23:23:23,656:INFO:Uploading model into container now
2023-06-19 23:23:23,656:INFO:_master_model_container: 5
2023-06-19 23:23:23,656:INFO:_display_container: 2
2023-06-19 23:23:23,657:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-06-19 23:23:23,658:INFO:create_model() successfully completed......................................
2023-06-19 23:23:23,725:INFO:SubProcess create_model() end ==================================
2023-06-19 23:23:23,725:INFO:Creating metrics dataframe
2023-06-19 23:23:23,734:INFO:Initializing Ridge Classifier
2023-06-19 23:23:23,734:INFO:Total runtime is 0.42599500020345055 minutes
2023-06-19 23:23:23,739:INFO:SubProcess create_model() called ==================================
2023-06-19 23:23:23,740:INFO:Initializing create_model()
2023-06-19 23:23:23,740:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A8E53E880>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AF6BF92E0>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 23:23:23,740:INFO:Checking exceptions
2023-06-19 23:23:23,740:INFO:Importing libraries
2023-06-19 23:23:23,741:INFO:Copying training dataset
2023-06-19 23:23:23,762:INFO:Defining folds
2023-06-19 23:23:23,762:INFO:Declaring metric variables
2023-06-19 23:23:23,767:INFO:Importing untrained model
2023-06-19 23:23:23,771:INFO:Ridge Classifier Imported successfully
2023-06-19 23:23:23,777:INFO:Starting cross validation
2023-06-19 23:23:23,779:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 23:23:24,156:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-19 23:23:24,163:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-19 23:23:24,164:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 23:23:24,183:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-19 23:23:24,186:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-19 23:23:24,193:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 23:23:24,196:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 23:23:24,229:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-19 23:23:24,237:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 23:23:26,068:INFO:Calculating mean and std
2023-06-19 23:23:26,069:INFO:Creating metrics dataframe
2023-06-19 23:23:26,572:INFO:Uploading results into container
2023-06-19 23:23:26,572:INFO:Uploading model into container now
2023-06-19 23:23:26,573:INFO:_master_model_container: 6
2023-06-19 23:23:26,573:INFO:_display_container: 2
2023-06-19 23:23:26,573:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-06-19 23:23:26,574:INFO:create_model() successfully completed......................................
2023-06-19 23:23:26,645:INFO:SubProcess create_model() end ==================================
2023-06-19 23:23:26,646:INFO:Creating metrics dataframe
2023-06-19 23:23:26,657:INFO:Initializing Random Forest Classifier
2023-06-19 23:23:26,657:INFO:Total runtime is 0.4747020443280538 minutes
2023-06-19 23:23:26,660:INFO:SubProcess create_model() called ==================================
2023-06-19 23:23:26,660:INFO:Initializing create_model()
2023-06-19 23:23:26,660:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A8E53E880>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AF6BF92E0>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 23:23:26,660:INFO:Checking exceptions
2023-06-19 23:23:26,660:INFO:Importing libraries
2023-06-19 23:23:26,660:INFO:Copying training dataset
2023-06-19 23:23:26,680:INFO:Defining folds
2023-06-19 23:23:26,681:INFO:Declaring metric variables
2023-06-19 23:23:26,685:INFO:Importing untrained model
2023-06-19 23:23:26,694:INFO:Random Forest Classifier Imported successfully
2023-06-19 23:23:26,703:INFO:Starting cross validation
2023-06-19 23:23:26,706:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 23:23:35,574:INFO:Calculating mean and std
2023-06-19 23:23:35,575:INFO:Creating metrics dataframe
2023-06-19 23:23:36,182:INFO:Uploading results into container
2023-06-19 23:23:36,184:INFO:Uploading model into container now
2023-06-19 23:23:36,185:INFO:_master_model_container: 7
2023-06-19 23:23:36,185:INFO:_display_container: 2
2023-06-19 23:23:36,186:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-19 23:23:36,186:INFO:create_model() successfully completed......................................
2023-06-19 23:23:36,264:INFO:SubProcess create_model() end ==================================
2023-06-19 23:23:36,264:INFO:Creating metrics dataframe
2023-06-19 23:23:36,275:INFO:Initializing Quadratic Discriminant Analysis
2023-06-19 23:23:36,276:INFO:Total runtime is 0.6350179791450501 minutes
2023-06-19 23:23:36,280:INFO:SubProcess create_model() called ==================================
2023-06-19 23:23:36,281:INFO:Initializing create_model()
2023-06-19 23:23:36,281:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A8E53E880>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AF6BF92E0>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 23:23:36,281:INFO:Checking exceptions
2023-06-19 23:23:36,281:INFO:Importing libraries
2023-06-19 23:23:36,281:INFO:Copying training dataset
2023-06-19 23:23:36,307:INFO:Defining folds
2023-06-19 23:23:36,308:INFO:Declaring metric variables
2023-06-19 23:23:36,313:INFO:Importing untrained model
2023-06-19 23:23:36,318:INFO:Quadratic Discriminant Analysis Imported successfully
2023-06-19 23:23:36,327:INFO:Starting cross validation
2023-06-19 23:23:36,329:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 23:23:36,680:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-06-19 23:23:36,690:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-06-19 23:23:36,701:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-06-19 23:23:36,715:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-06-19 23:23:36,749:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-06-19 23:23:39,435:INFO:Calculating mean and std
2023-06-19 23:23:39,435:INFO:Creating metrics dataframe
2023-06-19 23:23:39,905:INFO:Uploading results into container
2023-06-19 23:23:39,906:INFO:Uploading model into container now
2023-06-19 23:23:39,907:INFO:_master_model_container: 8
2023-06-19 23:23:39,907:INFO:_display_container: 2
2023-06-19 23:23:39,907:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-06-19 23:23:39,907:INFO:create_model() successfully completed......................................
2023-06-19 23:23:39,979:INFO:SubProcess create_model() end ==================================
2023-06-19 23:23:39,980:INFO:Creating metrics dataframe
2023-06-19 23:23:39,991:INFO:Initializing Ada Boost Classifier
2023-06-19 23:23:39,991:INFO:Total runtime is 0.6969465176264446 minutes
2023-06-19 23:23:39,995:INFO:SubProcess create_model() called ==================================
2023-06-19 23:23:39,995:INFO:Initializing create_model()
2023-06-19 23:23:39,995:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A8E53E880>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AF6BF92E0>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 23:23:39,996:INFO:Checking exceptions
2023-06-19 23:23:39,996:INFO:Importing libraries
2023-06-19 23:23:39,996:INFO:Copying training dataset
2023-06-19 23:23:40,016:INFO:Defining folds
2023-06-19 23:23:40,017:INFO:Declaring metric variables
2023-06-19 23:23:40,021:INFO:Importing untrained model
2023-06-19 23:23:40,026:INFO:Ada Boost Classifier Imported successfully
2023-06-19 23:23:40,033:INFO:Starting cross validation
2023-06-19 23:23:40,035:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 23:23:45,981:INFO:Calculating mean and std
2023-06-19 23:23:45,982:INFO:Creating metrics dataframe
2023-06-19 23:23:46,419:INFO:Uploading results into container
2023-06-19 23:23:46,420:INFO:Uploading model into container now
2023-06-19 23:23:46,421:INFO:_master_model_container: 9
2023-06-19 23:23:46,421:INFO:_display_container: 2
2023-06-19 23:23:46,421:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-06-19 23:23:46,421:INFO:create_model() successfully completed......................................
2023-06-19 23:23:46,487:INFO:SubProcess create_model() end ==================================
2023-06-19 23:23:46,487:INFO:Creating metrics dataframe
2023-06-19 23:23:46,500:INFO:Initializing Gradient Boosting Classifier
2023-06-19 23:23:46,500:INFO:Total runtime is 0.8054295301437379 minutes
2023-06-19 23:23:46,504:INFO:SubProcess create_model() called ==================================
2023-06-19 23:23:46,504:INFO:Initializing create_model()
2023-06-19 23:23:46,504:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A8E53E880>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AF6BF92E0>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 23:23:46,504:INFO:Checking exceptions
2023-06-19 23:23:46,504:INFO:Importing libraries
2023-06-19 23:23:46,504:INFO:Copying training dataset
2023-06-19 23:23:46,526:INFO:Defining folds
2023-06-19 23:23:46,527:INFO:Declaring metric variables
2023-06-19 23:23:46,532:INFO:Importing untrained model
2023-06-19 23:23:46,534:INFO:Gradient Boosting Classifier Imported successfully
2023-06-19 23:23:46,542:INFO:Starting cross validation
2023-06-19 23:23:46,544:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 23:24:00,739:INFO:Calculating mean and std
2023-06-19 23:24:00,741:INFO:Creating metrics dataframe
2023-06-19 23:24:01,254:INFO:Uploading results into container
2023-06-19 23:24:01,255:INFO:Uploading model into container now
2023-06-19 23:24:01,255:INFO:_master_model_container: 10
2023-06-19 23:24:01,256:INFO:_display_container: 2
2023-06-19 23:24:01,256:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-19 23:24:01,256:INFO:create_model() successfully completed......................................
2023-06-19 23:24:01,324:INFO:SubProcess create_model() end ==================================
2023-06-19 23:24:01,325:INFO:Creating metrics dataframe
2023-06-19 23:24:01,336:INFO:Initializing Linear Discriminant Analysis
2023-06-19 23:24:01,336:INFO:Total runtime is 1.0526873071988425 minutes
2023-06-19 23:24:01,341:INFO:SubProcess create_model() called ==================================
2023-06-19 23:24:01,341:INFO:Initializing create_model()
2023-06-19 23:24:01,342:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A8E53E880>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AF6BF92E0>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 23:24:01,342:INFO:Checking exceptions
2023-06-19 23:24:01,342:INFO:Importing libraries
2023-06-19 23:24:01,342:INFO:Copying training dataset
2023-06-19 23:24:01,369:INFO:Defining folds
2023-06-19 23:24:01,370:INFO:Declaring metric variables
2023-06-19 23:24:01,374:INFO:Importing untrained model
2023-06-19 23:24:01,378:INFO:Linear Discriminant Analysis Imported successfully
2023-06-19 23:24:01,387:INFO:Starting cross validation
2023-06-19 23:24:01,389:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 23:24:06,458:INFO:Calculating mean and std
2023-06-19 23:24:06,464:INFO:Creating metrics dataframe
2023-06-19 23:24:08,139:INFO:Uploading results into container
2023-06-19 23:24:08,143:INFO:Uploading model into container now
2023-06-19 23:24:08,145:INFO:_master_model_container: 11
2023-06-19 23:24:08,145:INFO:_display_container: 2
2023-06-19 23:24:08,146:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-06-19 23:24:08,146:INFO:create_model() successfully completed......................................
2023-06-19 23:24:08,263:INFO:SubProcess create_model() end ==================================
2023-06-19 23:24:08,264:INFO:Creating metrics dataframe
2023-06-19 23:24:08,296:INFO:Initializing Extra Trees Classifier
2023-06-19 23:24:08,296:INFO:Total runtime is 1.1686968326568605 minutes
2023-06-19 23:24:08,304:INFO:SubProcess create_model() called ==================================
2023-06-19 23:24:08,305:INFO:Initializing create_model()
2023-06-19 23:24:08,305:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A8E53E880>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AF6BF92E0>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 23:24:08,305:INFO:Checking exceptions
2023-06-19 23:24:08,305:INFO:Importing libraries
2023-06-19 23:24:08,306:INFO:Copying training dataset
2023-06-19 23:24:08,371:INFO:Defining folds
2023-06-19 23:24:08,373:INFO:Declaring metric variables
2023-06-19 23:24:08,385:INFO:Importing untrained model
2023-06-19 23:24:08,396:INFO:Extra Trees Classifier Imported successfully
2023-06-19 23:24:08,417:INFO:Starting cross validation
2023-06-19 23:24:08,420:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 23:24:13,843:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 23:24:13,874:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-19 23:24:15,484:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 23:24:15,754:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-19 23:24:20,451:INFO:Calculating mean and std
2023-06-19 23:24:20,452:INFO:Creating metrics dataframe
2023-06-19 23:24:20,978:INFO:Uploading results into container
2023-06-19 23:24:20,979:INFO:Uploading model into container now
2023-06-19 23:24:20,980:INFO:_master_model_container: 12
2023-06-19 23:24:20,980:INFO:_display_container: 2
2023-06-19 23:24:20,980:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-06-19 23:24:20,980:INFO:create_model() successfully completed......................................
2023-06-19 23:24:21,053:INFO:SubProcess create_model() end ==================================
2023-06-19 23:24:21,053:INFO:Creating metrics dataframe
2023-06-19 23:24:21,066:INFO:Initializing Light Gradient Boosting Machine
2023-06-19 23:24:21,066:INFO:Total runtime is 1.3815314372380576 minutes
2023-06-19 23:24:21,070:INFO:SubProcess create_model() called ==================================
2023-06-19 23:24:21,070:INFO:Initializing create_model()
2023-06-19 23:24:21,070:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A8E53E880>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AF6BF92E0>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 23:24:21,070:INFO:Checking exceptions
2023-06-19 23:24:21,070:INFO:Importing libraries
2023-06-19 23:24:21,071:INFO:Copying training dataset
2023-06-19 23:24:21,094:INFO:Defining folds
2023-06-19 23:24:21,095:INFO:Declaring metric variables
2023-06-19 23:24:21,100:INFO:Importing untrained model
2023-06-19 23:24:21,105:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-19 23:24:21,113:INFO:Starting cross validation
2023-06-19 23:24:21,116:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 23:24:24,671:INFO:Calculating mean and std
2023-06-19 23:24:24,673:INFO:Creating metrics dataframe
2023-06-19 23:24:25,200:INFO:Uploading results into container
2023-06-19 23:24:25,200:INFO:Uploading model into container now
2023-06-19 23:24:25,200:INFO:_master_model_container: 13
2023-06-19 23:24:25,200:INFO:_display_container: 2
2023-06-19 23:24:25,200:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-19 23:24:25,200:INFO:create_model() successfully completed......................................
2023-06-19 23:24:25,274:INFO:SubProcess create_model() end ==================================
2023-06-19 23:24:25,274:INFO:Creating metrics dataframe
2023-06-19 23:24:25,289:INFO:Initializing Dummy Classifier
2023-06-19 23:24:25,289:INFO:Total runtime is 1.451908564567566 minutes
2023-06-19 23:24:25,289:INFO:SubProcess create_model() called ==================================
2023-06-19 23:24:25,289:INFO:Initializing create_model()
2023-06-19 23:24:25,289:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A8E53E880>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021AF6BF92E0>, model_only=True, return_train_score=False, kwargs={})
2023-06-19 23:24:25,289:INFO:Checking exceptions
2023-06-19 23:24:25,289:INFO:Importing libraries
2023-06-19 23:24:25,289:INFO:Copying training dataset
2023-06-19 23:24:25,313:INFO:Defining folds
2023-06-19 23:24:25,313:INFO:Declaring metric variables
2023-06-19 23:24:25,322:INFO:Importing untrained model
2023-06-19 23:24:25,323:INFO:Dummy Classifier Imported successfully
2023-06-19 23:24:25,330:INFO:Starting cross validation
2023-06-19 23:24:25,338:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 23:24:25,761:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 23:24:25,761:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 23:24:25,777:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 23:24:25,786:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 23:24:25,827:WARNING:c:\Users\choib\anaconda3\envs\iise-python\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-19 23:24:27,903:INFO:Calculating mean and std
2023-06-19 23:24:27,905:INFO:Creating metrics dataframe
2023-06-19 23:24:28,330:INFO:Uploading results into container
2023-06-19 23:24:28,331:INFO:Uploading model into container now
2023-06-19 23:24:28,332:INFO:_master_model_container: 14
2023-06-19 23:24:28,332:INFO:_display_container: 2
2023-06-19 23:24:28,332:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-06-19 23:24:28,333:INFO:create_model() successfully completed......................................
2023-06-19 23:24:28,400:INFO:SubProcess create_model() end ==================================
2023-06-19 23:24:28,400:INFO:Creating metrics dataframe
2023-06-19 23:24:28,419:INFO:Initializing create_model()
2023-06-19 23:24:28,419:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A8E53E880>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-19 23:24:28,419:INFO:Checking exceptions
2023-06-19 23:24:28,421:INFO:Importing libraries
2023-06-19 23:24:28,421:INFO:Copying training dataset
2023-06-19 23:24:28,441:INFO:Defining folds
2023-06-19 23:24:28,441:INFO:Declaring metric variables
2023-06-19 23:24:28,441:INFO:Importing untrained model
2023-06-19 23:24:28,441:INFO:Declaring custom model
2023-06-19 23:24:28,442:INFO:Random Forest Classifier Imported successfully
2023-06-19 23:24:28,443:INFO:Cross validation set to False
2023-06-19 23:24:28,443:INFO:Fitting Model
2023-06-19 23:24:30,155:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-19 23:24:30,155:INFO:create_model() successfully completed......................................
2023-06-19 23:24:30,258:INFO:_master_model_container: 14
2023-06-19 23:24:30,259:INFO:_display_container: 2
2023-06-19 23:24:30,259:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-19 23:24:30,259:INFO:compare_models() successfully completed......................................
2023-06-19 23:24:30,297:INFO:Initializing create_model()
2023-06-19 23:24:30,297:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A8E53E880>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-19 23:24:30,298:INFO:Checking exceptions
2023-06-19 23:24:30,338:INFO:Importing libraries
2023-06-19 23:24:30,338:INFO:Copying training dataset
2023-06-19 23:24:30,373:INFO:Defining folds
2023-06-19 23:24:30,373:INFO:Declaring metric variables
2023-06-19 23:24:30,378:INFO:Importing untrained model
2023-06-19 23:24:30,383:INFO:Random Forest Classifier Imported successfully
2023-06-19 23:24:30,392:INFO:Starting cross validation
2023-06-19 23:24:30,394:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 23:24:33,756:INFO:Calculating mean and std
2023-06-19 23:24:33,757:INFO:Creating metrics dataframe
2023-06-19 23:24:33,763:INFO:Finalizing model
2023-06-19 23:24:34,438:INFO:Uploading results into container
2023-06-19 23:24:34,439:INFO:Uploading model into container now
2023-06-19 23:24:34,447:INFO:_master_model_container: 15
2023-06-19 23:24:34,447:INFO:_display_container: 3
2023-06-19 23:24:34,448:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-19 23:24:34,448:INFO:create_model() successfully completed......................................
2023-06-19 23:24:34,512:INFO:Initializing predict_model()
2023-06-19 23:24:34,512:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A8E53E880>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021A8DE22160>)
2023-06-19 23:24:34,512:INFO:Checking exceptions
2023-06-19 23:24:34,512:INFO:Preloading libraries
2023-06-19 23:24:34,514:INFO:Set up data.
2023-06-19 23:24:34,532:INFO:Set up index.
2023-06-19 23:43:45,521:INFO:Initializing create_model()
2023-06-19 23:43:45,522:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A8E53E880>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-19 23:43:45,523:INFO:Checking exceptions
2023-06-19 23:43:45,616:INFO:Importing libraries
2023-06-19 23:43:45,616:INFO:Copying training dataset
2023-06-19 23:43:45,690:INFO:Defining folds
2023-06-19 23:43:45,690:INFO:Declaring metric variables
2023-06-19 23:43:45,711:INFO:Importing untrained model
2023-06-19 23:43:45,726:INFO:Random Forest Classifier Imported successfully
2023-06-19 23:43:45,757:INFO:Starting cross validation
2023-06-19 23:43:45,761:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-19 23:43:54,187:INFO:Calculating mean and std
2023-06-19 23:43:54,188:INFO:Creating metrics dataframe
2023-06-19 23:43:54,194:INFO:Finalizing model
2023-06-19 23:43:55,027:INFO:Uploading results into container
2023-06-19 23:43:55,029:INFO:Uploading model into container now
2023-06-19 23:43:55,041:INFO:_master_model_container: 16
2023-06-19 23:43:55,041:INFO:_display_container: 5
2023-06-19 23:43:55,042:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-19 23:43:55,042:INFO:create_model() successfully completed......................................
2023-06-19 23:43:55,136:INFO:Initializing predict_model()
2023-06-19 23:43:55,136:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A8E53E880>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021A8E524F70>)
2023-06-19 23:43:55,136:INFO:Checking exceptions
2023-06-19 23:43:55,136:INFO:Preloading libraries
2023-06-19 23:43:55,139:INFO:Set up data.
2023-06-19 23:43:55,167:INFO:Set up index.
2023-06-27 02:10:28,694:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-27 02:10:28,695:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-27 02:10:28,695:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-27 02:10:28,695:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-27 02:10:31,321:INFO:Soft dependency imported: prophet: 1.1.4
2023-06-27 02:10:33,121:INFO:PyCaret ClassificationExperiment
2023-06-27 02:10:33,121:INFO:Logging name: clf-default-name
2023-06-27 02:10:33,121:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-27 02:10:33,121:INFO:version 3.0.2
2023-06-27 02:10:33,121:INFO:Initializing setup()
2023-06-27 02:10:33,121:INFO:self.USI: 3f1b
2023-06-27 02:10:33,121:INFO:self._variable_keys: {'fold_generator', 'X_test', 'gpu_param', 'X_train', 'gpu_n_jobs_param', 'idx', 'fix_imbalance', 'fold_shuffle_param', 'fold_groups_param', 'exp_name_log', 'X', 'log_plots_param', 'n_jobs_param', '_ml_usecase', 'pipeline', 'exp_id', 'USI', 'logging_param', '_available_plots', 'data', 'target_param', 'y', 'y_test', 'is_multiclass', 'html_param', 'memory', 'y_train', 'seed'}
2023-06-27 02:10:33,121:INFO:Checking environment
2023-06-27 02:10:33,121:INFO:python_version: 3.8.12
2023-06-27 02:10:33,121:INFO:python_build: ('default', 'Oct 12 2021 03:01:40')
2023-06-27 02:10:33,121:INFO:machine: AMD64
2023-06-27 02:10:33,121:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-27 02:10:33,121:INFO:Memory: svmem(total=16861405184, available=3770712064, percent=77.6, used=13090693120, free=3770712064)
2023-06-27 02:10:33,121:INFO:Physical Core: 4
2023-06-27 02:10:33,122:INFO:Logical Core: 8
2023-06-27 02:10:33,122:INFO:Checking libraries
2023-06-27 02:10:33,122:INFO:System:
2023-06-27 02:10:33,122:INFO:    python: 3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]
2023-06-27 02:10:33,122:INFO:executable: c:\Users\choib\anaconda3\envs\iise-python\python.exe
2023-06-27 02:10:33,122:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-27 02:10:33,122:INFO:PyCaret required dependencies:
2023-06-27 02:10:33,122:INFO:                 pip: 21.0.1
2023-06-27 02:10:33,122:INFO:          setuptools: 58.0.4
2023-06-27 02:10:33,122:INFO:             pycaret: 3.0.2
2023-06-27 02:10:33,122:INFO:             IPython: 8.12.0
2023-06-27 02:10:33,123:INFO:          ipywidgets: 8.0.6
2023-06-27 02:10:33,123:INFO:                tqdm: 4.65.0
2023-06-27 02:10:33,123:INFO:               numpy: 1.24.3
2023-06-27 02:10:33,123:INFO:              pandas: 1.5.3
2023-06-27 02:10:33,123:INFO:              jinja2: 3.1.2
2023-06-27 02:10:33,123:INFO:               scipy: 1.10.1
2023-06-27 02:10:33,123:INFO:              joblib: 1.2.0
2023-06-27 02:10:33,123:INFO:             sklearn: 1.2.2
2023-06-27 02:10:33,123:INFO:                pyod: 1.0.9
2023-06-27 02:10:33,123:INFO:            imblearn: 0.10.1
2023-06-27 02:10:33,124:INFO:   category_encoders: 2.6.1
2023-06-27 02:10:33,124:INFO:            lightgbm: 3.3.5
2023-06-27 02:10:33,124:INFO:               numba: 0.57.0
2023-06-27 02:10:33,124:INFO:            requests: 2.31.0
2023-06-27 02:10:33,124:INFO:          matplotlib: 3.4.3
2023-06-27 02:10:33,124:INFO:          scikitplot: 0.3.7
2023-06-27 02:10:33,124:INFO:         yellowbrick: 1.5
2023-06-27 02:10:33,125:INFO:              plotly: 5.15.0
2023-06-27 02:10:33,125:INFO:             kaleido: 0.2.1
2023-06-27 02:10:33,125:INFO:         statsmodels: 0.14.0
2023-06-27 02:10:33,126:INFO:              sktime: 0.17.0
2023-06-27 02:10:33,126:INFO:               tbats: 1.1.3
2023-06-27 02:10:33,126:INFO:            pmdarima: 2.0.3
2023-06-27 02:10:33,127:INFO:              psutil: 5.9.0
2023-06-27 02:10:33,128:INFO:PyCaret optional dependencies:
2023-06-27 02:10:33,151:INFO:                shap: Not installed
2023-06-27 02:10:33,151:INFO:           interpret: Not installed
2023-06-27 02:10:33,151:INFO:                umap: Not installed
2023-06-27 02:10:33,151:INFO:    pandas_profiling: Not installed
2023-06-27 02:10:33,151:INFO:  explainerdashboard: Not installed
2023-06-27 02:10:33,151:INFO:             autoviz: Not installed
2023-06-27 02:10:33,151:INFO:           fairlearn: Not installed
2023-06-27 02:10:33,151:INFO:             xgboost: Not installed
2023-06-27 02:10:33,151:INFO:            catboost: Not installed
2023-06-27 02:10:33,151:INFO:              kmodes: Not installed
2023-06-27 02:10:33,152:INFO:             mlxtend: Not installed
2023-06-27 02:10:33,152:INFO:       statsforecast: Not installed
2023-06-27 02:10:33,152:INFO:        tune_sklearn: Not installed
2023-06-27 02:10:33,152:INFO:                 ray: Not installed
2023-06-27 02:10:33,152:INFO:            hyperopt: Not installed
2023-06-27 02:10:33,152:INFO:              optuna: Not installed
2023-06-27 02:10:33,152:INFO:               skopt: Not installed
2023-06-27 02:10:33,152:INFO:              mlflow: Not installed
2023-06-27 02:10:33,152:INFO:              gradio: Not installed
2023-06-27 02:10:33,152:INFO:             fastapi: Not installed
2023-06-27 02:10:33,152:INFO:             uvicorn: Not installed
2023-06-27 02:10:33,152:INFO:              m2cgen: Not installed
2023-06-27 02:10:33,152:INFO:           evidently: Not installed
2023-06-27 02:10:33,152:INFO:               fugue: Not installed
2023-06-27 02:10:33,152:INFO:           streamlit: Not installed
2023-06-27 02:10:33,152:INFO:             prophet: 1.1.4
2023-06-27 02:10:33,152:INFO:None
2023-06-27 02:10:33,152:INFO:Set up data.
2023-06-27 02:10:33,189:INFO:Set up train/test split.
2023-06-27 02:10:33,225:INFO:Set up index.
2023-06-27 02:10:33,229:INFO:Set up folding strategy.
2023-06-27 02:10:33,229:INFO:Assigning column types.
2023-06-27 02:10:33,250:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-27 02:10:33,291:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-27 02:10:33,299:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-27 02:10:33,346:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-27 02:10:33,414:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-27 02:10:33,453:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-27 02:10:33,454:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-27 02:10:33,478:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-27 02:10:33,478:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-27 02:10:33,478:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-27 02:10:33,527:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-27 02:10:33,551:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-27 02:10:33,551:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-27 02:10:33,589:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-27 02:10:33,614:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-27 02:10:33,614:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-27 02:10:33,614:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-27 02:10:33,677:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-27 02:10:33,678:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-27 02:10:33,738:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-27 02:10:33,739:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-27 02:10:33,740:INFO:Preparing preprocessing pipeline...
2023-06-27 02:10:33,750:INFO:Set up simple imputation.
2023-06-27 02:10:33,759:INFO:Set up encoding of categorical features.
2023-06-27 02:10:33,761:INFO:Set up feature normalization.
2023-06-27 02:10:34,000:INFO:Finished creating preprocessing pipeline.
2023-06-27 02:10:34,005:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\choib\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['disk_id', 'r_1', 'n_5', 'r_5',
                                             'r_9', 'r_12', 'n_171', 'r_171',
                                             'n_172', 'r_172', 'n_173', 'r_174',
                                             'n_180', 'r_180', 'n_184', 'r_184',
                                             'r_187', 'r_188', 'n_190', 'r_190',
                                             'r_194', 'r_195', 'n_196', 'r_196',
                                             'r_197', 'r_198', 'r...
                 TransformerWrapper(exclude=None, include=['ds'],
                                    transformer=TargetEncoder(cols=['ds'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1))))],
         verbose=False)
2023-06-27 02:10:34,006:INFO:Creating final display dataframe.
2023-06-27 02:10:34,550:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             label
2                   Target type            Binary
3           Original data shape       (52838, 31)
4        Transformed data shape       (52838, 31)
5   Transformed train set shape       (36986, 31)
6    Transformed test set shape       (15852, 31)
7              Numeric features                29
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            minmax
17               Fold Generator   StratifiedKFold
18                  Fold Number                 5
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              3f1b
2023-06-27 02:10:34,620:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-27 02:10:34,621:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-27 02:10:34,684:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-27 02:10:34,685:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-27 02:10:34,685:INFO:setup() successfully completed in 2.58s...............
2023-06-27 02:10:34,686:INFO:Initializing compare_models()
2023-06-27 02:10:34,686:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B172731940>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001B172731940>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-06-27 02:10:34,686:INFO:Checking exceptions
2023-06-27 02:10:34,700:INFO:Preparing display monitor
2023-06-27 02:10:34,740:INFO:Initializing Logistic Regression
2023-06-27 02:10:34,740:INFO:Total runtime is 0.0 minutes
2023-06-27 02:10:34,746:INFO:SubProcess create_model() called ==================================
2023-06-27 02:10:34,747:INFO:Initializing create_model()
2023-06-27 02:10:34,747:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B172731940>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B1120AC0D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-27 02:10:34,747:INFO:Checking exceptions
2023-06-27 02:10:34,747:INFO:Importing libraries
2023-06-27 02:10:34,747:INFO:Copying training dataset
2023-06-27 02:10:34,771:INFO:Defining folds
2023-06-27 02:10:34,771:INFO:Declaring metric variables
2023-06-27 02:10:34,775:INFO:Importing untrained model
2023-06-27 02:10:34,779:INFO:Logistic Regression Imported successfully
2023-06-27 02:10:34,786:INFO:Starting cross validation
2023-06-27 02:10:34,788:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-27 02:10:40,929:INFO:Calculating mean and std
2023-06-27 02:10:40,930:INFO:Creating metrics dataframe
2023-06-27 02:10:41,294:INFO:Uploading results into container
2023-06-27 02:10:41,296:INFO:Uploading model into container now
2023-06-27 02:10:41,296:INFO:_master_model_container: 1
2023-06-27 02:10:41,296:INFO:_display_container: 2
2023-06-27 02:10:41,297:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-06-27 02:10:41,297:INFO:create_model() successfully completed......................................
2023-06-27 02:10:41,365:INFO:SubProcess create_model() end ==================================
2023-06-27 02:10:41,365:INFO:Creating metrics dataframe
2023-06-27 02:10:41,372:INFO:Initializing K Neighbors Classifier
2023-06-27 02:10:41,373:INFO:Total runtime is 0.11055268843968709 minutes
2023-06-27 02:10:41,377:INFO:SubProcess create_model() called ==================================
2023-06-27 02:10:41,377:INFO:Initializing create_model()
2023-06-27 02:10:41,378:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B172731940>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B1120AC0D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-27 02:10:41,378:INFO:Checking exceptions
2023-06-27 02:10:41,378:INFO:Importing libraries
2023-06-27 02:10:41,378:INFO:Copying training dataset
2023-06-27 02:10:41,402:INFO:Defining folds
2023-06-27 02:10:41,402:INFO:Declaring metric variables
2023-06-27 02:10:41,408:INFO:Importing untrained model
2023-06-27 02:10:41,414:INFO:K Neighbors Classifier Imported successfully
2023-06-27 02:10:41,423:INFO:Starting cross validation
2023-06-27 02:10:41,427:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-27 02:10:49,020:INFO:Calculating mean and std
2023-06-27 02:10:49,022:INFO:Creating metrics dataframe
2023-06-27 02:10:49,438:INFO:Uploading results into container
2023-06-27 02:10:49,439:INFO:Uploading model into container now
2023-06-27 02:10:49,440:INFO:_master_model_container: 2
2023-06-27 02:10:49,440:INFO:_display_container: 2
2023-06-27 02:10:49,441:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-06-27 02:10:49,441:INFO:create_model() successfully completed......................................
2023-06-27 02:10:49,538:INFO:SubProcess create_model() end ==================================
2023-06-27 02:10:49,538:INFO:Creating metrics dataframe
2023-06-27 02:10:49,547:INFO:Initializing Naive Bayes
2023-06-27 02:10:49,548:INFO:Total runtime is 0.2467921535174052 minutes
2023-06-27 02:10:49,550:INFO:SubProcess create_model() called ==================================
2023-06-27 02:10:49,550:INFO:Initializing create_model()
2023-06-27 02:10:49,550:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B172731940>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B1120AC0D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-27 02:10:49,550:INFO:Checking exceptions
2023-06-27 02:10:49,550:INFO:Importing libraries
2023-06-27 02:10:49,550:INFO:Copying training dataset
2023-06-27 02:10:49,571:INFO:Defining folds
2023-06-27 02:10:49,571:INFO:Declaring metric variables
2023-06-27 02:10:49,574:INFO:Importing untrained model
2023-06-27 02:10:49,579:INFO:Naive Bayes Imported successfully
2023-06-27 02:10:49,586:INFO:Starting cross validation
2023-06-27 02:10:49,588:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-27 02:10:51,815:INFO:Calculating mean and std
2023-06-27 02:10:51,816:INFO:Creating metrics dataframe
2023-06-27 02:10:52,213:INFO:Uploading results into container
2023-06-27 02:10:52,214:INFO:Uploading model into container now
2023-06-27 02:10:52,215:INFO:_master_model_container: 3
2023-06-27 02:10:52,215:INFO:_display_container: 2
2023-06-27 02:10:52,215:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-06-27 02:10:52,215:INFO:create_model() successfully completed......................................
2023-06-27 02:10:52,290:INFO:SubProcess create_model() end ==================================
2023-06-27 02:10:52,291:INFO:Creating metrics dataframe
2023-06-27 02:10:52,301:INFO:Initializing Decision Tree Classifier
2023-06-27 02:10:52,302:INFO:Total runtime is 0.29270099401474 minutes
2023-06-27 02:10:52,305:INFO:SubProcess create_model() called ==================================
2023-06-27 02:10:52,305:INFO:Initializing create_model()
2023-06-27 02:10:52,306:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B172731940>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B1120AC0D0>, model_only=True, return_train_score=False, kwargs={})
2023-06-27 02:10:52,306:INFO:Checking exceptions
2023-06-27 02:10:52,306:INFO:Importing libraries
2023-06-27 02:10:52,306:INFO:Copying training dataset
2023-06-27 02:10:52,330:INFO:Defining folds
2023-06-27 02:10:52,330:INFO:Declaring metric variables
2023-06-27 02:10:52,334:INFO:Importing untrained model
2023-06-27 02:10:52,339:INFO:Decision Tree Classifier Imported successfully
2023-06-27 02:10:52,347:INFO:Starting cross validation
2023-06-27 02:10:52,349:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
